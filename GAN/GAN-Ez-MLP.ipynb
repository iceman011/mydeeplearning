{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "MINST-GAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iceman011/mydeeplearning/blob/master/GAN/GAN-Ez-MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4T7d7TxwUU9",
        "outputId": "fcd7af9a-944d-432c-9239-a36885cfdd0b"
      },
      "source": [
        "#Imports\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "!pip install https://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_86x_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install tensorboardX"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.4.1-cp36-cp36m-linux_86x_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (51.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54k0Ue9XwUVE"
      },
      "source": [
        "from logger import Logger"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmQPZHf6wUVF"
      },
      "source": [
        "#Dataset class\n",
        "\n",
        "def mnist_data():\n",
        "    compose = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5), ( 0.5))\n",
        "        ])\n",
        "    out_dir = './dataset'\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
        "\n",
        "# Load data\n",
        "data = mnist_data()\n",
        "\n",
        "# Create loader with data, so that we can iterate over it\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOWjIA7uwUVF",
        "outputId": "e97033fd-6c0a-41f6-8ef6-1c553fcefb69"
      },
      "source": [
        "#Discriminator\n",
        "\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 784\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "discriminator = DiscriminatorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    discriminator = discriminator.cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8dlj0ewwUVG"
      },
      "source": [
        "#Dimensionality changing \n",
        "\n",
        "def images_to_vectors(images):\n",
        "    return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZNces_awUVG"
      },
      "source": [
        "#Generator\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 784\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "generator = GeneratorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    generator = generator.cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HearFsdBwUVH"
      },
      "source": [
        "#Random noise sampler\n",
        "\n",
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    return n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBHjEHW6wUVH"
      },
      "source": [
        "#Optimizers\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kngnLNNwUVH"
      },
      "source": [
        "#Loss fucntion\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsCUNq3mwUVI"
      },
      "source": [
        "#Target vectors\n",
        "\n",
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    return data\n",
        "\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    return data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze352xdxwUVI"
      },
      "source": [
        "#Discriminator Trainer\n",
        "\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data.cuda())\n",
        "    prediction_real = prediction_real.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real.cuda(), ones_target(N).cuda())\n",
        "    error_real = error_real.cuda()\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data.cuda())\n",
        "    prediction_fake = prediction_fake.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake.cuda(), zeros_target(N).cuda())\n",
        "    error_fake = error_fake.cuda()\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_real + error_fake, prediction_real, prediction_fake"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F0l6qixwUVJ"
      },
      "source": [
        "#Generator Trainer\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    N = fake_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data.cuda())\n",
        "    prediction = prediction.cuda()\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction.cuda(), ones_target(N).cuda())\n",
        "    error = error.cuda()\n",
        "    error.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OcWOzZtwUVJ"
      },
      "source": [
        "#Testing\n",
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsGn-mVtwUVJ"
      },
      "source": [
        "#Training\n",
        "\n",
        "# Create logger instance\n",
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "# Total number of epochs to train\n",
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "        N = real_batch.size(0)\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch).cuda())\n",
        "\n",
        "        # Generate fake data and detach \n",
        "        # (so gradients are not calculated for generator)\n",
        "        fake_data = generator((noise(N).cuda().detach()))\n",
        "\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = \\\n",
        "              train_discriminator(d_optimizer, real_data.cuda(), fake_data.cuda())\n",
        "\n",
        "        # 2. Train Generator\n",
        "\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(N).cuda())\n",
        "\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "\n",
        "        # Log batch error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress every few batches\n",
        "        if (n_batch) % 100 == 0: \n",
        "            test_images = vectors_to_images(generator(test_noise.cuda()))\n",
        "            test_images = test_images.data\n",
        "\n",
        "            logger.log_images(\n",
        "                test_images.cpu(), num_test_samples, \n",
        "                epoch, n_batch, num_batches\n",
        "            );\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_PTxjXgwUVK"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeuK3akBwUVK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}