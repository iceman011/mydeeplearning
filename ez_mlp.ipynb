{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqYa6V2exOFUw9ttzE30Jn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iceman011/mydeeplearning/blob/master/ez_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBXy2soVzPQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import datetime\n",
        "import os\n",
        "import pdb\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "#%config InlineBackend.figure_format = 'retina'\n",
        "  \n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from torch import optim\n",
        "import itertools\n",
        "#!/usr/bin/env python3\n",
        "import mmap\n",
        "import re\n",
        "from itertools import dropwhile, product\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers,output_classes,transform,dataset, drop_p=0.5,lr =0.001, train_on_gpu=False):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input layer\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "        \n",
        "        '''\n",
        "        super().__init__()\n",
        "        if train_on_gpu:\n",
        "          # check if CUDA is available\n",
        "          self.train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "        if not self.train_on_gpu:\n",
        "            print('CUDA is not available.  Using CPU ...')\n",
        "        else:\n",
        "            print('CUDA is available!  Using GPU ...')\n",
        "            \n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = lr\n",
        "        self.drop_ratio = drop_p\n",
        "        self.output_classes = output_classes\n",
        "        self.transform=transform\n",
        "        self.dataset=dataset\n",
        "\n",
        "        # Input to a hidden layer\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "        \n",
        "        # Add a variable number of more hidden layers\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "        \n",
        "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=drop_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        for each in self.hidden_layers:\n",
        "            x = F.relu(each(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "######################    \n",
        "# LOADING DATA #\n",
        "######################\n",
        "def LoadData(datasetName,batch_size=20,valid_size = 0.2):\n",
        "      \n",
        "    # number of subprocesses to use for data loading\n",
        "    num_workers = 0\n",
        "\n",
        "\n",
        "    # convert data to torch.FloatTensor\n",
        "    #transform = transforms.ToTensor()\n",
        "\n",
        "    # convert data to a normalized torch.FloatTensor\n",
        "    transform = None\n",
        "    train_data= None\n",
        "    test_data=None\n",
        "    classes=None\n",
        "    if(datasetName == 'MINST'):\n",
        "       # convert data to a normalized torch.FloatTensor\n",
        "      transform = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "          #transforms.RandomRotation(10),\n",
        "          transforms.CenterCrop(224),          \n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, ), (0.5, ))\n",
        "          ])\n",
        "      \n",
        "      # choose the training and test datasets\n",
        "      train_data = datasets.MNIST(root='data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "      test_data = datasets.MNIST(root='data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "      # specify the image classes\n",
        "      classes = ['1', '2', '3', '4', '5',\n",
        "           '6', '7', '8', '9', '10']\n",
        "    elif(datasetName == 'CIFAR'):\n",
        "      \n",
        "      # convert data to a normalized torch.FloatTensor\n",
        "      transform = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "          transforms.RandomRotation(10),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "          ])\n",
        "      \n",
        "      # choose the training and test datasets\n",
        "      train_data = datasets.CIFAR10(root='data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "      test_data = datasets.CIFAR10(root='data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "      # specify the image classes\n",
        "      classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "\n",
        "    # obtain training indices that will be used for validation\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # define samplers for obtaining training and validation batches\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # prepare data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "        sampler=train_sampler, num_workers=num_workers)\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "        sampler=valid_sampler, num_workers=num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "        num_workers=num_workers)\n",
        "    return train_loader , valid_loader ,test_loader ,classes , transform\n",
        "\n",
        "\n",
        "#############################\n",
        "# VALIDATE MODEL\n",
        "############################\n",
        "def validation(model, validationloader, criterion):\n",
        "    accuracy = 0\n",
        "    validation_loss = 0\n",
        "    validate_start_time = time.time()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : ','Starting Validation....')\n",
        "\n",
        "    with torch.no_grad():    \n",
        "      # move tensors to GPU if CUDA is available\n",
        "      if model.train_on_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "      for images, labels in validationloader:\n",
        "\n",
        "          if model.train_on_gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "          \n",
        "          images = images.resize_(images.size()[0], model.input_size)\n",
        "\n",
        "          output = model.forward(images)\n",
        "          validation_loss += criterion(output, labels).item()\n",
        "\n",
        "          ## Calculating the accuracy \n",
        "          # Model's output is log-softmax, take exponential to get the probabilities\n",
        "          ps = torch.exp(output)\n",
        "          # Class with highest probability is our predicted class, compare with true label\n",
        "          #equality = (labels.data == ps.max(1)[1])\n",
        "          # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
        "          #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "\n",
        "\n",
        "        \n",
        "          top_p, top_class = ps.topk(1, dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor))      \n",
        "        \n",
        "      validation_loss = validation_loss/len(validationloader)\n",
        "      accuracy = 100. * accuracy/len(validationloader)\n",
        "    \n",
        "    print('Finished Validation In ',datetime.timedelta(seconds = time.time() - validate_start_time) )\n",
        "    return validation_loss, accuracy\n",
        "\n",
        "#############################\n",
        "# TEST MODEL\n",
        "############################\n",
        "def test(model,test_loader,criterion,checkpoint,outputfilepath,batch_size,override_checkpoint):\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(model.output_size))\n",
        "    class_total = list(0. for i in range(model.output_size))\n",
        "    test_start_time = time.time()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Testing....')\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if model.train_on_gpu:\n",
        "      model.cuda()\n",
        "\n",
        "    with torch.no_grad():    \n",
        "      model.eval()\n",
        "      # iterate over test data\n",
        "      for data, target in test_loader:\n",
        "          # move tensors to GPU if CUDA is available\n",
        "          if model.train_on_gpu:\n",
        "              data, target = data.cuda(), target.cuda()\n",
        "          \n",
        "          # Flatten images into a 784 long vector\n",
        "          data.resize_(data.size()[0], model.input_size)\n",
        "\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the batch loss\n",
        "          loss = criterion(output, target)\n",
        "          # update test loss \n",
        "          test_loss += loss.item()*data.size(0)\n",
        "          # convert output probabilities to predicted class\n",
        "          _, pred = torch.max(output, 1)    \n",
        "          # compare predictions to true label\n",
        "          correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "          correct = np.squeeze(correct_tensor.numpy()) if not model.train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "          # calculate test accuracy for each object class\n",
        "          for i in range(batch_size):\n",
        "              label = target.data[i]\n",
        "              class_correct[label] += correct[i].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "      # average test loss\n",
        "      print('Finished Testing during ',datetime.timedelta(seconds=time.time() - test_start_time))\n",
        "      test_loss = test_loss/len(test_loader.dataset)\n",
        "      print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "      \n",
        "      test_checkpoint = dict()\n",
        "\n",
        "      if(override_checkpoint):\n",
        "        checkpoint.update({'TestLoss': test_loss})\n",
        "      else :\n",
        "        test_checkpoint.update({'TestLoss': test_loss})\n",
        "\n",
        "      for i in range(model.output_size):\n",
        "          if class_total[i] > 0:\n",
        "            current_key  = 'Test Accuracy of '+model.output_classes[i]\n",
        "            current_val = '{:.3f}% ({}/{})'.format(100 *( class_correct[i] / class_total[i]),\n",
        "                  np.sum(class_correct[i]), np.sum(class_total[i]))\n",
        "            ele={current_key:current_val}\n",
        "            if(override_checkpoint):\n",
        "              checkpoint.update(ele)\n",
        "              print(current_key,current_val)\n",
        "            else:\n",
        "              test_checkpoint.update(ele)\n",
        "\n",
        "\n",
        "          \"\"\"else:\n",
        "              print('Test Accuracy of %5s: N/A (no training examples)' % (model.output_classes[i]))\n",
        "          \"\"\"\n",
        "\n",
        "      current_key = 'Test Accuracy (Overall): '#.format(100. * np.sum(class_correct) / np.sum(class_total))\n",
        "      current_val = '{:.3f}% ({}/{})'.format(100 * (np.sum(class_correct) / np.sum(class_total)),\n",
        "          np.sum(class_correct), np.sum(class_total) )\n",
        "      ele={current_key:current_val}\n",
        "      if(override_checkpoint):\n",
        "        checkpoint.update(ele)      \n",
        "        print(current_key,current_val)\n",
        "      else:\n",
        "        test_checkpoint.update(ele)\n",
        "        test_checkpoint.update({'Detailed ':checkpoint})\n",
        "\n",
        "    \n",
        "    #model.train()\n",
        "    if(override_checkpoint):\n",
        "      print('Overriding Checkpoint')\n",
        "      torch.save(checkpoint,outputfilepath)\n",
        "\n",
        "    return checkpoint , test_checkpoint\n",
        "\n",
        "#############################\n",
        "# TRAIN MODEL\n",
        "############################\n",
        "def train(model, trainloader, validationloader, criterion, optimizer, uploadToGDrive,checkpointPath,PreviousCheckPointId,\n",
        "          PreviousValidationLoss,start_time,exp_id,epochs=5, print_every=40):\n",
        "    # monitor training loss    \n",
        "    steps = 0    \n",
        "    #start_time = time.time()\n",
        "    #dateTimeObj = datetime.now()\n",
        "    #start_time_timestamp = './results/'+dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "    #start_time_timestamp = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "    train_losses, valid_losses = [], []\n",
        "    checkpoint = dict()\n",
        "\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if model.train_on_gpu:\n",
        "      model.cuda()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Training using Model Parameters \\n '+str(model)+' \\n from PreviousModel '+ PreviousCheckPointId + ' with validationLoss '+ str(PreviousValidationLoss) )\n",
        "    valid_loss_min = PreviousValidationLoss #np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "    for e in range(epochs):        \n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Training of Epoch'+str(e)  )\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            steps += 1\n",
        "            \n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if model.train_on_gpu:\n",
        "              images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "            # Flatten images into a 784 long vector\n",
        "            images.resize_(images.size()[0], model.input_size)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss = train_loss/len(trainloader.sampler)\n",
        "        train_losses.append(train_loss)\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        # Model in inference mode, dropout is off\n",
        "        model.eval()\n",
        "        print(' Finished Training of Epoch '+str(e),' In ',datetime.timedelta(seconds = time.time() - epoch_start_time) )\n",
        "\n",
        "        # Turn off gradients for validation, will speed up inference\n",
        "        with torch.no_grad():\n",
        "            valid_loss, accuracy = validation(model, validationloader, criterion)\n",
        "        \n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print('{} : Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy : {:.6f}'.format(\n",
        "            dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\"),\n",
        "            e+1, \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            accuracy\n",
        "            ))\n",
        "        \n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f} ,)  Accuracy: {:.6f}  TimeElapsed: {:.6f}.  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss,\n",
        "            accuracy,\n",
        "            (time.time() - start_time)))\n",
        "            \n",
        "            \n",
        "\n",
        "            checkpoint = {'InputSize': model.input_size,\n",
        "                  'OutputSize': model.output_size,\n",
        "                  'HiddenLayers': [each.out_features for each in model.hidden_layers],\n",
        "                  'LearningRate':model.learning_rate,\n",
        "                  'DropRatio':model.drop_ratio,\n",
        "                  'TrainingLoss' :train_loss,\n",
        "                  'ValidationLoss':valid_loss,\n",
        "                  'ValidationAccuracy':accuracy,\n",
        "                  'ElapsedTime': datetime.timedelta(seconds = time.time() - start_time),\n",
        "                  'Dataset':model.dataset,\n",
        "                  'LastEpoch': e,\n",
        "                  'PreviousCheckPoint': PreviousCheckPointId,\n",
        "                  'GPUState': model.train_on_gpu,                  \n",
        "                  'OutputFolder' : exp_id,\n",
        "                  'CheckPointTimestamp': dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\"), #time.time(),\n",
        "                  'OutputFilePrefix' : 'checkpoint_',\n",
        "                  'OutputClasses': model.output_classes,\n",
        "                  'Transforms': model.transform,\n",
        "                  'TrainingLosses' :train_losses,\n",
        "                  'ValidationLosses':valid_losses,\n",
        "                  'StateDictionay': model.state_dict()}\n",
        "            \n",
        "            #print(checkpoint)\n",
        "            save_model(checkpoint,uploadToGDrive,checkpointPath)\n",
        "            valid_loss_min = valid_loss\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "\n",
        "    return train_losses , valid_losses , checkpoint\n",
        "\n",
        "\n",
        "#############################\n",
        "# SAVE MODEL TO GOOGLE DRIVE\n",
        "############################\n",
        "def save_model(checkpoint,uploadToGDrive,checkpointPath):\n",
        "  \n",
        "  file_path = ''\n",
        "  if(uploadToGDrive):\n",
        "    drive.mount('/content/gdrive')\n",
        "    file_path = checkpointPath+checkpoint['OutputFolder']\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)      \n",
        "    #path = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch'])+'.pt'\n",
        "    print('Saving Model to ',file_path +'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "    torch.save(checkpoint, file_path +'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "  else:\n",
        "    file_path=checkpointPath+checkpoint['OutputFolder']\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "    \n",
        "    print('Saving Model to ',file_path+'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "    torch.save(checkpoint, file_path+'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "\n",
        "\n",
        "###########################\n",
        "# SKIP CERTAIN ENTERIES FROM ITERTOOLS.PRODUCT\n",
        "#####################33\n",
        "def resume(iterable, sentinel):\n",
        "    yield from dropwhile(lambda x: x != sentinel, iterable)\n",
        "\n",
        "#############################\n",
        "# LOAD LAST EXPERIMENT PARAMS\n",
        "##################################\n",
        "def load_last_exp_param(logPath,checkpointPath):\n",
        "\n",
        "  #with open(checkpointPath+'/3-3-2020.txt') as f:\n",
        "  #    total = f.read()\n",
        "  #    print( total.count('Starting New') )\n",
        "      \n",
        "  f = open(logPath, 'r')\n",
        "  content = f.read()\n",
        "\n",
        "  hidden_layers = re.findall('hidden_layers: \\{(.+?)\\}', content)\n",
        "  hidden_layers = int(hidden_layers[len(hidden_layers)-1])\n",
        "\n",
        "  hidden_layer_width = re.findall('hidden_layer_width: \\{(.+?)\\}', content)\n",
        "  hidden_layer_width = hidden_layer_width[len(hidden_layer_width)-1]\n",
        "\n",
        "  Learning_rate = re.findall('Learning_Rate: \\{(.+?)\\}', content)\n",
        "  Learning_rate = float(Learning_rate[len(Learning_rate)-1])\n",
        "\n",
        "  drop_ratio = re.findall('drop_ratio: \\{(.+?)\\}', content)\n",
        "  drop_ratio = float(drop_ratio[len(drop_ratio)-1])\n",
        "  prev_valid_loss = np.Inf\n",
        "  return_checkpoint = None\n",
        "  return_model = None\n",
        "\n",
        "  #for filename in os.listdir(checkpointPath):\n",
        "  for root, dirs, files in os.walk(checkpointPath):\n",
        "    for filename in files:\n",
        "      model , checkpoint , filepath = load_checkpoint(root,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')],load_model=True)\n",
        "      if( float(checkpoint['ValidationLoss']) < prev_valid_loss ):\n",
        "        prev_valid_loss = checkpoint['ValidationLoss']\n",
        "      \n",
        "      \n",
        "      #pdb.set_trace()\n",
        "      hidden_layer_width_local = hidden_layer_width.strip()\n",
        "      hidden_layer_width_local = hidden_layer_width_local[1:len(hidden_layer_width_local)-1]\n",
        "      hidden_layer_width_local = list(map(int, hidden_layer_width_local.split(',')))\n",
        "\n",
        "      if(hidden_layer_width_local == checkpoint['HiddenLayers'] and float(checkpoint['ValidationLoss']) <= prev_valid_loss ):\n",
        "        print(' Found Matching Checkpoint with Last Experiement Parame ValidationLoss:{} hidden_layers:{}  hidden_layer_width:{} Learning_rate:{} drop_ratio:{} '.format(checkpoint['ValidationLoss'],hidden_layers,hidden_layer_width,Learning_rate,drop_ratio))\n",
        "        return_checkpoint = checkpoint\n",
        "        return_model = model\n",
        "        prev_valid_loss = checkpoint['ValidationLoss']\n",
        "        #return checkpoint,model,hidden_layers,hidden_layer_width,Learning_rate,drop_ratio,prev_valid_loss\n",
        "\n",
        "  if( not bool(return_checkpoint)): \n",
        "    print(' Not Found Matching Checkpoint with Last Experiement Parameters hidden_layers:{}  hidden_layer_width:{} Learning_rate:{} drop_ratio:{} '.format(hidden_layers,hidden_layer_width,Learning_rate,drop_ratio))    \n",
        "\n",
        "  return return_checkpoint,return_model,hidden_layers,hidden_layer_width,Learning_rate,drop_ratio,prev_valid_loss\n",
        "\n",
        "\n",
        "################################\n",
        "# TUNE NETWORK LAYERS AND NO. OF NODES\n",
        "##################################\n",
        "def tune_train_network(dataset,epochs,resumeExp=False,resume_logPath='',resume_checkpointPath=''):\n",
        "\n",
        "  start_time = time.time()\n",
        "  dateTimeObj = dt.now()\n",
        "  exp_id = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "\n",
        "  #How many samples loaded per batch\n",
        "  batch_size = 20\n",
        "  # percentage of training set to use as validation\n",
        "  valid_size = 0.2\n",
        "  #dataset = 'MINST'\n",
        "  checkpointPath = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'\n",
        "  #checkpointPath = f'./results/'+dataset+'/'\n",
        "\n",
        "  #train_loader =None\n",
        "  #valid_loader =None\n",
        "  #Load Data\n",
        "  \n",
        "  train_loader , valid_loader ,test_loader , classes , transform = LoadData(dataset,batch_size,valid_size)\n",
        "\n",
        "  nodes_per_layer =  [2048, 1024, 512, 256, 128, 64, 32]\n",
        "  full_learning_rates= [0.1, 0.01, 0.0001, 0.001]\n",
        "  full_drop_ratios= [0.8, 0.5, 0.3, 0.1]\n",
        "  learning_rates = None\n",
        "  drop_ratios = None\n",
        "  PreviousValidationLoss= np.Inf\n",
        "  max_hidden_layers = 3\n",
        "  iter_hidden_layer_nodes = None\n",
        "  iter_hidden_layer_nodes_list = None\n",
        "  model = None\n",
        "  resume_checkpoint = None\n",
        "\n",
        "  if(resumeExp):\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Resuming Experiment With New ID ',exp_id )\n",
        "    resume_checkpoint,model,resum_hidden_layers,resume_hidden_layer_width,resume_Learning_rate,resume_drop_ratio,resume_prev_valid_loss =  load_last_exp_param(resume_logPath,resume_checkpointPath)\n",
        "    max_hidden_layers = resum_hidden_layers  \n",
        "\n",
        "    learning_rates = full_learning_rates[full_learning_rates.index(resume_Learning_rate):]\n",
        "    drop_ratios = full_drop_ratios[full_drop_ratios.index(resume_drop_ratio):]\n",
        "    PreviousValidationLoss = resume_prev_valid_loss\n",
        "    checkpointPath = resume_checkpointPath\n",
        "\n",
        "      #iter_hidden_layer_nodes = resume(itertools.product(nodes_per_layer, repeat=hidden_layers+1), resume_checkpoint['HiddenLayers'])      \n",
        "    #if(bool(resume_checkpoint)):\n",
        "    #  model , resume_checkpoint , filepath = load_checkpoint(checkpointPath,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')])\n",
        "      \n",
        "\n",
        "  global_counter = 0\n",
        "  #VARY HIDDEN LAEYERS\n",
        "  for hidden_layers in range(max_hidden_layers,0,-1):\n",
        "    #VARY HIDDEN LAYER NODES/WIDTH\n",
        "    if(resumeExp ):\n",
        "      iter_hidden_layer_nodes = itertools.product(nodes_per_layer, repeat= hidden_layers)\n",
        "      iter_hidden_layer_nodes_list = [item for item in iter_hidden_layer_nodes]\n",
        "      resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\n",
        "      \n",
        "      #pdb.set_trace()\n",
        "      resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\n",
        "      resume_hidden_layer_width_list = tuple(list(map(int, resume_hidden_layer_width.split(','))))\n",
        "      iter_hidden_layer_nodes_list = iter_hidden_layer_nodes_list[iter_hidden_layer_nodes_list.index(resume_hidden_layer_width_list):]\n",
        "      \n",
        "      print('Resume ValidationLoss ',PreviousValidationLoss,'Resume Learning Rate Array ',learning_rates ,' Resume Drop Ratio List ',drop_ratios , ' Resume Hidden Nodes List ',iter_hidden_layer_nodes_list )\n",
        "    else:      \n",
        "      iter_hidden_layer_nodes = itertools.product(nodes_per_layer, repeat=hidden_layers+1)\n",
        "      iter_hidden_layer_nodes_list = [item for item in iter_hidden_layer_nodes]\n",
        "    for hidden_layer in iter_hidden_layer_nodes_list:\n",
        "      #VARY LEARNING RATE\n",
        "      if( not resumeExp):\n",
        "        learning_rates = full_learning_rates\n",
        "      for lr in learning_rates :\n",
        "        #VARY DROP RATIO\n",
        "        if( not resumeExp):\n",
        "          drop_ratios = full_drop_ratios\n",
        "        for drop_ratio in drop_ratios :\n",
        "          \n",
        "          print('Global Counter: '+str(global_counter)+' EXP-ID : '+exp_id+'  DurationSinceStart :',datetime.timedelta(seconds = time.time() - start_time),' Starting New Experiment with %hidden_layers: {',hidden_layers,'}% %hidden_layer_width: {',hidden_layer ,'}% %Learning_Rate: {',lr, '}% %drop_ratio: {',drop_ratio,'}%')\n",
        "          #model = Network(784, 10, [first_layer, second_layer, third_layer ],classes,transform,dataset, lr=0.001,train_on_gpu=True)\n",
        "          if( not bool(resume_checkpoint) or not resumeExp ):\n",
        "            if(dataset == 'MINST'):\n",
        "              model = Network(784, 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True)\n",
        "            else:\n",
        "              model = Network((32*32*3), 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True)\n",
        "\n",
        "\n",
        "          criterion = nn.NLLLoss()\n",
        "          optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "          #Upload checkpoint to local drive\n",
        "          #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, False,checkpointPath,PreviousCheckPointId,PreviousValidationLoss,epochs=100)\n",
        "\n",
        "          #Upload to gDrive\n",
        "          train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, True,checkpointPath,'',PreviousValidationLoss,start_time,exp_id,epochs=epochs)\n",
        "          if( bool(checkpointt) and checkpointt['ValidationLoss'] < PreviousValidationLoss ):\n",
        "            PreviousValidationLoss = checkpointt['ValidationLoss']\n",
        "          global_counter+= 1\n",
        "        \n",
        "        #pdb.set_trace()\n",
        "        resumeExp=False\n",
        "\n",
        "\n",
        "#############################\n",
        "# PLOT TRAINING LOSS VS VALIDATION LOSS \n",
        "############################\n",
        "def plotLossTrend(train_losses,validation_losses,test_losses=[]):\n",
        "  #TRAINING LOSS DATA\n",
        "  values = []\n",
        "  labels = []\n",
        "  for item in train_losses:    \n",
        "    for key, value in item.items():\n",
        "      values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "\n",
        "\n",
        "  plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Training Loss')\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "  \n",
        "  plt.xticks(rotation=90)\n",
        "  #plt.show()\n",
        "\n",
        "  #VALIDATON LOSS\n",
        "  values = []\n",
        "  labels = []\n",
        "  for item in validation_losses:   \n",
        "    #pdb.set_trace() \n",
        "    for key, value in item.items():      \n",
        "      values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "\n",
        "\n",
        "  #plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Validation Loss')\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "  \n",
        "  plt.xticks(rotation=90)\n",
        "  #plt.show()\n",
        "\n",
        "  #TEST LOSS\n",
        "  values = []\n",
        "  labels = []\n",
        "  for item in test_losses:    \n",
        "    for key, value in item.items():\n",
        "      #pdb.set_trace()\n",
        "      values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "\n",
        "\n",
        "  #plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Test Loss')\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "  \n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()\n",
        "  #for i, v in enumerate(values):\n",
        "  #    ax.text(i, v+25, \"%d\" %v, ha=\"center\")\n",
        "  #plt.ylim(-10, 595)\n",
        "\n",
        "#############################\n",
        "# LOAD CHECKPOINT\n",
        "############################\n",
        "def load_checkpoint(OutputFolder,OutputFilePrefix,max_epoch,exact_epoch,load_model=True):\n",
        "    \n",
        "    file_epoch = 0\n",
        "    if(max_epoch):\n",
        "      for filename in os.listdir(OutputFolder):\n",
        "        data = filename.split('_')\n",
        "        tmp=int(data[1][:-3])\n",
        "        #print('data[1]',data[1],' tmp[:-3] ',tmp[:-3])\n",
        "        if( file_epoch <= tmp ):\n",
        "          file_epoch = tmp\n",
        "    else:\n",
        "      file_epoch=exact_epoch\n",
        "\n",
        "    filepath = OutputFolder+'/'+OutputFilePrefix + str(file_epoch)+'.pt'\n",
        "    print('Loading Checkpoint from '+filepath+'...')\n",
        "    indent=1\n",
        "    checkpoint = torch.load(filepath)\n",
        "    for key, value in checkpoint.items():\n",
        "        if(key == 'StateDictionay'):\n",
        "          continue\n",
        "        print('\\t' * indent + str(key),'\\t' * (indent+1) + str(value))\n",
        "        #print('\\t' * (indent+1) + str(value))\n",
        "    \n",
        "    testmodel = None\n",
        "\n",
        "    if(load_model):\n",
        "      testmodel = Network(checkpoint['InputSize'],\n",
        "                              checkpoint['OutputSize'],\n",
        "                              checkpoint['HiddenLayers'],\n",
        "                              checkpoint['OutputClasses'],\n",
        "                              checkpoint['Transforms'],\n",
        "                              checkpoint['Dataset'],\n",
        "                              checkpoint['DropRatio'],\n",
        "                              checkpoint['LearningRate'],\n",
        "                              train_on_gpu=checkpoint['GPUState']\n",
        "                      )\n",
        "      testmodel.load_state_dict(checkpoint['StateDictionay'])\n",
        "      \n",
        "    return testmodel , checkpoint , filepath\n",
        "\n",
        "\n",
        "def test_all_epochs(OutputFolder,test_loader,criterion,batch_size,OutputFilePrefix='checkpoint_'):\n",
        "\n",
        "    #OutputFolder = './results/'\n",
        "    file_epoch = 0\n",
        "    result_list=[]\n",
        "    print('Starting Test All Saved Epochs ....')\n",
        "    trainig_loss=[]\n",
        "    validation_loss=[]\n",
        "    test_loss=[]\n",
        "    ele = dict()\n",
        "\n",
        "    \"\"\"\n",
        "        for folder in os.listdir(OutputFolder):\n",
        "          for filename in os.listdir(OutputFolder+folder):\n",
        "            data = filename.split('_')\n",
        "            #pdb.set_trace()\n",
        "            print(data)\n",
        "            file_epoch=int(data[1][:-3])\n",
        "\n",
        "            model , checkpoint , filepath = load_checkpoint(OutputFolder+folder,OutputFilePrefix,False,file_epoch)\n",
        "    \"\"\"\n",
        "    #for filename in os.listdir(checkpointPath):\n",
        "    for root, dirs, files in os.walk(OutputFolder):\n",
        "      for filename in files:\n",
        "        model , checkpoint , filepath = load_checkpoint(root,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')],load_model=True)\n",
        "\n",
        "        checkpoint , checkpoint_test = test(model,test_loader,criterion,checkpoint,filepath,batch_size,False)\n",
        "\n",
        "        print('Test Accuracy ',checkpoint_test['Test Accuracy (Overall): '])\n",
        "        result_list.append(checkpoint_test)\n",
        "\n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint['TrainingLoss'])\n",
        "        key = checkpoint['Dataset'] + '_' + checkpoint['OutputFolder'] + '_' + str(checkpoint['LastEpoch'])\n",
        "        ele = {key: checkpoint['TrainingLoss']}\n",
        "        trainig_loss.append(ele)\n",
        "        \n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint['ValidationLoss'])\n",
        "        ele = {}\n",
        "        ele ={key: checkpoint['ValidationLoss']}\n",
        "        validation_loss.append(ele)\n",
        "\n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint_test['TestLoss'])\n",
        "        ele = {}\n",
        "        ele ={key: checkpoint_test['TestLoss']}\n",
        "        test_loss.append(ele)\n",
        "    \n",
        "    #print('Result List',result_list)\n",
        "    plotLossTrend (trainig_loss,validation_loss,test_loss)\n",
        "    return result_list\n",
        "      \n",
        "\n",
        "#############################\n",
        "# VISUALIZE ALL IMAGES IN BATCH\n",
        "############################\n",
        "def visualize_images_in_batch(loader,batch_size) :\n",
        "    # obtain one batch of training images\n",
        "\t\tdataiter = iter(loader)\n",
        "\t\timages, labels = dataiter.next()\n",
        "\t\timages = images.numpy()\n",
        "\n",
        "\t\t# plot the images in the batch, along with the corresponding labels\n",
        "\t\tfig = plt.figure(figsize=(25, 4))\n",
        "\t\tfor idx in np.arange(batch_size):\n",
        "\t\t\tax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
        "\t\t\tax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "\t\t\t# print out the correct label for each image\n",
        "\t\t\t# .item() gets the value contained in a Tensor\n",
        "\t\t\tax.set_title(str(labels[idx].item()))\n",
        "\t\treturn images\n",
        "\n",
        "\n",
        "#############################\n",
        "# VISUALIZE PIXEL OF AN IMAGE RETURN FROM PREV FUNCTION\n",
        "############################\n",
        "def visualize_image_pixels_value(image):\n",
        "\n",
        "  img = np.squeeze(image)\n",
        "  fig = plt.figure(figsize = (12,12)) \n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img, cmap='gray')\n",
        "  width, height = img.shape\n",
        "  thresh = img.max()/2.5\n",
        "  for x in range(width):\n",
        "      for y in range(height):\n",
        "          val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "          ax.annotate(str(val), xy=(y,x),\n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center',\n",
        "                      color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "def visualize_rgb_image_pixels_value(image):\n",
        "  rgb_img = np.squeeze(image)\n",
        "  channels = ['red channel', 'green channel', 'blue channel']\n",
        "\n",
        "  fig = plt.figure(figsize = (36, 36)) \n",
        "  for idx in np.arange(rgb_img.shape[0]):\n",
        "      ax = fig.add_subplot(1, 3, idx + 1)\n",
        "      img = rgb_img[idx]\n",
        "      ax.imshow(img, cmap='gray')\n",
        "      ax.set_title(channels[idx])\n",
        "      width, height = img.shape\n",
        "      thresh = img.max()/2.5\n",
        "      for x in range(width):\n",
        "          for y in range(height):\n",
        "              val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "              ax.annotate(str(val), xy=(y,x),\n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center', size=8,\n",
        "                      color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "def visualize_test_results(model,test_loader,batch_size,RGB=False):\n",
        "  # obtain one batch of test images\n",
        "  dataiter = iter(test_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images.numpy()\n",
        "\n",
        "  # move model inputs to cuda, if GPU available\n",
        "  if model.train_on_gpu:\n",
        "      images = images.cuda()\n",
        "\n",
        "  # Flatten images into a 784 long vector\n",
        "  images.resize_(images.size()[0], model.input_size)\n",
        "\n",
        "  # get sample outputs\n",
        "  output = model(images)\n",
        "  # convert output probabilities to predicted class\n",
        "  _, preds_tensor = torch.max(output, 1)\n",
        "  preds = np.squeeze(preds_tensor.numpy()) if not model.train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "  # plot the images in the batch, along with predicted and true labels\n",
        "  fig = plt.figure(figsize=(25, 4))\n",
        "  for idx in np.arange(batch_size):\n",
        "      ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
        "\n",
        "      image_cpu = images.cpu()[idx]\n",
        "      image_cpu = image_cpu / 2 + 0.5  # unnormalize\n",
        "      if(RGB):\n",
        "        plt.imshow(np.transpose(image_cpu, (1, 2, 0)))  # convert from Tensor image\n",
        "      else:\n",
        "        ax.imshow(np.squeeze(image_cpu), cmap='gray')\n",
        "\n",
        "      ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                  color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voDNqAjioodn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################# TEST TUNE NETWORK ####################################\n",
        "import sys\n",
        "\n",
        "\"\"\"\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\"\"\"\n",
        "def test_tune_train_network(dataset):    \n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "  #tune_train_network(resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "  #tune_train_network('MINST',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "\n",
        "  #load_last_exp_param('/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/3-6-2020.txt','/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "\n",
        "  #sys.path.append('./mydeeplearning/')\n",
        "  \n",
        "  #MINST\n",
        "  #cmd_str = \"from mydeeplearning.ez_mlp import*; tune_train_network(\"+dataset+\",10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/') 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt'\" \n",
        "  func_str = \"\\\"from mydeeplearning.ez_mlp import*; tune_train_network(\\'\"+dataset+\"\\',10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/all/')\\\"\" \n",
        "  log_path = \"'/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume.txt'\"\n",
        "\n",
        "\n",
        "  #CIFAR\n",
        "  #func_str = \"\\\"from mydeeplearning.ez_mlp import*; tune_train_network(\\'\"+dataset+\"\\',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/3-8-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/')\\\"\" \n",
        "  #log_path = \"'/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/3-8-2020.txt'\"\n",
        "\n",
        "  print(func_str)\n",
        "  print(log_path)\n",
        "\n",
        "  #!python -c \"from mydeeplearning.ez_mlp import*; tune_train_network('CIFAR',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/logs/3-8-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/06_Mar_2020_07_57_24/')\" 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/logs/3-8-2020.txt'\n",
        "  !python -c $func_str 2>&1 | tee -a $log_path\n",
        "\n",
        "\n",
        "  #!python -c $cmd_str\n",
        "\n",
        "  #!python -c \"from mydeeplearning.ez_mlp import*; tune_train_network(\"+dataset+\",10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/')\" -u /mydeeplearning/ez_mlp.py 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume-3-6-2020.txt' #2>&1\n",
        "  \n",
        "  \n",
        "\n",
        "  #load_last_exp_param('/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs','/content/gdrive/My Drive/Colab Notebooks/models/MINST/04_Mar_2020_20_13_34')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wXvRQ0zv5hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### TEST ALL EPOCHS ##############################\n",
        "def test_test_all_epochs():\n",
        "    \n",
        "\n",
        "  #model , checkpointtt , filepathh = load_checkpoint(checkpointttt['OutputFolder'],checkpointttt['OutputFilePrefix'],False,10)\n",
        "\n",
        "  #result_list = test_all_epochs(test_loader,criterion,batch_size)\n",
        "\n",
        "  dataset = 'MINST'\n",
        "\n",
        "\n",
        "  #How many samples loaded per batch\n",
        "  batch_size = 20\n",
        "  # percentage of training set to use as validation\n",
        "  valid_size = 0.2\n",
        "\n",
        "  #train_loader =None\n",
        "  #valid_loader =None\n",
        "  #Load Data\n",
        "  dataset = 'MINST'\n",
        "  train_loader , valid_loader ,test_loader , classes , transform = LoadData(dataset,batch_size,valid_size)\n",
        "\n",
        "\n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "  gfolder = '/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/'\n",
        "\n",
        "  localfolder = './results/'+dataset+'/'\n",
        "\n",
        "  result_list = test_all_epochs(gfolder,test_loader,nn.NLLLoss(),batch_size,OutputFilePrefix='checkpoint_')\n",
        "\n",
        "  #checkpoint = torch.load('/content/drive/My Drive/Colab Notebooks/models/minst/29_Feb_2020_20_06_50_74.pt')\n",
        "\n",
        "  #print(checkpoint)\n",
        "  #load_checkpoint('/gdrive/My Drive/Colab Notebooks/models/'+dataset,'29_Feb_2020_20_06_50',False,74)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu907NvWVlBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## TEST VISUALIZATION###################\n",
        "def test_visualize_images_in_batch():\n",
        "  images = visualize_images_in_batch(train_loader,batch_size)\n",
        "  visualize_image_pixels_value(images[2])\n",
        "\n",
        "  model , checkpointtt , filepathh = load_checkpoint(checkpointt['OutputFolder'],checkpointt['OutputFilePrefix'],True,0)\n",
        "\n",
        "  checkpointttt = test(model,test_loader,criterion,checkpointtt,filepathh,batch_size,True)\n",
        "\n",
        "  # obtain one batch of test images\n",
        "  dataiter = iter(test_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images.numpy()\n",
        "\n",
        "  #visualize_rgb_image_pixels_value(images[2])\n",
        "  #visualize_test_results(model,test_loader,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbNJdUIMSTBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "#import helper.py\n",
        "import imp \n",
        "\n",
        "\n",
        "################################\n",
        "# INIT GITHUB\n",
        "#######################################\n",
        "def init_github():\n",
        "  \"\"\"\n",
        "  !git init\n",
        "  !git config  global user.email ice.man011@gmail.com\n",
        "  !git config  global user.name iceman011\n",
        "  !git add -A\n",
        "  !git commit -m first commit\n",
        "  !git remote add origin https://<username>:<password>github@github.com/iceman011/mydeeplearning.git\n",
        "  !git push -u origin master\n",
        "  \"\"\"\n",
        "  #!git clone -l -s git://github.com/iceman011/mydeeplearning.git #mydeeplearning-repo\n",
        "  #!git clone -l -s https://github.com/iceman011@github.com/mydeeplearning.git\n",
        "\n",
        "  #%cd mydeeplearning-repo\n",
        "  #!ls\n",
        "\n",
        "  # path to your project on Google Drive\n",
        "  #MY_GOOGLE_DRIVE_PATH = 'My Drive/MyDrive/Udacity/deep-learning-v2-pytorch' \n",
        "  # replace with your Github username \n",
        "  GIT_USERNAME = \"iceman011\" \n",
        "  # definitely replace with your\n",
        "  GIT_TOKEN = \"1aeb0c6f424e3c604988a3a636f74c6e5180cd89\"  \n",
        "  # Replace with your github repository in this case we want \n",
        "  # to clone deep-learning-v2-pytorch repository\n",
        "  GIT_REPOSITORY = \"mydeeplearning\" \n",
        "\n",
        "  # REMOVE IT BEFORE INIT\n",
        "  if( os.path.isdir('./'+GIT_REPOSITORY) ):\n",
        "    shutil.rmtree('./'+GIT_REPOSITORY)\n",
        "\n",
        "  #PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "  # It's good to print out the value if you are not sure \n",
        "  #print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "  # In case we haven't created the folder already; we will create a folder in the project path \n",
        "  #!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "  #GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "\n",
        "  GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "  print(\"GIT_PATH: \", GIT_PATH)\n",
        "\n",
        "  !git clone \"{GIT_PATH}\" # clone the github repository\n",
        "\n",
        "############################3\n",
        "# CONVERT FROM COLAB INTO PYTHON\n",
        "#############################3\n",
        "def from_colab_to_python():\n",
        "\n",
        "  !pip install ipython\n",
        "  !pip install nbconvert\n",
        "  !ipython nbconvert --to python ./mydeeplearning/ez_mlp.ipynb\n",
        "\n",
        "  #helper = imp.new_module('ez-mlp')\n",
        "  #exec(open('./'+GIT_REPOSITORY+\"/ez-mlp.py\").read(), helper.__dict__)\n",
        "\n",
        "\n",
        "######################################\n",
        "# PUSH CHANGES TO GITHUB\n",
        "##################################\n",
        "def push_github():\n",
        "  !git add -u\n",
        "  !git commit -m \"new commit\"\n",
        "  !git push mydeeplearning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7of0_y_zsQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "######################    \n",
        "# MAIN #\n",
        "######################\n",
        "def mainn():\n",
        "\n",
        "  # Create the network, define the criterion and optimizer\n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "  dataset = 'MINST'\n",
        "\n",
        "  init_github()\n",
        "  from_colab_to_python()\n",
        "  test_tune_train_network(dataset)\n",
        "\n",
        "  #CONTINUE FROM PREVIOUS MODEL\n",
        "  #model , checkpoint , filepath = load_checkpoint('/content/drive/My Drive/Colab Notebooks/models/MINST/01_Mar_2020_18_42_35','checkpoint_',True,0)\n",
        "  #PreviousCheckPointId = checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch'])\n",
        "  #PreviousValidationLoss= checkpoint['ValidationLoss'] #np.Inf\n",
        "\n",
        "  #model = Network(784, 10, [512, 256, 128 , 64 ],classes,transform,dataset, lr=0.001,train_on_gpu=True)\n",
        "\n",
        "  #criterion = nn.NLLLoss()\n",
        "  #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  #checkpointPath = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'\n",
        "  #checkpointPath = f'./results/'+dataset+'/'\n",
        "\n",
        "\n",
        "\n",
        "  #Upload checkpoint to local drive\n",
        "  #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, False,checkpointPath,PreviousCheckPointId,PreviousValidationLoss,epochs=100)\n",
        "\n",
        "  #Upload to gDrive\n",
        "  #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, True,checkpointPath,'',np.Inf,epochs=10)\n",
        "\n",
        "  #plotLossTrend (train_lossess , valid_lossess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mp5Be63OjI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e83d4722-2e16-44c9-bbb1-a8129a079e02"
      },
      "source": [
        "mainn()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/gdrive\n",
            "GIT_PATH:  https://1aeb0c6f424e3c604988a3a636f74c6e5180cd89@github.com/iceman011/mydeeplearning.git\n",
            "Cloning into 'mydeeplearning'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 152 (delta 67), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (152/152), 755.15 KiB | 2.55 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython) (4.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (45.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython) (0.1.8)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.6.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.11.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.0.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (4.4.1)\n",
            "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
            "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
            "[NbConvertApp] Converting notebook ./mydeeplearning/ez_mlp.ipynb to python\n",
            "[NbConvertApp] Writing 43582 bytes to ./mydeeplearning/ez_mlp.py\n",
            "Mounted at /content/gdrive\n",
            "\"from mydeeplearning.ez_mlp import*; tune_train_network('MINST',10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/all/')\"\n",
            "'/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume.txt'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
            "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n",
            "9920512it [00:01, 9035609.89it/s]                             \n",
            "32768it [00:00, 114015.78it/s]           \n",
            "1654784it [00:00, 2287253.82it/s]                            \n",
            "8192it [00:00, 69639.41it/s]            Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "12_Mar_2020_14_51_32 : Resuming Experiment With New ID  12_Mar_2020_14_51_30\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_14_16_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t20.977743203709522\n",
            "\tValidationLoss \t\t2.313524465560913\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t41.749404191970825\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_14_16\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[20.977743203709522]\n",
            "\tValidationLosses \t\t[2.313524465560913]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_14_46_1.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11590311275422573\n",
            "\tValidationLoss \t\t2.3115229586760204\n",
            "\tValidationAccuracy \t\ttensor(10.1750)\n",
            "\tElapsedTime \t\t71.41641139984131\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t1\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_14_46\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[20.977743203709522, 0.11590311275422573]\n",
            "\tValidationLosses \t\t[2.313524465560913, 2.3115229586760204]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_15_15_2.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.1158978755325079\n",
            "\tValidationLoss \t\t2.3063833125432334\n",
            "\tValidationAccuracy \t\ttensor(10.4083)\n",
            "\tElapsedTime \t\t101.25275611877441\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t2\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_15_15\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[20.977743203709522, 0.11590311275422573, 0.1158978755325079]\n",
            "\tValidationLosses \t\t[2.313524465560913, 2.3115229586760204, 2.3063833125432334]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_25_05_2.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.3\n",
            "\tTrainingLoss \t\t0.11583339028060437\n",
            "\tValidationLoss \t\t2.306087704102198\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t691.1725616455078\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t2\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_25_05\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[281.5077789706091, 0.11579228625694911, 0.11583339028060437]\n",
            "\tValidationLosses \t\t[2.3158168717225394, 2.315196233590444, 2.306087704102198]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_33_53_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.01\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11912868322432041\n",
            "\tValidationLoss \t\t2.301278197367986\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t1218.9278683662415\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_33_53\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11912868322432041]\n",
            "\tValidationLosses \t\t[2.301278197367986]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_34_51_2.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.01\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11515133934219678\n",
            "\tValidationLoss \t\t2.300851330757141\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t1276.9346287250519\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t2\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_34_51\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11912868322432041, 0.11514817476272583, 0.11515133934219678]\n",
            "\tValidationLosses \t\t[2.301278197367986, 2.3015719799200696, 2.300851330757141]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_53_31_1.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.1150956140657266\n",
            "\tValidationLoss \t\t2.300832857290904\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t2396.4296135902405\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t1\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_53_31\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11536191315452257, 0.1150956140657266]\n",
            "\tValidationLosses \t\t[2.3014506928126015, 2.300832857290904]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_20_59_43_4.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11508187551796437\n",
            "\tValidationLoss \t\t2.3008144863446556\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t2768.5276823043823\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t4\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_20_59_43\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.1151658234645923, 0.11508367783327897, 0.11508282598853112, 0.11508216535051664, 0.11508187551796437]\n",
            "\tValidationLosses \t\t[2.301037000815074, 2.301236010789871, 2.3010030853748322, 2.300855881770452, 2.3008144863446556]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_21_05_27_6.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.3\n",
            "\tTrainingLoss \t\t0.11507549087703228\n",
            "\tValidationLoss \t\t2.300806434949239\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t3112.7151877880096\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t6\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_21_05_27\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11511238146324952, 0.11508220896124839, 0.11508225373923779, 0.11508028693993887, 0.11507841654618581, 0.11507487197220326, 0.11507549087703228]\n",
            "\tValidationLosses \t\t[2.3013989722728727, 2.300894759496053, 2.3010033023357392, 2.30092342098554, 2.300829785267512, 2.3008612902959187, 2.300806434949239]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/04_Mar_2020_20_13_34/checkpoint_04_Mar_2020_21_06_24_8.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.3\n",
            "\tTrainingLoss \t\t0.11507420448462169\n",
            "\tValidationLoss \t\t2.3007216640313466\n",
            "\tValidationAccuracy \t\ttensor(11.4000)\n",
            "\tElapsedTime \t\t3169.854605436325\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t8\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t04_Mar_2020_20_13_34\n",
            "\tCheckPointTimestamp \t\t04_Mar_2020_21_06_24\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11511238146324952, 0.11508220896124839, 0.11508225373923779, 0.11508028693993887, 0.11507841654618581, 0.11507487197220326, 0.11507549087703228, 0.11507090218365193, 0.11507420448462169]\n",
            "\tValidationLosses \t\t[2.3013989722728727, 2.300894759496053, 2.3010033023357392, 2.30092342098554, 2.300829785267512, 2.3008612902959187, 2.300806434949239, 2.301010252634684, 2.3007216640313466]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/05_Mar_2020_17_58_54/checkpoint_05_Mar_2020_17_59_46_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t13.874534028187394\n",
            "\tValidationLoss \t\t2.3078386274973552\n",
            "\tValidationAccuracy \t\ttensor(10.0250)\n",
            "\tElapsedTime \t\t51.979976415634155\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t05_Mar_2020_17_58_54\n",
            "\tCheckPointTimestamp \t\t05_Mar_2020_17_59_46\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[13.874534028187394]\n",
            "\tValidationLosses \t\t[2.3078386274973552]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_54_39/checkpoint_06_Mar_2020_07_55_13_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t19.242717800756296\n",
            "\tValidationLoss \t\t2.3120368576049803\n",
            "\tValidationAccuracy \t\ttensor(10.3833)\n",
            "\tElapsedTime \t\t33.455825328826904\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_54_39\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_07_55_13\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[19.242717800756296]\n",
            "\tValidationLosses \t\t[2.3120368576049803]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_54_39/checkpoint_06_Mar_2020_07_56_44_3.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.1159083252598842\n",
            "\tValidationLoss \t\t2.309082218805949\n",
            "\tValidationAccuracy \t\ttensor(9.8166)\n",
            "\tElapsedTime \t\t124.79307007789612\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t3\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_54_39\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_07_56_44\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[19.242717800756296, 0.11581980217496554, 0.11588552070657412, 0.1159083252598842]\n",
            "\tValidationLosses \t\t[2.3120368576049803, 2.3197654072443643, 2.3206359187761945, 2.309082218805949]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_07_57_57_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.1\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t25.76125770568351\n",
            "\tValidationLoss \t\t2.306779959599177\n",
            "\tValidationAccuracy \t\ttensor(9.9417)\n",
            "\tElapsedTime \t\t33.66304087638855\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_07_57_57\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[25.76125770568351]\n",
            "\tValidationLosses \t\t[2.306779959599177]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_08_00_00_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.01\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11934958743552367\n",
            "\tValidationLoss \t\t2.302425160010656\n",
            "\tValidationAccuracy \t\ttensor(10.3750)\n",
            "\tElapsedTime \t\t156.75316905975342\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_08_00_00\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11934958743552367]\n",
            "\tValidationLosses \t\t[2.302425160010656]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_08_02_04_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.1153421110411485\n",
            "\tValidationLoss \t\t2.3012513740857443\n",
            "\tValidationAccuracy \t\ttensor(11.3917)\n",
            "\tElapsedTime \t\t280.2341685295105\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_08_02_04\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.1153421110411485]\n",
            "\tValidationLosses \t\t[2.3012513740857443]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_08_03_05_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.3\n",
            "\tTrainingLoss \t\t0.11511734959979852\n",
            "\tValidationLoss \t\t2.301214106082916\n",
            "\tValidationAccuracy \t\ttensor(11.3917)\n",
            "\tElapsedTime \t\t341.5318179130554\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_08_03_05\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11511734959979852]\n",
            "\tValidationLosses \t\t[2.301214106082916]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_08_03_36_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.1\n",
            "\tTrainingLoss \t\t0.11510088475545248\n",
            "\tValidationLoss \t\t2.301190451780955\n",
            "\tValidationAccuracy \t\ttensor(11.3917)\n",
            "\tElapsedTime \t\t372.1698338985443\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_08_03_36\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11510088475545248]\n",
            "\tValidationLosses \t\t[2.301190451780955]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_06_Mar_2020_08_05_38_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 1024]\n",
            "\tLearningRate \t\t0.001\n",
            "\tDropRatio \t\t0.1\n",
            "\tTrainingLoss \t\t0.11509947038690249\n",
            "\tValidationLoss \t\t2.3011662662029266\n",
            "\tValidationAccuracy \t\ttensor(11.3917)\n",
            "\tElapsedTime \t\t494.0928854942322\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t06_Mar_2020_07_57_24\n",
            "\tCheckPointTimestamp \t\t06_Mar_2020_08_05_38\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11509947038690249]\n",
            "\tValidationLosses \t\t[2.3011662662029266]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_07_Mar_2020_09_41_02_1.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.01\n",
            "\tDropRatio \t\t0.1\n",
            "\tTrainingLoss \t\t0.11514954202373823\n",
            "\tValidationLoss \t\t2.3011316565672555\n",
            "\tValidationAccuracy \t\ttensor(11.2333)\n",
            "\tElapsedTime \t\t57.15238881111145\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t1\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_40_05\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_09_41_02\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.1260872092942397, 0.11514954202373823]\n",
            "\tValidationLosses \t\t[2.30335329413414, 2.3011316565672555]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/checkpoint_07_Mar_2020_09_54_44_2.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11507290008167426\n",
            "\tValidationLoss \t\t2.301096880833308\n",
            "\tValidationAccuracy \t\ttensor(11.2333)\n",
            "\tElapsedTime \t\t879.6431925296783\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t2\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_40_05\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_09_54_44\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.115144493902723, 0.11507457349697749, 0.11507290008167426]\n",
            "\tValidationLosses \t\t[2.301135915915171, 2.3013081534703574, 2.301096880833308]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/07_Mar_2020_09_58_57/checkpoint_07_Mar_2020_10_04_17_1.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11508879185716311\n",
            "\tValidationLoss \t\t2.3010568388303123\n",
            "\tValidationAccuracy \t\ttensor(11.5333)\n",
            "\tElapsedTime \t\t320.57190561294556\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t1\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_58_57\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_10_04_17\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11538717292745908, 0.11508879185716311]\n",
            "\tValidationLosses \t\t[2.301528647343318, 2.3010568388303123]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/07_Mar_2020_09_58_57/checkpoint_07_Mar_2020_10_07_49_9.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11507154820362726\n",
            "\tValidationLoss \t\t2.3010536726315816\n",
            "\tValidationAccuracy \t\ttensor(11.5333)\n",
            "\tElapsedTime \t\t532.6445009708405\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t9\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_58_57\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_10_07_49\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11538717292745908, 0.11508879185716311, 0.11509019969403744, 0.11509061993161837, 0.11509118069211642, 0.11509961046775181, 0.11507301930089792, 0.11507826224962871, 0.11508845796684423, 0.11507154820362726]\n",
            "\tValidationLosses \t\t[2.301528647343318, 2.3010568388303123, 2.301455497741699, 2.3011225871245067, 2.3013400304317475, 2.3013796178499857, 2.3011358761787415, 2.30127081712087, 2.301152486403783, 2.3010536726315816]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/07_Mar_2020_09_58_57/checkpoint_07_Mar_2020_10_11_50_8.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11506870467960835\n",
            "\tValidationLoss \t\t2.30102055589358\n",
            "\tValidationAccuracy \t\ttensor(11.5333)\n",
            "\tElapsedTime \t\t773.3333265781403\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t8\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_58_57\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_10_11_50\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11514368245999018, 0.11508080213765304, 0.11507484171787898, 0.11507781574626763, 0.11507756092151006, 0.11507819091777007, 0.1150748208463192, 0.11507202955087026, 0.11506870467960835]\n",
            "\tValidationLosses \t\t[2.30144775390625, 2.3013516223430632, 2.301413631439209, 2.3011373960971833, 2.3012535536289214, 2.3012785947322847, 2.3013112103939055, 2.301148924827576, 2.30102055589358]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/07_Mar_2020_09_58_57/checkpoint_07_Mar_2020_10_14_05_3.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 512]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.3\n",
            "\tTrainingLoss \t\t0.11507319716612498\n",
            "\tValidationLoss \t\t2.3009991105397543\n",
            "\tValidationAccuracy \t\ttensor(11.5333)\n",
            "\tElapsedTime \t\t907.9653749465942\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t3\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t07_Mar_2020_09_58_57\n",
            "\tCheckPointTimestamp \t\t07_Mar_2020_10_14_05\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11512529721856117, 0.11507846306761106, 0.11507514945665995, 0.11507319716612498]\n",
            "\tValidationLosses \t\t[2.3017901225884754, 2.3014088888963062, 2.301205315589905, 2.3009991105397543]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_17_53_18/checkpoint_08_Mar_2020_18_38_20_4.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11507978646953901\n",
            "\tValidationLoss \t\t2.3009497197469075\n",
            "\tValidationAccuracy \t\ttensor(11.4250)\n",
            "\tElapsedTime \t\t0:45:01.736092\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t4\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_17_53_18\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_18_38_20\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11540549431741237, 0.11510577751696109, 0.11509671521683534, 0.11508872573077679, 0.11507978646953901]\n",
            "\tValidationLosses \t\t[2.3018471074104307, 2.301228897571564, 2.301109787225723, 2.301007336775462, 2.3009497197469075]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_17_53_18/checkpoint_08_Mar_2020_18_39_02_5.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11507149637242159\n",
            "\tValidationLoss \t\t2.3009447610378264\n",
            "\tValidationAccuracy \t\ttensor(11.4250)\n",
            "\tElapsedTime \t\t0:45:43.140323\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t5\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_17_53_18\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_18_39_02\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11540549431741237, 0.11510577751696109, 0.11509671521683534, 0.11508872573077679, 0.11507978646953901, 0.11507149637242159]\n",
            "\tValidationLosses \t\t[2.3018471074104307, 2.301228897571564, 2.301109787225723, 2.301007336775462, 2.3009497197469075, 2.3009447610378264]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_17_53_18/checkpoint_08_Mar_2020_18_46_35_6.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11510007476806641\n",
            "\tValidationLoss \t\t2.300929999748866\n",
            "\tValidationAccuracy \t\ttensor(11.4250)\n",
            "\tElapsedTime \t\t0:53:16.225477\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t6\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_17_53_18\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_18_46_35\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11534030141929785, 0.11520791622499625, 0.11512308167914549, 0.11512999221682549, 0.11509456015129885, 0.11509338976442814, 0.11510007476806641]\n",
            "\tValidationLosses \t\t[2.303494987487793, 2.3017048915227254, 2.3009752074877423, 2.3010841902097066, 2.301273048321406, 2.3009478052457175, 2.300929999748866]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_31_58_0.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11509772455692291\n",
            "\tValidationLoss \t\t2.3006331849098207\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:00:51.700213\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_31_58\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11509772455692291]\n",
            "\tValidationLosses \t\t[2.3006331849098207]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_32_45_2.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11509295508265495\n",
            "\tValidationLoss \t\t2.3004842682679496\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:01:38.190367\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t2\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_32_45\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11509772455692291, 0.11509680426120758, 0.11509295508265495]\n",
            "\tValidationLosses \t\t[2.3006331849098207, 2.3006836251417795, 2.3004842682679496]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_33_54_5.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11508566900591055\n",
            "\tValidationLoss \t\t2.300455356836319\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:02:47.546700\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t5\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_33_54\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11509772455692291, 0.11509680426120758, 0.11509295508265495, 0.11509381775557995, 0.11508415538569292, 0.11508566900591055]\n",
            "\tValidationLosses \t\t[2.3006331849098207, 2.3006836251417795, 2.3004842682679496, 2.300719017982483, 2.3004879438877106, 2.300455356836319]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_37_47_5.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11507850277423859\n",
            "\tValidationLoss \t\t2.3004255441824597\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:06:40.288010\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t5\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_37_47\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11508050655325254, 0.11507943020761013, 0.11508011728525162, 0.11507630161444346, 0.1150815849105517, 0.11507850277423859]\n",
            "\tValidationLosses \t\t[2.3005482856432597, 2.3005296965440114, 2.3005069371064506, 2.300602573553721, 2.300498387813568, 2.3004255441824597]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_38_11_6.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t0.5\n",
            "\tTrainingLoss \t\t0.11506878552337488\n",
            "\tValidationLoss \t\t2.300424952507019\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:07:03.889380\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t6\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_38_11\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11508050655325254, 0.11507943020761013, 0.11508011728525162, 0.11507630161444346, 0.1150815849105517, 0.11507850277423859, 0.11506878552337488]\n",
            "\tValidationLosses \t\t[2.3005482856432597, 2.3005296965440114, 2.3005069371064506, 2.300602573553721, 2.300498387813568, 2.3004255441824597, 2.300424952507019]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_40_08_1.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11508705192804336\n",
            "\tValidationLoss \t\t2.300394515991211\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:09:00.712669\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t1\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_40_08\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11536910290022691, 0.11508705192804336]\n",
            "\tValidationLosses \t\t[2.3005114909013114, 2.300394515991211]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_41_18_4.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.1150842467546463\n",
            "\tValidationLoss \t\t2.300310746828715\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:10:11.018901\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t4\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_41_18\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11536910290022691, 0.11508705192804336, 0.11509626411398252, 0.11509078412254652, 0.1150842467546463]\n",
            "\tValidationLosses \t\t[2.3005114909013114, 2.300394515991211, 2.300619271993637, 2.3005396370093028, 2.300310746828715]\n",
            "CUDA is available!  Using GPU ...\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/MINST/all/06_Mar_2020_07_57_24/08_Mar_2020_20_31_07/checkpoint_08_Mar_2020_20_42_52_8.pt...\n",
            "\tInputSize \t\t784\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\t[1024, 1024, 1024, 32]\n",
            "\tLearningRate \t\t0.001\n",
            "\tDropRatio \t\t0.8\n",
            "\tTrainingLoss \t\t0.11508324266970157\n",
            "\tValidationLoss \t\t2.3002626490592957\n",
            "\tValidationAccuracy \t\ttensor(11.6417)\n",
            "\tElapsedTime \t\t0:11:45.423925\n",
            "\tDataset \t\tMINST\n",
            "\tLastEpoch \t\t8\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t08_Mar_2020_20_31_07\n",
            "\tCheckPointTimestamp \t\t08_Mar_2020_20_42_52\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
            "\tTransforms \t\tCompose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\tTrainingLosses \t\t[0.11536910290022691, 0.11508705192804336, 0.11509626411398252, 0.11509078412254652, 0.1150842467546463, 0.11508417503535748, 0.11508327387770018, 0.11508219531178475, 0.11508324266970157]\n",
            "\tValidationLosses \t\t[2.3005114909013114, 2.300394515991211, 2.300619271993637, 2.3005396370093028, 2.300310746828715, 2.300451920032501, 2.3004555130004882, 2.30043932000796, 2.3002626490592957]\n",
            "CUDA is available!  Using GPU ...\n",
            " Not Found Matching Checkpoint with Last Experiement Parameters hidden_layers:4  hidden_layer_width: (1024, 1024, 512, 64)  Learning_rate:0.001 drop_ratio:0.1 \n",
            "Resume ValidationLoss  2.3002626490592957 Resume Learning Rate Array  [0.001]  Resume Drop Ratio List  [0.1]  Resume Hidden Nodes List  [(1024, 1024, 512, 64), (1024, 1024, 512, 32), (1024, 1024, 256, 2048), (1024, 1024, 256, 1024), (1024, 1024, 256, 512), (1024, 1024, 256, 256), (1024, 1024, 256, 128), (1024, 1024, 256, 64), (1024, 1024, 256, 32), (1024, 1024, 128, 2048), (1024, 1024, 128, 1024), (1024, 1024, 128, 512), (1024, 1024, 128, 256), (1024, 1024, 128, 128), (1024, 1024, 128, 64), (1024, 1024, 128, 32), (1024, 1024, 64, 2048), (1024, 1024, 64, 1024), (1024, 1024, 64, 512), (1024, 1024, 64, 256), (1024, 1024, 64, 128), (1024, 1024, 64, 64), (1024, 1024, 64, 32), (1024, 1024, 32, 2048), (1024, 1024, 32, 1024), (1024, 1024, 32, 512), (1024, 1024, 32, 256), (1024, 1024, 32, 128), (1024, 1024, 32, 64), (1024, 1024, 32, 32), (1024, 512, 2048, 2048), (1024, 512, 2048, 1024), (1024, 512, 2048, 512), (1024, 512, 2048, 256), (1024, 512, 2048, 128), (1024, 512, 2048, 64), (1024, 512, 2048, 32), (1024, 512, 1024, 2048), (1024, 512, 1024, 1024), (1024, 512, 1024, 512), (1024, 512, 1024, 256), (1024, 512, 1024, 128), (1024, 512, 1024, 64), (1024, 512, 1024, 32), (1024, 512, 512, 2048), (1024, 512, 512, 1024), (1024, 512, 512, 512), (1024, 512, 512, 256), (1024, 512, 512, 128), (1024, 512, 512, 64), (1024, 512, 512, 32), (1024, 512, 256, 2048), (1024, 512, 256, 1024), (1024, 512, 256, 512), (1024, 512, 256, 256), (1024, 512, 256, 128), (1024, 512, 256, 64), (1024, 512, 256, 32), (1024, 512, 128, 2048), (1024, 512, 128, 1024), (1024, 512, 128, 512), (1024, 512, 128, 256), (1024, 512, 128, 128), (1024, 512, 128, 64), (1024, 512, 128, 32), (1024, 512, 64, 2048), (1024, 512, 64, 1024), (1024, 512, 64, 512), (1024, 512, 64, 256), (1024, 512, 64, 128), (1024, 512, 64, 64), (1024, 512, 64, 32), (1024, 512, 32, 2048), (1024, 512, 32, 1024), (1024, 512, 32, 512), (1024, 512, 32, 256), (1024, 512, 32, 128), (1024, 512, 32, 64), (1024, 512, 32, 32), (1024, 256, 2048, 2048), (1024, 256, 2048, 1024), (1024, 256, 2048, 512), (1024, 256, 2048, 256), (1024, 256, 2048, 128), (1024, 256, 2048, 64), (1024, 256, 2048, 32), (1024, 256, 1024, 2048), (1024, 256, 1024, 1024), (1024, 256, 1024, 512), (1024, 256, 1024, 256), (1024, 256, 1024, 128), (1024, 256, 1024, 64), (1024, 256, 1024, 32), (1024, 256, 512, 2048), (1024, 256, 512, 1024), (1024, 256, 512, 512), (1024, 256, 512, 256), (1024, 256, 512, 128), (1024, 256, 512, 64), (1024, 256, 512, 32), (1024, 256, 256, 2048), (1024, 256, 256, 1024), (1024, 256, 256, 512), (1024, 256, 256, 256), (1024, 256, 256, 128), (1024, 256, 256, 64), (1024, 256, 256, 32), (1024, 256, 128, 2048), (1024, 256, 128, 1024), (1024, 256, 128, 512), (1024, 256, 128, 256), (1024, 256, 128, 128), (1024, 256, 128, 64), (1024, 256, 128, 32), (1024, 256, 64, 2048), (1024, 256, 64, 1024), (1024, 256, 64, 512), (1024, 256, 64, 256), (1024, 256, 64, 128), (1024, 256, 64, 64), (1024, 256, 64, 32), (1024, 256, 32, 2048), (1024, 256, 32, 1024), (1024, 256, 32, 512), (1024, 256, 32, 256), (1024, 256, 32, 128), (1024, 256, 32, 64), (1024, 256, 32, 32), (1024, 128, 2048, 2048), (1024, 128, 2048, 1024), (1024, 128, 2048, 512), (1024, 128, 2048, 256), (1024, 128, 2048, 128), (1024, 128, 2048, 64), (1024, 128, 2048, 32), (1024, 128, 1024, 2048), (1024, 128, 1024, 1024), (1024, 128, 1024, 512), (1024, 128, 1024, 256), (1024, 128, 1024, 128), (1024, 128, 1024, 64), (1024, 128, 1024, 32), (1024, 128, 512, 2048), (1024, 128, 512, 1024), (1024, 128, 512, 512), (1024, 128, 512, 256), (1024, 128, 512, 128), (1024, 128, 512, 64), (1024, 128, 512, 32), (1024, 128, 256, 2048), (1024, 128, 256, 1024), (1024, 128, 256, 512), (1024, 128, 256, 256), (1024, 128, 256, 128), (1024, 128, 256, 64), (1024, 128, 256, 32), (1024, 128, 128, 2048), (1024, 128, 128, 1024), (1024, 128, 128, 512), (1024, 128, 128, 256), (1024, 128, 128, 128), (1024, 128, 128, 64), (1024, 128, 128, 32), (1024, 128, 64, 2048), (1024, 128, 64, 1024), (1024, 128, 64, 512), (1024, 128, 64, 256), (1024, 128, 64, 128), (1024, 128, 64, 64), (1024, 128, 64, 32), (1024, 128, 32, 2048), (1024, 128, 32, 1024), (1024, 128, 32, 512), (1024, 128, 32, 256), (1024, 128, 32, 128), (1024, 128, 32, 64), (1024, 128, 32, 32), (1024, 64, 2048, 2048), (1024, 64, 2048, 1024), (1024, 64, 2048, 512), (1024, 64, 2048, 256), (1024, 64, 2048, 128), (1024, 64, 2048, 64), (1024, 64, 2048, 32), (1024, 64, 1024, 2048), (1024, 64, 1024, 1024), (1024, 64, 1024, 512), (1024, 64, 1024, 256), (1024, 64, 1024, 128), (1024, 64, 1024, 64), (1024, 64, 1024, 32), (1024, 64, 512, 2048), (1024, 64, 512, 1024), (1024, 64, 512, 512), (1024, 64, 512, 256), (1024, 64, 512, 128), (1024, 64, 512, 64), (1024, 64, 512, 32), (1024, 64, 256, 2048), (1024, 64, 256, 1024), (1024, 64, 256, 512), (1024, 64, 256, 256), (1024, 64, 256, 128), (1024, 64, 256, 64), (1024, 64, 256, 32), (1024, 64, 128, 2048), (1024, 64, 128, 1024), (1024, 64, 128, 512), (1024, 64, 128, 256), (1024, 64, 128, 128), (1024, 64, 128, 64), (1024, 64, 128, 32), (1024, 64, 64, 2048), (1024, 64, 64, 1024), (1024, 64, 64, 512), (1024, 64, 64, 256), (1024, 64, 64, 128), (1024, 64, 64, 64), (1024, 64, 64, 32), (1024, 64, 32, 2048), (1024, 64, 32, 1024), (1024, 64, 32, 512), (1024, 64, 32, 256), (1024, 64, 32, 128), (1024, 64, 32, 64), (1024, 64, 32, 32), (1024, 32, 2048, 2048), (1024, 32, 2048, 1024), (1024, 32, 2048, 512), (1024, 32, 2048, 256), (1024, 32, 2048, 128), (1024, 32, 2048, 64), (1024, 32, 2048, 32), (1024, 32, 1024, 2048), (1024, 32, 1024, 1024), (1024, 32, 1024, 512), (1024, 32, 1024, 256), (1024, 32, 1024, 128), (1024, 32, 1024, 64), (1024, 32, 1024, 32), (1024, 32, 512, 2048), (1024, 32, 512, 1024), (1024, 32, 512, 512), (1024, 32, 512, 256), (1024, 32, 512, 128), (1024, 32, 512, 64), (1024, 32, 512, 32), (1024, 32, 256, 2048), (1024, 32, 256, 1024), (1024, 32, 256, 512), (1024, 32, 256, 256), (1024, 32, 256, 128), (1024, 32, 256, 64), (1024, 32, 256, 32), (1024, 32, 128, 2048), (1024, 32, 128, 1024), (1024, 32, 128, 512), (1024, 32, 128, 256), (1024, 32, 128, 128), (1024, 32, 128, 64), (1024, 32, 128, 32), (1024, 32, 64, 2048), (1024, 32, 64, 1024), (1024, 32, 64, 512), (1024, 32, 64, 256), (1024, 32, 64, 128), (1024, 32, 64, 64), (1024, 32, 64, 32), (1024, 32, 32, 2048), (1024, 32, 32, 1024), (1024, 32, 32, 512), (1024, 32, 32, 256), (1024, 32, 32, 128), (1024, 32, 32, 64), (1024, 32, 32, 32), (512, 2048, 2048, 2048), (512, 2048, 2048, 1024), (512, 2048, 2048, 512), (512, 2048, 2048, 256), (512, 2048, 2048, 128), (512, 2048, 2048, 64), (512, 2048, 2048, 32), (512, 2048, 1024, 2048), (512, 2048, 1024, 1024), (512, 2048, 1024, 512), (512, 2048, 1024, 256), (512, 2048, 1024, 128), (512, 2048, 1024, 64), (512, 2048, 1024, 32), (512, 2048, 512, 2048), (512, 2048, 512, 1024), (512, 2048, 512, 512), (512, 2048, 512, 256), (512, 2048, 512, 128), (512, 2048, 512, 64), (512, 2048, 512, 32), (512, 2048, 256, 2048), (512, 2048, 256, 1024), (512, 2048, 256, 512), (512, 2048, 256, 256), (512, 2048, 256, 128), (512, 2048, 256, 64), (512, 2048, 256, 32), (512, 2048, 128, 2048), (512, 2048, 128, 1024), (512, 2048, 128, 512), (512, 2048, 128, 256), (512, 2048, 128, 128), (512, 2048, 128, 64), (512, 2048, 128, 32), (512, 2048, 64, 2048), (512, 2048, 64, 1024), (512, 2048, 64, 512), (512, 2048, 64, 256), (512, 2048, 64, 128), (512, 2048, 64, 64), (512, 2048, 64, 32), (512, 2048, 32, 2048), (512, 2048, 32, 1024), (512, 2048, 32, 512), (512, 2048, 32, 256), (512, 2048, 32, 128), (512, 2048, 32, 64), (512, 2048, 32, 32), (512, 1024, 2048, 2048), (512, 1024, 2048, 1024), (512, 1024, 2048, 512), (512, 1024, 2048, 256), (512, 1024, 2048, 128), (512, 1024, 2048, 64), (512, 1024, 2048, 32), (512, 1024, 1024, 2048), (512, 1024, 1024, 1024), (512, 1024, 1024, 512), (512, 1024, 1024, 256), (512, 1024, 1024, 128), (512, 1024, 1024, 64), (512, 1024, 1024, 32), (512, 1024, 512, 2048), (512, 1024, 512, 1024), (512, 1024, 512, 512), (512, 1024, 512, 256), (512, 1024, 512, 128), (512, 1024, 512, 64), (512, 1024, 512, 32), (512, 1024, 256, 2048), (512, 1024, 256, 1024), (512, 1024, 256, 512), (512, 1024, 256, 256), (512, 1024, 256, 128), (512, 1024, 256, 64), (512, 1024, 256, 32), (512, 1024, 128, 2048), (512, 1024, 128, 1024), (512, 1024, 128, 512), (512, 1024, 128, 256), (512, 1024, 128, 128), (512, 1024, 128, 64), (512, 1024, 128, 32), (512, 1024, 64, 2048), (512, 1024, 64, 1024), (512, 1024, 64, 512), (512, 1024, 64, 256), (512, 1024, 64, 128), (512, 1024, 64, 64), (512, 1024, 64, 32), (512, 1024, 32, 2048), (512, 1024, 32, 1024), (512, 1024, 32, 512), (512, 1024, 32, 256), (512, 1024, 32, 128), (512, 1024, 32, 64), (512, 1024, 32, 32), (512, 512, 2048, 2048), (512, 512, 2048, 1024), (512, 512, 2048, 512), (512, 512, 2048, 256), (512, 512, 2048, 128), (512, 512, 2048, 64), (512, 512, 2048, 32), (512, 512, 1024, 2048), (512, 512, 1024, 1024), (512, 512, 1024, 512), (512, 512, 1024, 256), (512, 512, 1024, 128), (512, 512, 1024, 64), (512, 512, 1024, 32), (512, 512, 512, 2048), (512, 512, 512, 1024), (512, 512, 512, 512), (512, 512, 512, 256), (512, 512, 512, 128), (512, 512, 512, 64), (512, 512, 512, 32), (512, 512, 256, 2048), (512, 512, 256, 1024), (512, 512, 256, 512), (512, 512, 256, 256), (512, 512, 256, 128), (512, 512, 256, 64), (512, 512, 256, 32), (512, 512, 128, 2048), (512, 512, 128, 1024), (512, 512, 128, 512), (512, 512, 128, 256), (512, 512, 128, 128), (512, 512, 128, 64), (512, 512, 128, 32), (512, 512, 64, 2048), (512, 512, 64, 1024), (512, 512, 64, 512), (512, 512, 64, 256), (512, 512, 64, 128), (512, 512, 64, 64), (512, 512, 64, 32), (512, 512, 32, 2048), (512, 512, 32, 1024), (512, 512, 32, 512), (512, 512, 32, 256), (512, 512, 32, 128), (512, 512, 32, 64), (512, 512, 32, 32), (512, 256, 2048, 2048), (512, 256, 2048, 1024), (512, 256, 2048, 512), (512, 256, 2048, 256), (512, 256, 2048, 128), (512, 256, 2048, 64), (512, 256, 2048, 32), (512, 256, 1024, 2048), (512, 256, 1024, 1024), (512, 256, 1024, 512), (512, 256, 1024, 256), (512, 256, 1024, 128), (512, 256, 1024, 64), (512, 256, 1024, 32), (512, 256, 512, 2048), (512, 256, 512, 1024), (512, 256, 512, 512), (512, 256, 512, 256), (512, 256, 512, 128), (512, 256, 512, 64), (512, 256, 512, 32), (512, 256, 256, 2048), (512, 256, 256, 1024), (512, 256, 256, 512), (512, 256, 256, 256), (512, 256, 256, 128), (512, 256, 256, 64), (512, 256, 256, 32), (512, 256, 128, 2048), (512, 256, 128, 1024), (512, 256, 128, 512), (512, 256, 128, 256), (512, 256, 128, 128), (512, 256, 128, 64), (512, 256, 128, 32), (512, 256, 64, 2048), (512, 256, 64, 1024), (512, 256, 64, 512), (512, 256, 64, 256), (512, 256, 64, 128), (512, 256, 64, 64), (512, 256, 64, 32), (512, 256, 32, 2048), (512, 256, 32, 1024), (512, 256, 32, 512), (512, 256, 32, 256), (512, 256, 32, 128), (512, 256, 32, 64), (512, 256, 32, 32), (512, 128, 2048, 2048), (512, 128, 2048, 1024), (512, 128, 2048, 512), (512, 128, 2048, 256), (512, 128, 2048, 128), (512, 128, 2048, 64), (512, 128, 2048, 32), (512, 128, 1024, 2048), (512, 128, 1024, 1024), (512, 128, 1024, 512), (512, 128, 1024, 256), (512, 128, 1024, 128), (512, 128, 1024, 64), (512, 128, 1024, 32), (512, 128, 512, 2048), (512, 128, 512, 1024), (512, 128, 512, 512), (512, 128, 512, 256), (512, 128, 512, 128), (512, 128, 512, 64), (512, 128, 512, 32), (512, 128, 256, 2048), (512, 128, 256, 1024), (512, 128, 256, 512), (512, 128, 256, 256), (512, 128, 256, 128), (512, 128, 256, 64), (512, 128, 256, 32), (512, 128, 128, 2048), (512, 128, 128, 1024), (512, 128, 128, 512), (512, 128, 128, 256), (512, 128, 128, 128), (512, 128, 128, 64), (512, 128, 128, 32), (512, 128, 64, 2048), (512, 128, 64, 1024), (512, 128, 64, 512), (512, 128, 64, 256), (512, 128, 64, 128), (512, 128, 64, 64), (512, 128, 64, 32), (512, 128, 32, 2048), (512, 128, 32, 1024), (512, 128, 32, 512), (512, 128, 32, 256), (512, 128, 32, 128), (512, 128, 32, 64), (512, 128, 32, 32), (512, 64, 2048, 2048), (512, 64, 2048, 1024), (512, 64, 2048, 512), (512, 64, 2048, 256), (512, 64, 2048, 128), (512, 64, 2048, 64), (512, 64, 2048, 32), (512, 64, 1024, 2048), (512, 64, 1024, 1024), (512, 64, 1024, 512), (512, 64, 1024, 256), (512, 64, 1024, 128), (512, 64, 1024, 64), (512, 64, 1024, 32), (512, 64, 512, 2048), (512, 64, 512, 1024), (512, 64, 512, 512), (512, 64, 512, 256), (512, 64, 512, 128), (512, 64, 512, 64), (512, 64, 512, 32), (512, 64, 256, 2048), (512, 64, 256, 1024), (512, 64, 256, 512), (512, 64, 256, 256), (512, 64, 256, 128), (512, 64, 256, 64), (512, 64, 256, 32), (512, 64, 128, 2048), (512, 64, 128, 1024), (512, 64, 128, 512), (512, 64, 128, 256), (512, 64, 128, 128), (512, 64, 128, 64), (512, 64, 128, 32), (512, 64, 64, 2048), (512, 64, 64, 1024), (512, 64, 64, 512), (512, 64, 64, 256), (512, 64, 64, 128), (512, 64, 64, 64), (512, 64, 64, 32), (512, 64, 32, 2048), (512, 64, 32, 1024), (512, 64, 32, 512), (512, 64, 32, 256), (512, 64, 32, 128), (512, 64, 32, 64), (512, 64, 32, 32), (512, 32, 2048, 2048), (512, 32, 2048, 1024), (512, 32, 2048, 512), (512, 32, 2048, 256), (512, 32, 2048, 128), (512, 32, 2048, 64), (512, 32, 2048, 32), (512, 32, 1024, 2048), (512, 32, 1024, 1024), (512, 32, 1024, 512), (512, 32, 1024, 256), (512, 32, 1024, 128), (512, 32, 1024, 64), (512, 32, 1024, 32), (512, 32, 512, 2048), (512, 32, 512, 1024), (512, 32, 512, 512), (512, 32, 512, 256), (512, 32, 512, 128), (512, 32, 512, 64), (512, 32, 512, 32), (512, 32, 256, 2048), (512, 32, 256, 1024), (512, 32, 256, 512), (512, 32, 256, 256), (512, 32, 256, 128), (512, 32, 256, 64), (512, 32, 256, 32), (512, 32, 128, 2048), (512, 32, 128, 1024), (512, 32, 128, 512), (512, 32, 128, 256), (512, 32, 128, 128), (512, 32, 128, 64), (512, 32, 128, 32), (512, 32, 64, 2048), (512, 32, 64, 1024), (512, 32, 64, 512), (512, 32, 64, 256), (512, 32, 64, 128), (512, 32, 64, 64), (512, 32, 64, 32), (512, 32, 32, 2048), (512, 32, 32, 1024), (512, 32, 32, 512), (512, 32, 32, 256), (512, 32, 32, 128), (512, 32, 32, 64), (512, 32, 32, 32), (256, 2048, 2048, 2048), (256, 2048, 2048, 1024), (256, 2048, 2048, 512), (256, 2048, 2048, 256), (256, 2048, 2048, 128), (256, 2048, 2048, 64), (256, 2048, 2048, 32), (256, 2048, 1024, 2048), (256, 2048, 1024, 1024), (256, 2048, 1024, 512), (256, 2048, 1024, 256), (256, 2048, 1024, 128), (256, 2048, 1024, 64), (256, 2048, 1024, 32), (256, 2048, 512, 2048), (256, 2048, 512, 1024), (256, 2048, 512, 512), (256, 2048, 512, 256), (256, 2048, 512, 128), (256, 2048, 512, 64), (256, 2048, 512, 32), (256, 2048, 256, 2048), (256, 2048, 256, 1024), (256, 2048, 256, 512), (256, 2048, 256, 256), (256, 2048, 256, 128), (256, 2048, 256, 64), (256, 2048, 256, 32), (256, 2048, 128, 2048), (256, 2048, 128, 1024), (256, 2048, 128, 512), (256, 2048, 128, 256), (256, 2048, 128, 128), (256, 2048, 128, 64), (256, 2048, 128, 32), (256, 2048, 64, 2048), (256, 2048, 64, 1024), (256, 2048, 64, 512), (256, 2048, 64, 256), (256, 2048, 64, 128), (256, 2048, 64, 64), (256, 2048, 64, 32), (256, 2048, 32, 2048), (256, 2048, 32, 1024), (256, 2048, 32, 512), (256, 2048, 32, 256), (256, 2048, 32, 128), (256, 2048, 32, 64), (256, 2048, 32, 32), (256, 1024, 2048, 2048), (256, 1024, 2048, 1024), (256, 1024, 2048, 512), (256, 1024, 2048, 256), (256, 1024, 2048, 128), (256, 1024, 2048, 64), (256, 1024, 2048, 32), (256, 1024, 1024, 2048), (256, 1024, 1024, 1024), (256, 1024, 1024, 512), (256, 1024, 1024, 256), (256, 1024, 1024, 128), (256, 1024, 1024, 64), (256, 1024, 1024, 32), (256, 1024, 512, 2048), (256, 1024, 512, 1024), (256, 1024, 512, 512), (256, 1024, 512, 256), (256, 1024, 512, 128), (256, 1024, 512, 64), (256, 1024, 512, 32), (256, 1024, 256, 2048), (256, 1024, 256, 1024), (256, 1024, 256, 512), (256, 1024, 256, 256), (256, 1024, 256, 128), (256, 1024, 256, 64), (256, 1024, 256, 32), (256, 1024, 128, 2048), (256, 1024, 128, 1024), (256, 1024, 128, 512), (256, 1024, 128, 256), (256, 1024, 128, 128), (256, 1024, 128, 64), (256, 1024, 128, 32), (256, 1024, 64, 2048), (256, 1024, 64, 1024), (256, 1024, 64, 512), (256, 1024, 64, 256), (256, 1024, 64, 128), (256, 1024, 64, 64), (256, 1024, 64, 32), (256, 1024, 32, 2048), (256, 1024, 32, 1024), (256, 1024, 32, 512), (256, 1024, 32, 256), (256, 1024, 32, 128), (256, 1024, 32, 64), (256, 1024, 32, 32), (256, 512, 2048, 2048), (256, 512, 2048, 1024), (256, 512, 2048, 512), (256, 512, 2048, 256), (256, 512, 2048, 128), (256, 512, 2048, 64), (256, 512, 2048, 32), (256, 512, 1024, 2048), (256, 512, 1024, 1024), (256, 512, 1024, 512), (256, 512, 1024, 256), (256, 512, 1024, 128), (256, 512, 1024, 64), (256, 512, 1024, 32), (256, 512, 512, 2048), (256, 512, 512, 1024), (256, 512, 512, 512), (256, 512, 512, 256), (256, 512, 512, 128), (256, 512, 512, 64), (256, 512, 512, 32), (256, 512, 256, 2048), (256, 512, 256, 1024), (256, 512, 256, 512), (256, 512, 256, 256), (256, 512, 256, 128), (256, 512, 256, 64), (256, 512, 256, 32), (256, 512, 128, 2048), (256, 512, 128, 1024), (256, 512, 128, 512), (256, 512, 128, 256), (256, 512, 128, 128), (256, 512, 128, 64), (256, 512, 128, 32), (256, 512, 64, 2048), (256, 512, 64, 1024), (256, 512, 64, 512), (256, 512, 64, 256), (256, 512, 64, 128), (256, 512, 64, 64), (256, 512, 64, 32), (256, 512, 32, 2048), (256, 512, 32, 1024), (256, 512, 32, 512), (256, 512, 32, 256), (256, 512, 32, 128), (256, 512, 32, 64), (256, 512, 32, 32), (256, 256, 2048, 2048), (256, 256, 2048, 1024), (256, 256, 2048, 512), (256, 256, 2048, 256), (256, 256, 2048, 128), (256, 256, 2048, 64), (256, 256, 2048, 32), (256, 256, 1024, 2048), (256, 256, 1024, 1024), (256, 256, 1024, 512), (256, 256, 1024, 256), (256, 256, 1024, 128), (256, 256, 1024, 64), (256, 256, 1024, 32), (256, 256, 512, 2048), (256, 256, 512, 1024), (256, 256, 512, 512), (256, 256, 512, 256), (256, 256, 512, 128), (256, 256, 512, 64), (256, 256, 512, 32), (256, 256, 256, 2048), (256, 256, 256, 1024), (256, 256, 256, 512), (256, 256, 256, 256), (256, 256, 256, 128), (256, 256, 256, 64), (256, 256, 256, 32), (256, 256, 128, 2048), (256, 256, 128, 1024), (256, 256, 128, 512), (256, 256, 128, 256), (256, 256, 128, 128), (256, 256, 128, 64), (256, 256, 128, 32), (256, 256, 64, 2048), (256, 256, 64, 1024), (256, 256, 64, 512), (256, 256, 64, 256), (256, 256, 64, 128), (256, 256, 64, 64), (256, 256, 64, 32), (256, 256, 32, 2048), (256, 256, 32, 1024), (256, 256, 32, 512), (256, 256, 32, 256), (256, 256, 32, 128), (256, 256, 32, 64), (256, 256, 32, 32), (256, 128, 2048, 2048), (256, 128, 2048, 1024), (256, 128, 2048, 512), (256, 128, 2048, 256), (256, 128, 2048, 128), (256, 128, 2048, 64), (256, 128, 2048, 32), (256, 128, 1024, 2048), (256, 128, 1024, 1024), (256, 128, 1024, 512), (256, 128, 1024, 256), (256, 128, 1024, 128), (256, 128, 1024, 64), (256, 128, 1024, 32), (256, 128, 512, 2048), (256, 128, 512, 1024), (256, 128, 512, 512), (256, 128, 512, 256), (256, 128, 512, 128), (256, 128, 512, 64), (256, 128, 512, 32), (256, 128, 256, 2048), (256, 128, 256, 1024), (256, 128, 256, 512), (256, 128, 256, 256), (256, 128, 256, 128), (256, 128, 256, 64), (256, 128, 256, 32), (256, 128, 128, 2048), (256, 128, 128, 1024), (256, 128, 128, 512), (256, 128, 128, 256), (256, 128, 128, 128), (256, 128, 128, 64), (256, 128, 128, 32), (256, 128, 64, 2048), (256, 128, 64, 1024), (256, 128, 64, 512), (256, 128, 64, 256), (256, 128, 64, 128), (256, 128, 64, 64), (256, 128, 64, 32), (256, 128, 32, 2048), (256, 128, 32, 1024), (256, 128, 32, 512), (256, 128, 32, 256), (256, 128, 32, 128), (256, 128, 32, 64), (256, 128, 32, 32), (256, 64, 2048, 2048), (256, 64, 2048, 1024), (256, 64, 2048, 512), (256, 64, 2048, 256), (256, 64, 2048, 128), (256, 64, 2048, 64), (256, 64, 2048, 32), (256, 64, 1024, 2048), (256, 64, 1024, 1024), (256, 64, 1024, 512), (256, 64, 1024, 256), (256, 64, 1024, 128), (256, 64, 1024, 64), (256, 64, 1024, 32), (256, 64, 512, 2048), (256, 64, 512, 1024), (256, 64, 512, 512), (256, 64, 512, 256), (256, 64, 512, 128), (256, 64, 512, 64), (256, 64, 512, 32), (256, 64, 256, 2048), (256, 64, 256, 1024), (256, 64, 256, 512), (256, 64, 256, 256), (256, 64, 256, 128), (256, 64, 256, 64), (256, 64, 256, 32), (256, 64, 128, 2048), (256, 64, 128, 1024), (256, 64, 128, 512), (256, 64, 128, 256), (256, 64, 128, 128), (256, 64, 128, 64), (256, 64, 128, 32), (256, 64, 64, 2048), (256, 64, 64, 1024), (256, 64, 64, 512), (256, 64, 64, 256), (256, 64, 64, 128), (256, 64, 64, 64), (256, 64, 64, 32), (256, 64, 32, 2048), (256, 64, 32, 1024), (256, 64, 32, 512), (256, 64, 32, 256), (256, 64, 32, 128), (256, 64, 32, 64), (256, 64, 32, 32), (256, 32, 2048, 2048), (256, 32, 2048, 1024), (256, 32, 2048, 512), (256, 32, 2048, 256), (256, 32, 2048, 128), (256, 32, 2048, 64), (256, 32, 2048, 32), (256, 32, 1024, 2048), (256, 32, 1024, 1024), (256, 32, 1024, 512), (256, 32, 1024, 256), (256, 32, 1024, 128), (256, 32, 1024, 64), (256, 32, 1024, 32), (256, 32, 512, 2048), (256, 32, 512, 1024), (256, 32, 512, 512), (256, 32, 512, 256), (256, 32, 512, 128), (256, 32, 512, 64), (256, 32, 512, 32), (256, 32, 256, 2048), (256, 32, 256, 1024), (256, 32, 256, 512), (256, 32, 256, 256), (256, 32, 256, 128), (256, 32, 256, 64), (256, 32, 256, 32), (256, 32, 128, 2048), (256, 32, 128, 1024), (256, 32, 128, 512), (256, 32, 128, 256), (256, 32, 128, 128), (256, 32, 128, 64), (256, 32, 128, 32), (256, 32, 64, 2048), (256, 32, 64, 1024), (256, 32, 64, 512), (256, 32, 64, 256), (256, 32, 64, 128), (256, 32, 64, 64), (256, 32, 64, 32), (256, 32, 32, 2048), (256, 32, 32, 1024), (256, 32, 32, 512), (256, 32, 32, 256), (256, 32, 32, 128), (256, 32, 32, 64), (256, 32, 32, 32), (128, 2048, 2048, 2048), (128, 2048, 2048, 1024), (128, 2048, 2048, 512), (128, 2048, 2048, 256), (128, 2048, 2048, 128), (128, 2048, 2048, 64), (128, 2048, 2048, 32), (128, 2048, 1024, 2048), (128, 2048, 1024, 1024), (128, 2048, 1024, 512), (128, 2048, 1024, 256), (128, 2048, 1024, 128), (128, 2048, 1024, 64), (128, 2048, 1024, 32), (128, 2048, 512, 2048), (128, 2048, 512, 1024), (128, 2048, 512, 512), (128, 2048, 512, 256), (128, 2048, 512, 128), (128, 2048, 512, 64), (128, 2048, 512, 32), (128, 2048, 256, 2048), (128, 2048, 256, 1024), (128, 2048, 256, 512), (128, 2048, 256, 256), (128, 2048, 256, 128), (128, 2048, 256, 64), (128, 2048, 256, 32), (128, 2048, 128, 2048), (128, 2048, 128, 1024), (128, 2048, 128, 512), (128, 2048, 128, 256), (128, 2048, 128, 128), (128, 2048, 128, 64), (128, 2048, 128, 32), (128, 2048, 64, 2048), (128, 2048, 64, 1024), (128, 2048, 64, 512), (128, 2048, 64, 256), (128, 2048, 64, 128), (128, 2048, 64, 64), (128, 2048, 64, 32), (128, 2048, 32, 2048), (128, 2048, 32, 1024), (128, 2048, 32, 512), (128, 2048, 32, 256), (128, 2048, 32, 128), (128, 2048, 32, 64), (128, 2048, 32, 32), (128, 1024, 2048, 2048), (128, 1024, 2048, 1024), (128, 1024, 2048, 512), (128, 1024, 2048, 256), (128, 1024, 2048, 128), (128, 1024, 2048, 64), (128, 1024, 2048, 32), (128, 1024, 1024, 2048), (128, 1024, 1024, 1024), (128, 1024, 1024, 512), (128, 1024, 1024, 256), (128, 1024, 1024, 128), (128, 1024, 1024, 64), (128, 1024, 1024, 32), (128, 1024, 512, 2048), (128, 1024, 512, 1024), (128, 1024, 512, 512), (128, 1024, 512, 256), (128, 1024, 512, 128), (128, 1024, 512, 64), (128, 1024, 512, 32), (128, 1024, 256, 2048), (128, 1024, 256, 1024), (128, 1024, 256, 512), (128, 1024, 256, 256), (128, 1024, 256, 128), (128, 1024, 256, 64), (128, 1024, 256, 32), (128, 1024, 128, 2048), (128, 1024, 128, 1024), (128, 1024, 128, 512), (128, 1024, 128, 256), (128, 1024, 128, 128), (128, 1024, 128, 64), (128, 1024, 128, 32), (128, 1024, 64, 2048), (128, 1024, 64, 1024), (128, 1024, 64, 512), (128, 1024, 64, 256), (128, 1024, 64, 128), (128, 1024, 64, 64), (128, 1024, 64, 32), (128, 1024, 32, 2048), (128, 1024, 32, 1024), (128, 1024, 32, 512), (128, 1024, 32, 256), (128, 1024, 32, 128), (128, 1024, 32, 64), (128, 1024, 32, 32), (128, 512, 2048, 2048), (128, 512, 2048, 1024), (128, 512, 2048, 512), (128, 512, 2048, 256), (128, 512, 2048, 128), (128, 512, 2048, 64), (128, 512, 2048, 32), (128, 512, 1024, 2048), (128, 512, 1024, 1024), (128, 512, 1024, 512), (128, 512, 1024, 256), (128, 512, 1024, 128), (128, 512, 1024, 64), (128, 512, 1024, 32), (128, 512, 512, 2048), (128, 512, 512, 1024), (128, 512, 512, 512), (128, 512, 512, 256), (128, 512, 512, 128), (128, 512, 512, 64), (128, 512, 512, 32), (128, 512, 256, 2048), (128, 512, 256, 1024), (128, 512, 256, 512), (128, 512, 256, 256), (128, 512, 256, 128), (128, 512, 256, 64), (128, 512, 256, 32), (128, 512, 128, 2048), (128, 512, 128, 1024), (128, 512, 128, 512), (128, 512, 128, 256), (128, 512, 128, 128), (128, 512, 128, 64), (128, 512, 128, 32), (128, 512, 64, 2048), (128, 512, 64, 1024), (128, 512, 64, 512), (128, 512, 64, 256), (128, 512, 64, 128), (128, 512, 64, 64), (128, 512, 64, 32), (128, 512, 32, 2048), (128, 512, 32, 1024), (128, 512, 32, 512), (128, 512, 32, 256), (128, 512, 32, 128), (128, 512, 32, 64), (128, 512, 32, 32), (128, 256, 2048, 2048), (128, 256, 2048, 1024), (128, 256, 2048, 512), (128, 256, 2048, 256), (128, 256, 2048, 128), (128, 256, 2048, 64), (128, 256, 2048, 32), (128, 256, 1024, 2048), (128, 256, 1024, 1024), (128, 256, 1024, 512), (128, 256, 1024, 256), (128, 256, 1024, 128), (128, 256, 1024, 64), (128, 256, 1024, 32), (128, 256, 512, 2048), (128, 256, 512, 1024), (128, 256, 512, 512), (128, 256, 512, 256), (128, 256, 512, 128), (128, 256, 512, 64), (128, 256, 512, 32), (128, 256, 256, 2048), (128, 256, 256, 1024), (128, 256, 256, 512), (128, 256, 256, 256), (128, 256, 256, 128), (128, 256, 256, 64), (128, 256, 256, 32), (128, 256, 128, 2048), (128, 256, 128, 1024), (128, 256, 128, 512), (128, 256, 128, 256), (128, 256, 128, 128), (128, 256, 128, 64), (128, 256, 128, 32), (128, 256, 64, 2048), (128, 256, 64, 1024), (128, 256, 64, 512), (128, 256, 64, 256), (128, 256, 64, 128), (128, 256, 64, 64), (128, 256, 64, 32), (128, 256, 32, 2048), (128, 256, 32, 1024), (128, 256, 32, 512), (128, 256, 32, 256), (128, 256, 32, 128), (128, 256, 32, 64), (128, 256, 32, 32), (128, 128, 2048, 2048), (128, 128, 2048, 1024), (128, 128, 2048, 512), (128, 128, 2048, 256), (128, 128, 2048, 128), (128, 128, 2048, 64), (128, 128, 2048, 32), (128, 128, 1024, 2048), (128, 128, 1024, 1024), (128, 128, 1024, 512), (128, 128, 1024, 256), (128, 128, 1024, 128), (128, 128, 1024, 64), (128, 128, 1024, 32), (128, 128, 512, 2048), (128, 128, 512, 1024), (128, 128, 512, 512), (128, 128, 512, 256), (128, 128, 512, 128), (128, 128, 512, 64), (128, 128, 512, 32), (128, 128, 256, 2048), (128, 128, 256, 1024), (128, 128, 256, 512), (128, 128, 256, 256), (128, 128, 256, 128), (128, 128, 256, 64), (128, 128, 256, 32), (128, 128, 128, 2048), (128, 128, 128, 1024), (128, 128, 128, 512), (128, 128, 128, 256), (128, 128, 128, 128), (128, 128, 128, 64), (128, 128, 128, 32), (128, 128, 64, 2048), (128, 128, 64, 1024), (128, 128, 64, 512), (128, 128, 64, 256), (128, 128, 64, 128), (128, 128, 64, 64), (128, 128, 64, 32), (128, 128, 32, 2048), (128, 128, 32, 1024), (128, 128, 32, 512), (128, 128, 32, 256), (128, 128, 32, 128), (128, 128, 32, 64), (128, 128, 32, 32), (128, 64, 2048, 2048), (128, 64, 2048, 1024), (128, 64, 2048, 512), (128, 64, 2048, 256), (128, 64, 2048, 128), (128, 64, 2048, 64), (128, 64, 2048, 32), (128, 64, 1024, 2048), (128, 64, 1024, 1024), (128, 64, 1024, 512), (128, 64, 1024, 256), (128, 64, 1024, 128), (128, 64, 1024, 64), (128, 64, 1024, 32), (128, 64, 512, 2048), (128, 64, 512, 1024), (128, 64, 512, 512), (128, 64, 512, 256), (128, 64, 512, 128), (128, 64, 512, 64), (128, 64, 512, 32), (128, 64, 256, 2048), (128, 64, 256, 1024), (128, 64, 256, 512), (128, 64, 256, 256), (128, 64, 256, 128), (128, 64, 256, 64), (128, 64, 256, 32), (128, 64, 128, 2048), (128, 64, 128, 1024), (128, 64, 128, 512), (128, 64, 128, 256), (128, 64, 128, 128), (128, 64, 128, 64), (128, 64, 128, 32), (128, 64, 64, 2048), (128, 64, 64, 1024), (128, 64, 64, 512), (128, 64, 64, 256), (128, 64, 64, 128), (128, 64, 64, 64), (128, 64, 64, 32), (128, 64, 32, 2048), (128, 64, 32, 1024), (128, 64, 32, 512), (128, 64, 32, 256), (128, 64, 32, 128), (128, 64, 32, 64), (128, 64, 32, 32), (128, 32, 2048, 2048), (128, 32, 2048, 1024), (128, 32, 2048, 512), (128, 32, 2048, 256), (128, 32, 2048, 128), (128, 32, 2048, 64), (128, 32, 2048, 32), (128, 32, 1024, 2048), (128, 32, 1024, 1024), (128, 32, 1024, 512), (128, 32, 1024, 256), (128, 32, 1024, 128), (128, 32, 1024, 64), (128, 32, 1024, 32), (128, 32, 512, 2048), (128, 32, 512, 1024), (128, 32, 512, 512), (128, 32, 512, 256), (128, 32, 512, 128), (128, 32, 512, 64), (128, 32, 512, 32), (128, 32, 256, 2048), (128, 32, 256, 1024), (128, 32, 256, 512), (128, 32, 256, 256), (128, 32, 256, 128), (128, 32, 256, 64), (128, 32, 256, 32), (128, 32, 128, 2048), (128, 32, 128, 1024), (128, 32, 128, 512), (128, 32, 128, 256), (128, 32, 128, 128), (128, 32, 128, 64), (128, 32, 128, 32), (128, 32, 64, 2048), (128, 32, 64, 1024), (128, 32, 64, 512), (128, 32, 64, 256), (128, 32, 64, 128), (128, 32, 64, 64), (128, 32, 64, 32), (128, 32, 32, 2048), (128, 32, 32, 1024), (128, 32, 32, 512), (128, 32, 32, 256), (128, 32, 32, 128), (128, 32, 32, 64), (128, 32, 32, 32), (64, 2048, 2048, 2048), (64, 2048, 2048, 1024), (64, 2048, 2048, 512), (64, 2048, 2048, 256), (64, 2048, 2048, 128), (64, 2048, 2048, 64), (64, 2048, 2048, 32), (64, 2048, 1024, 2048), (64, 2048, 1024, 1024), (64, 2048, 1024, 512), (64, 2048, 1024, 256), (64, 2048, 1024, 128), (64, 2048, 1024, 64), (64, 2048, 1024, 32), (64, 2048, 512, 2048), (64, 2048, 512, 1024), (64, 2048, 512, 512), (64, 2048, 512, 256), (64, 2048, 512, 128), (64, 2048, 512, 64), (64, 2048, 512, 32), (64, 2048, 256, 2048), (64, 2048, 256, 1024), (64, 2048, 256, 512), (64, 2048, 256, 256), (64, 2048, 256, 128), (64, 2048, 256, 64), (64, 2048, 256, 32), (64, 2048, 128, 2048), (64, 2048, 128, 1024), (64, 2048, 128, 512), (64, 2048, 128, 256), (64, 2048, 128, 128), (64, 2048, 128, 64), (64, 2048, 128, 32), (64, 2048, 64, 2048), (64, 2048, 64, 1024), (64, 2048, 64, 512), (64, 2048, 64, 256), (64, 2048, 64, 128), (64, 2048, 64, 64), (64, 2048, 64, 32), (64, 2048, 32, 2048), (64, 2048, 32, 1024), (64, 2048, 32, 512), (64, 2048, 32, 256), (64, 2048, 32, 128), (64, 2048, 32, 64), (64, 2048, 32, 32), (64, 1024, 2048, 2048), (64, 1024, 2048, 1024), (64, 1024, 2048, 512), (64, 1024, 2048, 256), (64, 1024, 2048, 128), (64, 1024, 2048, 64), (64, 1024, 2048, 32), (64, 1024, 1024, 2048), (64, 1024, 1024, 1024), (64, 1024, 1024, 512), (64, 1024, 1024, 256), (64, 1024, 1024, 128), (64, 1024, 1024, 64), (64, 1024, 1024, 32), (64, 1024, 512, 2048), (64, 1024, 512, 1024), (64, 1024, 512, 512), (64, 1024, 512, 256), (64, 1024, 512, 128), (64, 1024, 512, 64), (64, 1024, 512, 32), (64, 1024, 256, 2048), (64, 1024, 256, 1024), (64, 1024, 256, 512), (64, 1024, 256, 256), (64, 1024, 256, 128), (64, 1024, 256, 64), (64, 1024, 256, 32), (64, 1024, 128, 2048), (64, 1024, 128, 1024), (64, 1024, 128, 512), (64, 1024, 128, 256), (64, 1024, 128, 128), (64, 1024, 128, 64), (64, 1024, 128, 32), (64, 1024, 64, 2048), (64, 1024, 64, 1024), (64, 1024, 64, 512), (64, 1024, 64, 256), (64, 1024, 64, 128), (64, 1024, 64, 64), (64, 1024, 64, 32), (64, 1024, 32, 2048), (64, 1024, 32, 1024), (64, 1024, 32, 512), (64, 1024, 32, 256), (64, 1024, 32, 128), (64, 1024, 32, 64), (64, 1024, 32, 32), (64, 512, 2048, 2048), (64, 512, 2048, 1024), (64, 512, 2048, 512), (64, 512, 2048, 256), (64, 512, 2048, 128), (64, 512, 2048, 64), (64, 512, 2048, 32), (64, 512, 1024, 2048), (64, 512, 1024, 1024), (64, 512, 1024, 512), (64, 512, 1024, 256), (64, 512, 1024, 128), (64, 512, 1024, 64), (64, 512, 1024, 32), (64, 512, 512, 2048), (64, 512, 512, 1024), (64, 512, 512, 512), (64, 512, 512, 256), (64, 512, 512, 128), (64, 512, 512, 64), (64, 512, 512, 32), (64, 512, 256, 2048), (64, 512, 256, 1024), (64, 512, 256, 512), (64, 512, 256, 256), (64, 512, 256, 128), (64, 512, 256, 64), (64, 512, 256, 32), (64, 512, 128, 2048), (64, 512, 128, 1024), (64, 512, 128, 512), (64, 512, 128, 256), (64, 512, 128, 128), (64, 512, 128, 64), (64, 512, 128, 32), (64, 512, 64, 2048), (64, 512, 64, 1024), (64, 512, 64, 512), (64, 512, 64, 256), (64, 512, 64, 128), (64, 512, 64, 64), (64, 512, 64, 32), (64, 512, 32, 2048), (64, 512, 32, 1024), (64, 512, 32, 512), (64, 512, 32, 256), (64, 512, 32, 128), (64, 512, 32, 64), (64, 512, 32, 32), (64, 256, 2048, 2048), (64, 256, 2048, 1024), (64, 256, 2048, 512), (64, 256, 2048, 256), (64, 256, 2048, 128), (64, 256, 2048, 64), (64, 256, 2048, 32), (64, 256, 1024, 2048), (64, 256, 1024, 1024), (64, 256, 1024, 512), (64, 256, 1024, 256), (64, 256, 1024, 128), (64, 256, 1024, 64), (64, 256, 1024, 32), (64, 256, 512, 2048), (64, 256, 512, 1024), (64, 256, 512, 512), (64, 256, 512, 256), (64, 256, 512, 128), (64, 256, 512, 64), (64, 256, 512, 32), (64, 256, 256, 2048), (64, 256, 256, 1024), (64, 256, 256, 512), (64, 256, 256, 256), (64, 256, 256, 128), (64, 256, 256, 64), (64, 256, 256, 32), (64, 256, 128, 2048), (64, 256, 128, 1024), (64, 256, 128, 512), (64, 256, 128, 256), (64, 256, 128, 128), (64, 256, 128, 64), (64, 256, 128, 32), (64, 256, 64, 2048), (64, 256, 64, 1024), (64, 256, 64, 512), (64, 256, 64, 256), (64, 256, 64, 128), (64, 256, 64, 64), (64, 256, 64, 32), (64, 256, 32, 2048), (64, 256, 32, 1024), (64, 256, 32, 512), (64, 256, 32, 256), (64, 256, 32, 128), (64, 256, 32, 64), (64, 256, 32, 32), (64, 128, 2048, 2048), (64, 128, 2048, 1024), (64, 128, 2048, 512), (64, 128, 2048, 256), (64, 128, 2048, 128), (64, 128, 2048, 64), (64, 128, 2048, 32), (64, 128, 1024, 2048), (64, 128, 1024, 1024), (64, 128, 1024, 512), (64, 128, 1024, 256), (64, 128, 1024, 128), (64, 128, 1024, 64), (64, 128, 1024, 32), (64, 128, 512, 2048), (64, 128, 512, 1024), (64, 128, 512, 512), (64, 128, 512, 256), (64, 128, 512, 128), (64, 128, 512, 64), (64, 128, 512, 32), (64, 128, 256, 2048), (64, 128, 256, 1024), (64, 128, 256, 512), (64, 128, 256, 256), (64, 128, 256, 128), (64, 128, 256, 64), (64, 128, 256, 32), (64, 128, 128, 2048), (64, 128, 128, 1024), (64, 128, 128, 512), (64, 128, 128, 256), (64, 128, 128, 128), (64, 128, 128, 64), (64, 128, 128, 32), (64, 128, 64, 2048), (64, 128, 64, 1024), (64, 128, 64, 512), (64, 128, 64, 256), (64, 128, 64, 128), (64, 128, 64, 64), (64, 128, 64, 32), (64, 128, 32, 2048), (64, 128, 32, 1024), (64, 128, 32, 512), (64, 128, 32, 256), (64, 128, 32, 128), (64, 128, 32, 64), (64, 128, 32, 32), (64, 64, 2048, 2048), (64, 64, 2048, 1024), (64, 64, 2048, 512), (64, 64, 2048, 256), (64, 64, 2048, 128), (64, 64, 2048, 64), (64, 64, 2048, 32), (64, 64, 1024, 2048), (64, 64, 1024, 1024), (64, 64, 1024, 512), (64, 64, 1024, 256), (64, 64, 1024, 128), (64, 64, 1024, 64), (64, 64, 1024, 32), (64, 64, 512, 2048), (64, 64, 512, 1024), (64, 64, 512, 512), (64, 64, 512, 256), (64, 64, 512, 128), (64, 64, 512, 64), (64, 64, 512, 32), (64, 64, 256, 2048), (64, 64, 256, 1024), (64, 64, 256, 512), (64, 64, 256, 256), (64, 64, 256, 128), (64, 64, 256, 64), (64, 64, 256, 32), (64, 64, 128, 2048), (64, 64, 128, 1024), (64, 64, 128, 512), (64, 64, 128, 256), (64, 64, 128, 128), (64, 64, 128, 64), (64, 64, 128, 32), (64, 64, 64, 2048), (64, 64, 64, 1024), (64, 64, 64, 512), (64, 64, 64, 256), (64, 64, 64, 128), (64, 64, 64, 64), (64, 64, 64, 32), (64, 64, 32, 2048), (64, 64, 32, 1024), (64, 64, 32, 512), (64, 64, 32, 256), (64, 64, 32, 128), (64, 64, 32, 64), (64, 64, 32, 32), (64, 32, 2048, 2048), (64, 32, 2048, 1024), (64, 32, 2048, 512), (64, 32, 2048, 256), (64, 32, 2048, 128), (64, 32, 2048, 64), (64, 32, 2048, 32), (64, 32, 1024, 2048), (64, 32, 1024, 1024), (64, 32, 1024, 512), (64, 32, 1024, 256), (64, 32, 1024, 128), (64, 32, 1024, 64), (64, 32, 1024, 32), (64, 32, 512, 2048), (64, 32, 512, 1024), (64, 32, 512, 512), (64, 32, 512, 256), (64, 32, 512, 128), (64, 32, 512, 64), (64, 32, 512, 32), (64, 32, 256, 2048), (64, 32, 256, 1024), (64, 32, 256, 512), (64, 32, 256, 256), (64, 32, 256, 128), (64, 32, 256, 64), (64, 32, 256, 32), (64, 32, 128, 2048), (64, 32, 128, 1024), (64, 32, 128, 512), (64, 32, 128, 256), (64, 32, 128, 128), (64, 32, 128, 64), (64, 32, 128, 32), (64, 32, 64, 2048), (64, 32, 64, 1024), (64, 32, 64, 512), (64, 32, 64, 256), (64, 32, 64, 128), (64, 32, 64, 64), (64, 32, 64, 32), (64, 32, 32, 2048), (64, 32, 32, 1024), (64, 32, 32, 512), (64, 32, 32, 256), (64, 32, 32, 128), (64, 32, 32, 64), (64, 32, 32, 32), (32, 2048, 2048, 2048), (32, 2048, 2048, 1024), (32, 2048, 2048, 512), (32, 2048, 2048, 256), (32, 2048, 2048, 128), (32, 2048, 2048, 64), (32, 2048, 2048, 32), (32, 2048, 1024, 2048), (32, 2048, 1024, 1024), (32, 2048, 1024, 512), (32, 2048, 1024, 256), (32, 2048, 1024, 128), (32, 2048, 1024, 64), (32, 2048, 1024, 32), (32, 2048, 512, 2048), (32, 2048, 512, 1024), (32, 2048, 512, 512), (32, 2048, 512, 256), (32, 2048, 512, 128), (32, 2048, 512, 64), (32, 2048, 512, 32), (32, 2048, 256, 2048), (32, 2048, 256, 1024), (32, 2048, 256, 512), (32, 2048, 256, 256), (32, 2048, 256, 128), (32, 2048, 256, 64), (32, 2048, 256, 32), (32, 2048, 128, 2048), (32, 2048, 128, 1024), (32, 2048, 128, 512), (32, 2048, 128, 256), (32, 2048, 128, 128), (32, 2048, 128, 64), (32, 2048, 128, 32), (32, 2048, 64, 2048), (32, 2048, 64, 1024), (32, 2048, 64, 512), (32, 2048, 64, 256), (32, 2048, 64, 128), (32, 2048, 64, 64), (32, 2048, 64, 32), (32, 2048, 32, 2048), (32, 2048, 32, 1024), (32, 2048, 32, 512), (32, 2048, 32, 256), (32, 2048, 32, 128), (32, 2048, 32, 64), (32, 2048, 32, 32), (32, 1024, 2048, 2048), (32, 1024, 2048, 1024), (32, 1024, 2048, 512), (32, 1024, 2048, 256), (32, 1024, 2048, 128), (32, 1024, 2048, 64), (32, 1024, 2048, 32), (32, 1024, 1024, 2048), (32, 1024, 1024, 1024), (32, 1024, 1024, 512), (32, 1024, 1024, 256), (32, 1024, 1024, 128), (32, 1024, 1024, 64), (32, 1024, 1024, 32), (32, 1024, 512, 2048), (32, 1024, 512, 1024), (32, 1024, 512, 512), (32, 1024, 512, 256), (32, 1024, 512, 128), (32, 1024, 512, 64), (32, 1024, 512, 32), (32, 1024, 256, 2048), (32, 1024, 256, 1024), (32, 1024, 256, 512), (32, 1024, 256, 256), (32, 1024, 256, 128), (32, 1024, 256, 64), (32, 1024, 256, 32), (32, 1024, 128, 2048), (32, 1024, 128, 1024), (32, 1024, 128, 512), (32, 1024, 128, 256), (32, 1024, 128, 128), (32, 1024, 128, 64), (32, 1024, 128, 32), (32, 1024, 64, 2048), (32, 1024, 64, 1024), (32, 1024, 64, 512), (32, 1024, 64, 256), (32, 1024, 64, 128), (32, 1024, 64, 64), (32, 1024, 64, 32), (32, 1024, 32, 2048), (32, 1024, 32, 1024), (32, 1024, 32, 512), (32, 1024, 32, 256), (32, 1024, 32, 128), (32, 1024, 32, 64), (32, 1024, 32, 32), (32, 512, 2048, 2048), (32, 512, 2048, 1024), (32, 512, 2048, 512), (32, 512, 2048, 256), (32, 512, 2048, 128), (32, 512, 2048, 64), (32, 512, 2048, 32), (32, 512, 1024, 2048), (32, 512, 1024, 1024), (32, 512, 1024, 512), (32, 512, 1024, 256), (32, 512, 1024, 128), (32, 512, 1024, 64), (32, 512, 1024, 32), (32, 512, 512, 2048), (32, 512, 512, 1024), (32, 512, 512, 512), (32, 512, 512, 256), (32, 512, 512, 128), (32, 512, 512, 64), (32, 512, 512, 32), (32, 512, 256, 2048), (32, 512, 256, 1024), (32, 512, 256, 512), (32, 512, 256, 256), (32, 512, 256, 128), (32, 512, 256, 64), (32, 512, 256, 32), (32, 512, 128, 2048), (32, 512, 128, 1024), (32, 512, 128, 512), (32, 512, 128, 256), (32, 512, 128, 128), (32, 512, 128, 64), (32, 512, 128, 32), (32, 512, 64, 2048), (32, 512, 64, 1024), (32, 512, 64, 512), (32, 512, 64, 256), (32, 512, 64, 128), (32, 512, 64, 64), (32, 512, 64, 32), (32, 512, 32, 2048), (32, 512, 32, 1024), (32, 512, 32, 512), (32, 512, 32, 256), (32, 512, 32, 128), (32, 512, 32, 64), (32, 512, 32, 32), (32, 256, 2048, 2048), (32, 256, 2048, 1024), (32, 256, 2048, 512), (32, 256, 2048, 256), (32, 256, 2048, 128), (32, 256, 2048, 64), (32, 256, 2048, 32), (32, 256, 1024, 2048), (32, 256, 1024, 1024), (32, 256, 1024, 512), (32, 256, 1024, 256), (32, 256, 1024, 128), (32, 256, 1024, 64), (32, 256, 1024, 32), (32, 256, 512, 2048), (32, 256, 512, 1024), (32, 256, 512, 512), (32, 256, 512, 256), (32, 256, 512, 128), (32, 256, 512, 64), (32, 256, 512, 32), (32, 256, 256, 2048), (32, 256, 256, 1024), (32, 256, 256, 512), (32, 256, 256, 256), (32, 256, 256, 128), (32, 256, 256, 64), (32, 256, 256, 32), (32, 256, 128, 2048), (32, 256, 128, 1024), (32, 256, 128, 512), (32, 256, 128, 256), (32, 256, 128, 128), (32, 256, 128, 64), (32, 256, 128, 32), (32, 256, 64, 2048), (32, 256, 64, 1024), (32, 256, 64, 512), (32, 256, 64, 256), (32, 256, 64, 128), (32, 256, 64, 64), (32, 256, 64, 32), (32, 256, 32, 2048), (32, 256, 32, 1024), (32, 256, 32, 512), (32, 256, 32, 256), (32, 256, 32, 128), (32, 256, 32, 64), (32, 256, 32, 32), (32, 128, 2048, 2048), (32, 128, 2048, 1024), (32, 128, 2048, 512), (32, 128, 2048, 256), (32, 128, 2048, 128), (32, 128, 2048, 64), (32, 128, 2048, 32), (32, 128, 1024, 2048), (32, 128, 1024, 1024), (32, 128, 1024, 512), (32, 128, 1024, 256), (32, 128, 1024, 128), (32, 128, 1024, 64), (32, 128, 1024, 32), (32, 128, 512, 2048), (32, 128, 512, 1024), (32, 128, 512, 512), (32, 128, 512, 256), (32, 128, 512, 128), (32, 128, 512, 64), (32, 128, 512, 32), (32, 128, 256, 2048), (32, 128, 256, 1024), (32, 128, 256, 512), (32, 128, 256, 256), (32, 128, 256, 128), (32, 128, 256, 64), (32, 128, 256, 32), (32, 128, 128, 2048), (32, 128, 128, 1024), (32, 128, 128, 512), (32, 128, 128, 256), (32, 128, 128, 128), (32, 128, 128, 64), (32, 128, 128, 32), (32, 128, 64, 2048), (32, 128, 64, 1024), (32, 128, 64, 512), (32, 128, 64, 256), (32, 128, 64, 128), (32, 128, 64, 64), (32, 128, 64, 32), (32, 128, 32, 2048), (32, 128, 32, 1024), (32, 128, 32, 512), (32, 128, 32, 256), (32, 128, 32, 128), (32, 128, 32, 64), (32, 128, 32, 32), (32, 64, 2048, 2048), (32, 64, 2048, 1024), (32, 64, 2048, 512), (32, 64, 2048, 256), (32, 64, 2048, 128), (32, 64, 2048, 64), (32, 64, 2048, 32), (32, 64, 1024, 2048), (32, 64, 1024, 1024), (32, 64, 1024, 512), (32, 64, 1024, 256), (32, 64, 1024, 128), (32, 64, 1024, 64), (32, 64, 1024, 32), (32, 64, 512, 2048), (32, 64, 512, 1024), (32, 64, 512, 512), (32, 64, 512, 256), (32, 64, 512, 128), (32, 64, 512, 64), (32, 64, 512, 32), (32, 64, 256, 2048), (32, 64, 256, 1024), (32, 64, 256, 512), (32, 64, 256, 256), (32, 64, 256, 128), (32, 64, 256, 64), (32, 64, 256, 32), (32, 64, 128, 2048), (32, 64, 128, 1024), (32, 64, 128, 512), (32, 64, 128, 256), (32, 64, 128, 128), (32, 64, 128, 64), (32, 64, 128, 32), (32, 64, 64, 2048), (32, 64, 64, 1024), (32, 64, 64, 512), (32, 64, 64, 256), (32, 64, 64, 128), (32, 64, 64, 64), (32, 64, 64, 32), (32, 64, 32, 2048), (32, 64, 32, 1024), (32, 64, 32, 512), (32, 64, 32, 256), (32, 64, 32, 128), (32, 64, 32, 64), (32, 64, 32, 32), (32, 32, 2048, 2048), (32, 32, 2048, 1024), (32, 32, 2048, 512), (32, 32, 2048, 256), (32, 32, 2048, 128), (32, 32, 2048, 64), (32, 32, 2048, 32), (32, 32, 1024, 2048), (32, 32, 1024, 1024), (32, 32, 1024, 512), (32, 32, 1024, 256), (32, 32, 1024, 128), (32, 32, 1024, 64), (32, 32, 1024, 32), (32, 32, 512, 2048), (32, 32, 512, 1024), (32, 32, 512, 512), (32, 32, 512, 256), (32, 32, 512, 128), (32, 32, 512, 64), (32, 32, 512, 32), (32, 32, 256, 2048), (32, 32, 256, 1024), (32, 32, 256, 512), (32, 32, 256, 256), (32, 32, 256, 128), (32, 32, 256, 64), (32, 32, 256, 32), (32, 32, 128, 2048), (32, 32, 128, 1024), (32, 32, 128, 512), (32, 32, 128, 256), (32, 32, 128, 128), (32, 32, 128, 64), (32, 32, 128, 32), (32, 32, 64, 2048), (32, 32, 64, 1024), (32, 32, 64, 512), (32, 32, 64, 256), (32, 32, 64, 128), (32, 32, 64, 64), (32, 32, 64, 32), (32, 32, 32, 2048), (32, 32, 32, 1024), (32, 32, 32, 512), (32, 32, 32, 256), (32, 32, 32, 128), (32, 32, 32, 64), (32, 32, 32, 32)]\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/content/mydeeplearning/ez_mlp.py\", line 583, in tune_train_network\n",
            "    print('Global Counter: '+global_counter+' EXP-ID : '+exp_id+'  DurationSinceStart :',datetime.timedelta(seconds = time.time() - start_time),' Starting New Experiment with %hidden_layers: {',hidden_layers,'}% %hidden_layer_width: {',hidden_layer ,'}% %Learning_Rate: {',lr, '}% %drop_ratio: {',drop_ratio,'}%')\n",
            "TypeError: must be str, not int\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}