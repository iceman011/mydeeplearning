{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcIoGjineB3h0pFIhWDZIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iceman011/mydeeplearning/blob/master/ez_deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBXy2soVzPQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "46c40f9d-d767-4a1e-95cc-a21d0785549d"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import datetime\n",
        "import os\n",
        "import pdb\n",
        "import sys\n",
        "import torchvision.models as pretrained_models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "  \n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "from torch import optim\n",
        "import itertools\n",
        "#!/usr/bin/env python3\n",
        "import mmap\n",
        "import re\n",
        "from itertools import dropwhile, product\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers,output_classes,transform,dataset, drop_p=0.5,lr =0.001, train_on_gpu=False,network_type ='normal',replace_full_classifier=False):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input layer\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "        \n",
        "        '''\n",
        "        super().__init__()\n",
        "        if train_on_gpu:\n",
        "          # check if CUDA is available\n",
        "          self.train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "        if not self.train_on_gpu:\n",
        "            print('CUDA is not available.  Using CPU ...')\n",
        "        else:\n",
        "            print('CUDA is available!  Using GPU ...')\n",
        "        \n",
        "        if(network_type == 'normal'):\n",
        "          print('init Network with Type ',network_type)    \n",
        "          self.input_size = input_size\n",
        "          \n",
        "          # Input to a hidden layer\n",
        "          self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "          \n",
        "          # Add a variable number of more hidden layers\n",
        "          layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "          self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "          \n",
        "          self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "          \n",
        "          self.dropout = nn.Dropout(p=drop_p)\n",
        "\n",
        "        else:\n",
        "          self.init_pre_trained_model(hidden_layers,network_type,output_size,replace_full_classifier)\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = lr\n",
        "        self.drop_ratio = drop_p\n",
        "        self.output_classes = output_classes\n",
        "        self.transform=transform\n",
        "        self.dataset=dataset\n",
        "        self.network_type = network_type\n",
        "        self.replace_full_classifier = replace_full_classifier\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        if(self.network_type == 'normal'):\n",
        "          for each in self.hidden_layers:\n",
        "              x = F.relu(each(x))\n",
        "              x = self.dropout(x)\n",
        "        else:\n",
        "          x = self.classifier(x)\n",
        "          \n",
        "        x = self.output(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    #https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#model-training-and-validation-code\n",
        "    def init_pre_trained_model(self,hidden_layers,network_type,output_size,replace_full_classifier):\n",
        "        print('init Network with Type ',network_type)\n",
        "        if ( network_type == 'alexnet'):\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model = pretrained_models.alexnet(pretrained=True)\n",
        "            self.pre_trained_model.classifier[1] = nn.Linear(self.pre_trained_model.classifier[1].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[1].in_features\n",
        "        elif ( network_type == 'vgg11'):\n",
        "            self.pre_trained_model = pretrained_models.vgg11(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg11_bn'):\n",
        "            self.pre_trained_model = pretrained_models.vgg11_bn(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg13'):\n",
        "            self.pre_trained_model = pretrained_models.vgg13(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg13_bn'):\n",
        "            self.pre_trained_model = pretrained_models.vgg13_bn(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg16'):\n",
        "            self.pre_trained_model = pretrained_models.vgg16(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg16_bn'):\n",
        "            self.pre_trained_model = pretrained_models.vgg16_bn(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg19'):\n",
        "            self.pre_trained_model = pretrained_models.vgg19(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'vgg19_bn'):\n",
        "            self.pre_trained_model = pretrained_models.vgg19_bn(pretrained=True)\n",
        "            self.freeze_parameters()\n",
        "            self.pre_trained_model.classifier[6] = nn.Linear(self.pre_trained_model.classifier[6].in_features,output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier[6].in_features\n",
        "        elif ( network_type == 'resnet18'):\n",
        "            self.pre_trained_model = pretrained_models.resnet18(pretrained=True)\n",
        "            self.pre_trained_model.fc = nn.Linear(pre_trained_model.fc.in_features,output_size)\n",
        "            self.input_size = pre_trained_model.fc.in_features\n",
        "        elif ( network_type == 'resnet34'):\n",
        "            self.pre_trained_model = pretrained_models.resnet34(pretrained=True)\n",
        "            self.pre_trained_model.fc = nn.Linear(pre_trained_model.fc.in_features,output_size)\n",
        "            self.input_size = pre_trained_model.fc.in_features\n",
        "        elif ( network_type == 'resnet50'):\n",
        "            self.pre_trained_model = pretrained_models.resnet50(pretrained=True)\n",
        "            self.pre_trained_model.fc = nn.Linear(pre_trained_model.fc.in_features,output_size)\n",
        "            self.input_size = pre_trained_model.fc.in_features\n",
        "        elif ( network_type == 'resnet101'):\n",
        "            self.pre_trained_model = pretrained_models.resnet101(pretrained=True)\n",
        "            pre_trained_model.fc = nn.Linear(pre_trained_model.fc.in_features,output_size)\n",
        "            self.input_size = pre_trained_model.fc.in_features\n",
        "        elif ( network_type == 'resnet152'):\n",
        "            self.pre_trained_model = pretrained_models.resnet152(pretrained=True)\n",
        "            self.pre_trained_model.fc = nn.Linear(pre_trained_model.fc.in_features,output_size)\n",
        "            self.input_size = pre_trained_model.fc.in_features\n",
        "        elif ( network_type == 'squeezenet1_0'):\n",
        "            self.pre_trained_model = pretrained_models.squeezenet1_0(pretrained=True)\n",
        "            self.pre_trained_model.classifier[1] = nn.Conv2d(512, output_size, kernel_size=(1,1), stride=(1,1))\n",
        "            self.input_size = 512\n",
        "        elif ( network_type == 'squeezenet1_1'):\n",
        "            self.pre_trained_model = pretrained_models.squeezenet1_1(pretrained=True)\n",
        "            self.pre_trained_model.classifier[1] = nn.Conv2d(512, output_size, kernel_size=(1,1), stride=(1,1))\n",
        "            self.input_size = 512\n",
        "        elif ( network_type == 'densenet121'):\n",
        "            self.pre_trained_model = pretrained_models.densenet121(pretrained=True)\n",
        "            self.pre_trained_model.classifier = nn.Linear(self.pre_trained_model.classifier.in_features, output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier.in_features\n",
        "        elif ( network_type == 'densenet169'):\n",
        "            self.pre_trained_model = pretrained_models.densenet169(pretrained=True)\n",
        "            self.pre_trained_model.classifier = nn.Linear(self.pre_trained_model.classifier.in_features, output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier.in_features\n",
        "        elif ( network_type == 'densenet161'):\n",
        "            self.pre_trained_model = pretrained_models.densenet161(pretrained=True)\n",
        "            self.pre_trained_model.classifier = nn.Linear(self.pre_trained_model.classifier.in_features, output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier.in_features\n",
        "        elif ( network_type == 'densenet201'):\n",
        "            self.pre_trained_model = pretrained_models.densenet201(pretrained=True)\n",
        "            self.pre_trained_model.classifier = nn.Linear(self.pre_trained_model.classifier.in_features, output_size)\n",
        "            self.input_size = self.pre_trained_model.classifier.in_features\n",
        "        #elif ( network_type == 'inception_v3'):\n",
        "        #    self.pre_trained_model = pretrained_models.inception_v3(pretrained=True)\n",
        "        #    self.input_size = model.fc.in_features\n",
        "\n",
        "        \"\"\"    \n",
        "        #print(model)\n",
        "        # here we get all the modules(layers) before the fc layer at the end\n",
        "        # note that currently at pytorch 1.0 the named_children() is not supported\n",
        "        # and using that instead of children() will fail with an error\n",
        "        self.features = nn.ModuleList(model.children())[:-1]\n",
        "\n",
        "        # Now we have our layers up to the fc layer, but we are not finished yet \n",
        "        # we need to feed these to nn.Sequential() as well, this is needed because,\n",
        "        # nn.ModuleList doesnt implement forward() \n",
        "        # so you cant do sth like self.features(images). Therefore we use \n",
        "        # nn.Sequential and since sequential doesnt accept lists, we \n",
        "        # unpack all the items and send them like this\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # now lets add our new layers \n",
        "        #in_features = model.fc.in_features\n",
        "\n",
        "        hidden_layers = [item for item in hidden_layers]\n",
        "        hidden_layers.insert(0,self.input_size)\n",
        "\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.network_type = network_type\n",
        "      \"\"\"\n",
        "        # replace last layer of classifier completely with new fully connected dynamic hidden layers  \n",
        "        if(replace_full_classifier) :\n",
        "          self.pre_trained_model.classifier, self.pre_trained_model.output = self.make_dynamic_layers(hidden_layers,output_size)\n",
        "        \n",
        "        \n",
        "    def parameters_to_update(model_ft,network_type):\n",
        "      if(network_type == 'normal' ):\n",
        "        params_to_update = model_ft.parameters()\n",
        "      print(\"Params to learn:\")\n",
        "      if network_type != 'normal' :\n",
        "          params_to_update = []\n",
        "          for name,param in model_ft.pre_trained_model.named_parameters():\n",
        "              if param.requires_grad == True:\n",
        "                  params_to_update.append(param)\n",
        "                  print(\"\\t\",name)\n",
        "      else:\n",
        "          for name,param in model_ft.named_parameters():\n",
        "              if param.requires_grad == True:\n",
        "                  print(\"\\t\",name)\n",
        "      return params_to_update\n",
        "\n",
        "    def freeze_parameters(self):\n",
        "      # Freeze parameters so we don't backprop through them\n",
        "      for param in self.pre_trained_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    def make_dynamic_layers(self,layers,n_classes):\n",
        "        layers_block = nn.Sequential(*[\n",
        "                                    nn.Sequential(\n",
        "                                        nn.Linear(in_f, out_f),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout()\n",
        "                                        ) \n",
        "                          for in_f, out_f in zip(layers, layers[1:])])\n",
        "        \n",
        "        output = nn.Linear(layers[-1], n_classes)\n",
        "        \n",
        "        return layers_block,output\n",
        "\n",
        "\"\"\"\n",
        "class PreTrainenModels(nn.Module):\n",
        "      \n",
        "      def __init__(self, input_size, output_size, hidden_layers,output_classes,transform,dataset, drop_p=0.5,lr =0.001, train_on_gpu=False,network_type ='normal'):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        if ( network_type == 'resnet18'):\n",
        "          #assert input_size == 1024 ,  'input features of pre-trained networks must bet 1024'\n",
        "          model = pretrained_models.resnet18(pretrained=True)\n",
        "          input_size = model.fc.in_features\n",
        "          \n",
        "        #print(model)\n",
        "        # here we get all the modules(layers) before the fc layer at the end\n",
        "        # note that currently at pytorch 1.0 the named_children() is not supported\n",
        "        # and using that instead of children() will fail with an error\n",
        "        self.features = nn.ModuleList(model.children())[:-1]\n",
        "\n",
        "        # Now we have our layers up to the fc layer, but we are not finished yet \n",
        "        # we need to feed these to nn.Sequential() as well, this is needed because,\n",
        "        # nn.ModuleList doesnt implement forward() \n",
        "        # so you cant do sth like self.features(images). Therefore we use \n",
        "        # nn.Sequential and since sequential doesnt accept lists, we \n",
        "        # unpack all the items and send them like this\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # now lets add our new layers \n",
        "        in_features = model.fc.in_features\n",
        "\n",
        "        # from now, you can add any kind of layers in any quantity!  \n",
        "        # Here I'm creating two new layers \n",
        "        #self.fc0 = nn.Linear(in_features, 256)\n",
        "        #self.fc0_bn = nn.BatchNorm1d(256, eps = 1e-2)\n",
        "        #self.fc1 = nn.Linear(256, output_size)\n",
        "        #self.fc1_bn = nn.BatchNorm1d(output_size, eps = 1e-2)\n",
        "        \n",
        "        # initialize all fc layers to xavier\n",
        "        #for m in self.modules():\n",
        "        #    if isinstance(m, nn.Linear):\n",
        "        #        torch.nn.init.xavier_normal_(m.weight, gain = 1)\n",
        "        \n",
        "        hidden_layers = [item for item in hidden_layers]\n",
        "        hidden_layers.insert(0,in_features)\n",
        "\n",
        "        self.hidden_layers = hidden_layers\n",
        "        \n",
        "        self.classifier, self.output = classifier_block(hidden_layers,output_size) #MyPreTrainedClassifier(hidden_layers,output_size)\n",
        "        \n",
        "        #self.model = model\n",
        "        #self.model.last_linear= self.classifier\n",
        "        #self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        #self.dropout = nn.Dropout(p=drop_p)\n",
        "\n",
        "        self.classifier = nn.Sequential(OrderedDict([\n",
        "                                  ('fc1', nn.Linear(in_features, 500)),\n",
        "                                  ('relu', nn.ReLU()),\n",
        "                                  ('fc2', nn.Linear(500, output_size)),\n",
        "                                  ('output', nn.LogSoftmax(dim=1))\n",
        "                                  ]))\n",
        "           \n",
        "        #model.classifier = classifier\n",
        "\n",
        "        # Freeze parameters so we don't backprop through them\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        if train_on_gpu:\n",
        "          # check if CUDA is available\n",
        "          self.train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "        if not self.train_on_gpu:\n",
        "            print('CUDA is not available.  Using CPU ...')\n",
        "        else:\n",
        "            print('CUDA is available!  Using GPU ...')\n",
        "            \n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = lr\n",
        "        self.drop_ratio = drop_p\n",
        "        self.output_classes = output_classes\n",
        "        self.transform=transform\n",
        "        self.dataset=dataset\n",
        "        self.network_type= network_type\n",
        "\n",
        "\n",
        "      def get_dense_net(self):        \n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = None\n",
        "\n",
        "        if ( self.network_type == 'densenet121'):\n",
        "          assert self.input_size == 1024 ,  'input features of pre-trained networks must bet 1024'\n",
        "          model = pretrained_models.densenet121(pretrained=True)\n",
        "\n",
        "        # Freeze parameters so we don't backprop through them\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "        model.classifier = nn.Sequential(nn.Linear(self.input_size, 256),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(self.drop_ratio),\n",
        "                                        nn.Linear(256, self.output_size),\n",
        "                                        nn.LogSoftmax(dim=1))\n",
        "\n",
        "        criterion = nn.NLLLoss()\n",
        "\n",
        "        # Only train the classifier parameters, feature parameters are frozen\n",
        "        optimizer = optim.Adam(model.classifier.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        model.to(device)\n",
        "        \n",
        "        return model , criterion , optimizer\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        #return self.model(x)\n",
        "       # now in forward pass, you have the full control, \n",
        "       # we can use the feature part from our pretrained model  like this\n",
        "        #x = self.features(x)\n",
        "\n",
        "        # since we are using fc layers from now on, we need to flatten the output.\n",
        "        # we used the avgpooling but we still need to flatten from the shape (batch, 1,1, features)\n",
        "        # to (batch, features) so we reshape like this. input_imgs.size(0) gives the batchsize, and \n",
        "        # we use -1 for inferring the rest\n",
        "        #output = output.view(input_imgs.size(0), -1)\n",
        "       # and also our new layers. \n",
        "        #output = self.fc0_bn(F.relu(self.fc1(output)))\n",
        "        #output = self.fc1_bn(F.relu(self.fc1(output)))\n",
        "        \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        #x = F.relu(self.classifier.fc1(x))\n",
        "        #x = self.dropout(x)\n",
        "        #x = F.relu(self.classifier.fc2(x))\n",
        "        #x = self.dropout(x)\n",
        "        #x = self.classifier.output(x)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MyPreTrainedClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, classifier_sizes, n_classes):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Sequential(*[classifier_block(in_f, out_f) \n",
        "                       for in_f, out_f in zip(classifier_sizes, classifier_sizes[1:])])\n",
        "        self.output = nn.Linear(classifier_sizes[-1], n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        for each in self.hidden_layers:\n",
        "            x = F.relu(each(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def forward_last(self, x):\n",
        "      x = self.classifier(x)\n",
        "      x = self.output(x)\n",
        "\n",
        "      for each in self.hidden_layers:\n",
        "        x = F.relu(each(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "      \n",
        "      return F.log_softmax(x, dim=1)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "######################    \n",
        "# LOADING DATA #\n",
        "######################\n",
        "def LoadData(datasetName,batch_size=20,valid_size = 0.2,network_type='normal'):\n",
        "      \n",
        "    # number of subprocesses to use for data loading\n",
        "    num_workers = 0\n",
        "\n",
        "    # convert data to torch.FloatTensor\n",
        "    #transform = transforms.ToTensor()\n",
        "\n",
        "    # convert data to a normalized torch.FloatTensor\n",
        "    transform = None\n",
        "    train_data= None\n",
        "    valid_data= None\n",
        "    test_data=None\n",
        "    classes=None\n",
        "    normalize = None\n",
        "\n",
        "    if network_type != 'normal' :\n",
        "      normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    elif network_type == 'normal' and datasetName == 'MINST' :\n",
        "      normalize = transforms.Normalize((0.5, ), (0.5, ))\n",
        "    elif network_type == 'normal' and datasetName == 'CIFAR' :\n",
        "      normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "    if(datasetName == 'MINST'):\n",
        "       # convert data to a normalized torch.FloatTensor\n",
        "      train_transform = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "          #transforms.RandomRotation(10),\n",
        "          transforms.CenterCrop(224),  \n",
        "          transforms.RandomResizedCrop(224),        \n",
        "          transforms.ToTensor(),\n",
        "          normalize\n",
        "          ])\n",
        "\n",
        "      valid_transform = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Resize(224),\n",
        "          normalize\n",
        "          ])\n",
        "\n",
        "      # choose the training and test datasets\n",
        "      train_data = datasets.MNIST(root='data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "      valid_data = datasets.MNIST(root='data', train=False,\n",
        "                                        download=True, transform=valid_transform)\n",
        "      test_data = datasets.MNIST(root='data', train=False,\n",
        "                                        download=True, transform=valid_transform)\n",
        "      # specify the image classes\n",
        "      classes = ['1', '2', '3', '4', '5',\n",
        "           '6', '7', '8', '9', '10']\n",
        "    elif(datasetName == 'CIFAR'):\n",
        "      \n",
        "      # convert data to a normalized torch.FloatTensor\n",
        "      valid_transform = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          #transforms.Resize(224),\n",
        "          normalize\n",
        "          ])\n",
        "      \n",
        "      train_transform = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "          transforms.RandomRotation(10),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.RandomResizedCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          normalize\n",
        "          ])\n",
        "      \n",
        "      # choose the training and test datasets\n",
        "      train_data = datasets.CIFAR10(root='data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "      valid_data = datasets.CIFAR10(root='data', train=True,\n",
        "                                        download=True, transform=valid_transform)\n",
        "      test_data = datasets.CIFAR10(root='data', train=False,\n",
        "                                        download=True, transform=valid_transform)\n",
        "      # specify the image classes\n",
        "      classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    # obtain training indices that will be used for validation\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # define samplers for obtaining training and validation batches\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # prepare data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "        sampler=train_sampler, num_workers=num_workers)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
        "        sampler=valid_sampler, num_workers=num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "        num_workers=num_workers)\n",
        "    return train_loader , valid_loader ,test_loader ,classes , transform\n",
        "\n",
        "\n",
        "\n",
        "#############################\n",
        "# VALIDATE MODEL\n",
        "############################\n",
        "def validation(model, validationloader, criterion):\n",
        "    accuracy = 0\n",
        "    validation_loss = 0\n",
        "    validate_start_time = time.time()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : ','Starting Validation....')\n",
        "\n",
        "    base_model = model\n",
        "\n",
        "    if(model.network_type != 'normal'):\n",
        "      base_model = model.pre_trained_model\n",
        "\n",
        "    with torch.no_grad():    \n",
        "      # move tensors to GPU if CUDA is available\n",
        "      if model.train_on_gpu:\n",
        "        base_model.cuda()\n",
        "\n",
        "      for images, labels in validationloader:\n",
        "\n",
        "          if model.train_on_gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "          \n",
        "          if(model.network_type == 'normal'):\n",
        "            images = images.resize_(images.size()[0], model.input_size)\n",
        "\n",
        "          output = base_model.forward(images)\n",
        "          validation_loss += criterion(output, labels).item()\n",
        "\n",
        "          ## Calculating the accuracy \n",
        "          # Model's output is log-softmax, take exponential to get the probabilities\n",
        "          ps = torch.exp(output)\n",
        "          # Class with highest probability is our predicted class, compare with true label\n",
        "          #equality = (labels.data == ps.max(1)[1])\n",
        "          # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
        "          #accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "\n",
        "\n",
        "          top_p, top_class = ps.topk(1, dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor))            \n",
        "        \n",
        "      validation_loss = validation_loss/len(validationloader)\n",
        "      accuracy = 100. * accuracy/len(validationloader)\n",
        "    \n",
        "    print('Finished Validation In ',datetime.timedelta(seconds = time.time() - validate_start_time) )\n",
        "    return validation_loss, accuracy\n",
        "\n",
        "#############################\n",
        "# TEST MODEL\n",
        "############################\n",
        "def test(model,test_loader,criterion,checkpoint,outputfilepath,batch_size,override_checkpoint):\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(model.output_size))\n",
        "    class_total = list(0. for i in range(model.output_size))\n",
        "    test_start_time = time.time()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Testing....')\n",
        "\n",
        "    base_model = model\n",
        "\n",
        "    if(model.network_type != 'normal'):\n",
        "      base_model = model.pre_trained_model\n",
        "\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if model.train_on_gpu:\n",
        "      base_model.cuda()\n",
        "\n",
        "    with torch.no_grad():    \n",
        "      base_model.eval()\n",
        "      # iterate over test data\n",
        "      for data, target in test_loader:\n",
        "          # move tensors to GPU if CUDA is available\n",
        "          if model.train_on_gpu:\n",
        "              data, target = data.cuda(), target.cuda()\n",
        "          \n",
        "          if(model.network_type == 'normal'):\n",
        "            # Flatten images into a 784 long vector\n",
        "            data.resize_(data.size()[0], model.input_size)\n",
        "\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = base_model(data)\n",
        "          # calculate the batch loss\n",
        "          loss = criterion(output, target)\n",
        "          # update test loss \n",
        "          test_loss += loss.item()*data.size(0)\n",
        "          # convert output probabilities to predicted class\n",
        "          _, pred = torch.max(output, 1)    \n",
        "          # compare predictions to true label\n",
        "          correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "          correct = np.squeeze(correct_tensor.numpy()) if not model.train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "          # calculate test accuracy for each object class\n",
        "          for i in range(batch_size):\n",
        "              label = target.data[i]\n",
        "              class_correct[label] += correct[i].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "      # average test loss\n",
        "      print('Finished Testing during ',datetime.timedelta(seconds=time.time() - test_start_time))\n",
        "      test_loss = test_loss/len(test_loader.dataset)\n",
        "      print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "      \n",
        "      test_checkpoint = dict()\n",
        "\n",
        "      if(override_checkpoint):\n",
        "        checkpoint.update({'TestLoss': test_loss})\n",
        "      else :\n",
        "        test_checkpoint.update({'TestLoss': test_loss})\n",
        "\n",
        "      for i in range(model.output_size):\n",
        "          if class_total[i] > 0:\n",
        "            current_key  = 'Test Accuracy of '+model.output_classes[i]\n",
        "            current_val = '{:.3f}% ({}/{})'.format(100 *( class_correct[i] / class_total[i]),\n",
        "                  np.sum(class_correct[i]), np.sum(class_total[i]))\n",
        "            ele={current_key:current_val}\n",
        "            if(override_checkpoint):\n",
        "              checkpoint.update(ele)\n",
        "              print(current_key,current_val)\n",
        "            else:\n",
        "              test_checkpoint.update(ele)\n",
        "\n",
        "\n",
        "          \"\"\"else:\n",
        "              print('Test Accuracy of %5s: N/A (no training examples)' % (model.output_classes[i]))\n",
        "          \"\"\"\n",
        "\n",
        "      current_key = 'Test Accuracy (Overall): '#.format(100. * np.sum(class_correct) / np.sum(class_total))\n",
        "      current_val = '{:.3f}% ({}/{})'.format(100 * (np.sum(class_correct) / np.sum(class_total)),\n",
        "          np.sum(class_correct), np.sum(class_total) )\n",
        "      ele={current_key:current_val}\n",
        "      if(override_checkpoint):\n",
        "        checkpoint.update(ele)      \n",
        "        print(current_key,current_val)\n",
        "      else:\n",
        "        test_checkpoint.update(ele)\n",
        "        test_checkpoint.update({'Detailed ':checkpoint})\n",
        "\n",
        "    \n",
        "    #model.train()\n",
        "    if(override_checkpoint):\n",
        "      print('Overriding Checkpoint')\n",
        "      torch.save(checkpoint,outputfilepath)\n",
        "\n",
        "    return checkpoint , test_checkpoint\n",
        "\n",
        "#############################\n",
        "# TRAIN MODEL\n",
        "############################\n",
        "def train(model, trainloader, validationloader, criterion, optimizer, uploadToGDrive,checkpointPath,PreviousCheckPointId,\n",
        "          PreviousValidationLoss,start_time,exp_id,epochs=5, print_every=40):\n",
        "    # monitor training loss    \n",
        "    steps = 0    \n",
        "    #start_time = time.time()\n",
        "    #dateTimeObj = datetime.now()\n",
        "    #start_time_timestamp = './results/'+dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "    #start_time_timestamp = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "    train_losses, valid_losses = [], []\n",
        "    checkpoint = dict()\n",
        "    base_model = model\n",
        "\n",
        "    if(model.network_type != 'normal'):\n",
        "      base_model = model.pre_trained_model\n",
        "\n",
        "\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if model.train_on_gpu:\n",
        "      base_model.cuda()\n",
        "\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Training using Model Parameters \\n '+str(base_model)+' \\n from PreviousModel '+ PreviousCheckPointId + ' with validationLoss '+ str(PreviousValidationLoss) )\n",
        "    valid_loss_min = PreviousValidationLoss #np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "    for e in range(epochs):        \n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Starting Training of Epoch'+str(e)  )\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        base_model.train() # prep model for training\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            steps += 1\n",
        "            \n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if model.train_on_gpu:\n",
        "              images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "            if model.network_type == 'normal':\n",
        "              # Flatten images into a 784 long vector\n",
        "              images.resize_(images.size()[0], model.input_size)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = base_model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss = train_loss/len(trainloader.sampler)\n",
        "        train_losses.append(train_loss)\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        # Model in inference mode, dropout is off\n",
        "        base_model.eval()\n",
        "        print(' Finished Training of Epoch '+str(e),' In ',datetime.timedelta(seconds = time.time() - epoch_start_time) )\n",
        "\n",
        "        # Turn off gradients for validation, will speed up inference\n",
        "        with torch.no_grad():\n",
        "            valid_loss, accuracy = validation(model, validationloader, criterion)\n",
        "        \n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print('{} : Epoch: {} \\tTraining Loss: {:.9f} \\tValidation Loss: {:.9f} \\tAccuracy : {:.6f}'.format(\n",
        "            dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\"),\n",
        "            e, \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            accuracy\n",
        "            ))\n",
        "        \n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.9f} --> {:.9f} ,)  Accuracy: {:.6f}  TimeElapsed: {}.  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss,\n",
        "            accuracy,\n",
        "            (datetime.timedelta(seconds = time.time() - start_time))))\n",
        "            \n",
        "            checkpoint = {'InputSize': model.input_size,\n",
        "                  'OutputSize': model.output_size,\n",
        "                  'HiddenLayers': [each.out_features for each in model.hidden_layers] if model.network_type == 'normal' else model.pre_trained_model, \n",
        "                  'LearningRate':model.learning_rate,\n",
        "                  'DropRatio':model.drop_ratio,\n",
        "                  'TrainingLoss' :train_loss,\n",
        "                  'ValidationLoss':valid_loss,\n",
        "                  'ValidationAccuracy':accuracy,\n",
        "                  'ElapsedTime': datetime.timedelta(seconds = time.time() - start_time),\n",
        "                  'Dataset':model.dataset,\n",
        "                  'LastEpoch': e,\n",
        "                  'PreviousCheckPoint': PreviousCheckPointId,\n",
        "                  'GPUState': model.train_on_gpu,                  \n",
        "                  'OutputFolder' : (exp_id+'/'+ model.network_type) if model.network_type != 'normal' else exp_id,\n",
        "                  'CheckPointTimestamp': dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\"), #time.time(),\n",
        "                  'OutputFilePrefix' : 'checkpoint_',\n",
        "                  'OutputClasses': model.output_classes,\n",
        "                  'NetworkType' : model.network_type,\n",
        "                  'ReplaceFullClassifier' : model.replace_full_classifier,\n",
        "                  'Transforms': model.transform,\n",
        "                  'TrainingLosses' :train_losses,\n",
        "                  'ValidationLosses':valid_losses,\n",
        "                  'StateDictionay': base_model.state_dict()}\n",
        "            \n",
        "            save_model(checkpoint,uploadToGDrive,checkpointPath)\n",
        "            valid_loss_min = valid_loss\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "\n",
        "    return train_losses , valid_losses , checkpoint\n",
        "\n",
        "\n",
        "#############################\n",
        "# SAVE MODEL TO GOOGLE DRIVE\n",
        "############################\n",
        "def save_model(checkpoint,uploadToGDrive,checkpointPath):\n",
        "  \n",
        "  file_path = ''\n",
        "  if(uploadToGDrive):\n",
        "    drive.mount('/content/gdrive')\n",
        "    file_path = checkpointPath+checkpoint['OutputFolder']\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)      \n",
        "    #path = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch'])+'.pt'\n",
        "    print('Saving Model to ',file_path +'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "    torch.save(checkpoint, file_path +'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "  else:\n",
        "    file_path=checkpointPath+checkpoint['OutputFolder']\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "    print('Saving Model to ',file_path+'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "    torch.save(checkpoint, file_path+'/'+checkpoint['OutputFilePrefix']+str(checkpoint['CheckPointTimestamp'])+'_'+str(checkpoint['LastEpoch'])+'.pt')\n",
        "\n",
        "\n",
        "###########################\n",
        "# SKIP CERTAIN ENTERIES FROM ITERTOOLS.PRODUCT\n",
        "#####################33\n",
        "def resume(iterable, sentinel):\n",
        "    yield from dropwhile(lambda x: x != sentinel, iterable)\n",
        "\n",
        "#############################\n",
        "# LOAD LAST EXPERIMENT PARAMS\n",
        "##################################\n",
        "def load_last_exp_param(logPath,checkpointPath):\n",
        "\n",
        "  #with open(checkpointPath+'/3-3-2020.txt') as f:\n",
        "  #    total = f.read()\n",
        "  #    print( total.count('Starting New') )\n",
        "      \n",
        "  f = open(logPath, 'r')\n",
        "  content = f.read()\n",
        "  \n",
        "  replace_full_classifier = re.findall('ReplaceFullClassifier: \\{(.+?)\\}', content)\n",
        "  replace_full_classifier = replace_full_classifier[len(replace_full_classifier)-1]\n",
        "  replace_full_classifier = replace_full_classifier.strip()\n",
        "\n",
        "  network_type = re.findall('Network Type: \\{(.+?)\\}', content)\n",
        "  network_type = network_type[len(network_type)-1]\n",
        "\n",
        "  hidden_layers = re.findall('hidden_layers: \\{(.+?)\\}', content)\n",
        "  hidden_layers = int(hidden_layers[len(hidden_layers)-1])\n",
        "\n",
        "  hidden_layer_width = re.findall('hidden_layer_width: \\{(.+?)\\}', content)\n",
        "  hidden_layer_width = hidden_layer_width[len(hidden_layer_width)-1]\n",
        "\n",
        "  Learning_rate = re.findall('Learning_Rate: \\{(.+?)\\}', content)\n",
        "  Learning_rate = float(Learning_rate[len(Learning_rate)-1])\n",
        "\n",
        "  drop_ratio = re.findall('drop_ratio: \\{(.+?)\\}', content)\n",
        "  drop_ratio = float(drop_ratio[len(drop_ratio)-1])\n",
        "  prev_valid_loss = np.Inf\n",
        "  return_checkpoint = None\n",
        "  return_model = None\n",
        "\n",
        "  #for filename in os.listdir(checkpointPath):\n",
        "  for root, dirs, files in os.walk(checkpointPath):\n",
        "    for filename in files:\n",
        "      fname, fext = os.path.splitext(filename)\n",
        "      if( fext != '.pt' ):\n",
        "        continue\n",
        "\n",
        "      model , checkpoint , filepath = load_checkpoint(root,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')],load_model=True)\n",
        "      if( float(checkpoint['ValidationLoss']) < prev_valid_loss ):\n",
        "        prev_valid_loss = checkpoint['ValidationLoss']\n",
        "      \n",
        "      \n",
        "      #pdb.set_trace()\n",
        "      hidden_layer_width_local = hidden_layer_width.strip()\n",
        "      if(hidden_layer_width_local[len(hidden_layer_width_local)-2:] == ',)'):\n",
        "        hidden_layer_width_local = hidden_layer_width_local[1:len(hidden_layer_width_local)-2]\n",
        "      else:\n",
        "        hidden_layer_width_local = hidden_layer_width_local[1:len(hidden_layer_width_local)-1]\n",
        "      \n",
        "        \n",
        "      hidden_layer_width_local = list(map(int, hidden_layer_width_local.split(',')))\n",
        "\n",
        "      if( replace_full_classifier == checkpoint.get('ReplaceFullClassifier',False) and network_type == checkpoint['NetworkType'] and hidden_layer_width_local == checkpoint['HiddenLayers'] and float(checkpoint['ValidationLoss']) <= prev_valid_loss ):\n",
        "        print(' Found Matching Checkpoint with Last Experiement Parame ValidationLoss:{} hidden_layers:{}  hidden_layer_width:{} Learning_rate:{} drop_ratio:{} network_type:{} replace_full_classifier:{} '.format(checkpoint['ValidationLoss'],hidden_layers,hidden_layer_width_local,Learning_rate,drop_ratio,checkpoint['NetworkType'],checkpoint['ReplaceFullClassifier']))\n",
        "        return_checkpoint = checkpoint\n",
        "        return_model = model\n",
        "        prev_valid_loss = checkpoint['ValidationLoss']\n",
        "        #return checkpoint,model,hidden_layers,hidden_layer_width,Learning_rate,drop_ratio,prev_valid_loss\n",
        "\n",
        "  if( not bool(return_checkpoint)): \n",
        "    print(' Not Found Matching Checkpoint with Last Experiement Parameters hidden_layers:{}  hidden_layer_width:{} Learning_rate:{} drop_ratio:{} network_type:{} replace_full_classifier:{} '.format(hidden_layers,hidden_layer_width_local,Learning_rate,drop_ratio,network_type,replace_full_classifier))    \n",
        "\n",
        "  return return_checkpoint,return_model,hidden_layers,hidden_layer_width_local,Learning_rate,drop_ratio,prev_valid_loss,network_type,replace_full_classifier\n",
        "\n",
        "\n",
        "################################\n",
        "# TUNE NETWORK LAYERS AND NO. OF NODES\n",
        "##################################\n",
        "def tune_train_network(dataset,epochs,resumeExp=False,resume_logPath='',resume_checkpointPath='',network_type='normal'):\n",
        "\n",
        "  start_time = time.time()\n",
        "  dateTimeObj = dt.now()\n",
        "  exp_id = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
        "\n",
        "  #How many samples loaded per batch\n",
        "  batch_size = 20\n",
        "  \n",
        "  # percentage of training set to use as validation\n",
        "  valid_size = 0.2\n",
        "  \n",
        "  checkpointPath = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'\n",
        "  \n",
        "  #train_loader =None\n",
        "  #valid_loader =None\n",
        "  global_train_loss = None\n",
        "  global_valid_loss = None\n",
        "  \n",
        "  global_train_loss , global_valid_loss, min_train_loss , min_valid_loss = plotLossTrendAll(resume_checkpointPath,True,global_train_loss,global_valid_loss)\n",
        "\n",
        "  print('Starting Tunning With MinTrainLoss:', min_train_loss, ' MinValidLoss:',min_valid_loss)\n",
        "\n",
        "  #Load Data\n",
        "  drive.mount('/content/gdrive')\n",
        "  train_loader , valid_loader ,test_loader , classes , transform = LoadData(dataset,batch_size,valid_size,network_type)\n",
        "  \n",
        "  max_hidden_layers = 4\n",
        "  nodes_per_layer =  [2048, 1024, 512, 256, 128, 64, 32]\n",
        "  full_drop_ratios= [0.8, 0.5, 0.3, 0.1]\n",
        "  full_learning_rates= [0.0001, 0.001] #[0.1, 0.01, 0.0001, 0.001]\n",
        "  full_replace_full_classifier = [False,True]\n",
        "  \n",
        "  full_pre_trained_models = ['vgg11','vgg11_bn','vgg13','vgg13_bn','vgg16','vgg16_bn','vgg19','vgg19_bn',\n",
        "                             'resnet18','resnet34','resnet50','resnet101','resnet152',\n",
        "                             'squeezenet1_0','squeezenet1_1',\n",
        "                             'densenet121','densenet169','densenet161','densenet201',\n",
        "                             #'inception_v3',\n",
        "                             'alexnet'\n",
        "                            ] if network_type != 'normal' else ['normal']\n",
        "  learning_rates = None\n",
        "  drop_ratios = None\n",
        "  pre_trained_models = None\n",
        "  PreviousValidationLoss= min_valid_loss #np.Inf\n",
        "  \n",
        "  iter_hidden_layer_nodes = None\n",
        "  iter_hidden_layer_nodes_list = None\n",
        "  model = None\n",
        "  resume_checkpoint = None\n",
        "\n",
        "  if(resumeExp):\n",
        "    print(dt.now().strftime(\"%d_%b_%Y_%H_%M_%S\")+' : Resuming Experiment With New ID ',exp_id )\n",
        "    resume_checkpoint,model,resum_hidden_layers,resume_hidden_layer_width,resume_Learning_rate,resume_drop_ratio,resume_prev_valid_loss,resume_network_type, resume_replace_full_classifier =  load_last_exp_param(resume_logPath,resume_checkpointPath)\n",
        "    max_hidden_layers = resum_hidden_layers  \n",
        "\n",
        "    full_replace_full_classifier = full_replace_full_classifier[full_replace_full_classifier.index(bool(resume_replace_full_classifier)):]\n",
        "    learning_rates = full_learning_rates[full_learning_rates.index(resume_Learning_rate):]\n",
        "    drop_ratios = full_drop_ratios[full_drop_ratios.index(resume_drop_ratio):]\n",
        "    pre_trained_models = full_pre_trained_models[full_pre_trained_models.index(resume_network_type):]\n",
        "    PreviousValidationLoss = resume_prev_valid_loss\n",
        "    checkpointPath = resume_checkpointPath\n",
        "\n",
        "      #iter_hidden_layer_nodes = resume(itertools.product(nodes_per_layer, repeat=hidden_layers+1), resume_checkpoint['HiddenLayers'])      \n",
        "    #if(bool(resume_checkpoint)):\n",
        "    #  model , resume_checkpoint , filepath = load_checkpoint(checkpointPath,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')])\n",
        "\n",
        "  global_counter = 0\n",
        "  for current_replace_full_classifier in full_replace_full_classifier:\n",
        "    # REPLACE CLASSIFIER LAYER IN PRE_TRAINED_MODELS FULLY OR PARTIALLY\n",
        "    if( network_type != 'normal' and current_replace_full_classifier == False):\n",
        "      max_hidden_layers = 1\n",
        "      nodes_per_layer =  [1]\n",
        "      full_drop_ratios = [0.1]\n",
        "\n",
        "  \n",
        "    #VARY HIDDEN LAEYERS\n",
        "    for hidden_layers in range(max_hidden_layers,0,-1):\n",
        "      #VARY HIDDEN LAYER NODES/WIDTH\n",
        "      if(resumeExp):\n",
        "        \n",
        "        iter_hidden_layer_nodes = itertools.product(nodes_per_layer, repeat= hidden_layers)\n",
        "        iter_hidden_layer_nodes_list = [item for item in iter_hidden_layer_nodes]\n",
        "        resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\n",
        "        \n",
        "        pdb.set_trace()\n",
        "        #resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\n",
        "        resume_hidden_layer_width_list = tuple(list(map(int, resume_hidden_layer_width.split(','))))\n",
        "\n",
        "        iter_hidden_layer_nodes_list = iter_hidden_layer_nodes_list[iter_hidden_layer_nodes_list.index(resume_hidden_layer_width_list):]\n",
        "        \n",
        "        print('Resume ValidationLoss ',PreviousValidationLoss,'Resume Learning Rate Array ',learning_rates ,' Resume Drop Ratio List ',drop_ratios , ' Resume Hidden Nodes List with Size :',len(iter_hidden_layer_nodes_list) , ' Starting From :',iter_hidden_layer_nodes_list[0],' resume Pretrained Model with Size: ',len(pre_trained_models), ' Starting From: ',pre_trained_models[0], ' Resume FullClassifier: ',resume_replace_full_classifier )\n",
        "      else:      \n",
        "        iter_hidden_layer_nodes = itertools.product(nodes_per_layer, repeat=hidden_layers)\n",
        "        iter_hidden_layer_nodes_list = [item for item in iter_hidden_layer_nodes]\n",
        "      for hidden_layer in iter_hidden_layer_nodes_list:\n",
        "        #VARY LEARNING RATE\n",
        "        if( not resumeExp):\n",
        "          learning_rates = full_learning_rates\n",
        "        for lr in learning_rates :\n",
        "          #VARY DROP RATIO\n",
        "          if( not resumeExp):\n",
        "            drop_ratios = full_drop_ratios\n",
        "          for drop_ratio in drop_ratios :\n",
        "            if( not resumeExp):\n",
        "              pre_trained_models = full_pre_trained_models\n",
        "            for pre_trained_model in pre_trained_models :\n",
        "              print('Start Global Counter: '+str(global_counter)+' Network Type:'+pre_trained_model+' EXP-ID:'+exp_id+'  DurationSinceStart :',datetime.timedelta(seconds = time.time() - start_time),' with hidden_layers:',hidden_layers,' hidden_layer_width:',hidden_layer ,' Learning_Rate:',lr, ' drop_ratio:',drop_ratio, ' replace_full_classifier:',current_replace_full_classifier )\n",
        "              #model = Network(784, 10, [first_layer, second_layer, third_layer ],classes,transform,dataset, lr=0.001,train_on_gpu=True)\n",
        "\n",
        "              if( not bool(resume_checkpoint) or not resumeExp ):\n",
        "                #intput_size = (28*28) if network_type == 'normal' and dataset == 'MINST' else (32*32*3) if network_type == 'normal' and dataset == 'CIFAR' else 1024 # 1024 is defult for pretrained networks\n",
        "                input_size = 0\n",
        "                if network_type == 'normal' and dataset == 'MINST':\n",
        "                  input_size = (28*28) \n",
        "                elif network_type == 'normal' and dataset == 'CIFAR' :\n",
        "                  input_size = (32*32*3)  \n",
        "                #elif network_type != 'normal' :\n",
        "                #input_size = 1024 # 1024 is defult for pretrained networks\n",
        "\n",
        "                #if network_type == 'normal':\n",
        "                model = Network(input_size, 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True,network_type=pre_trained_model,replace_full_classifier = current_replace_full_classifier)\n",
        "                #else:\n",
        "                #  model = PreTrainenModels(input_size, 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True,network_type=network_type)\n",
        "\n",
        "              if(model.network_type == 'normal' or current_replace_full_classifier == True):\n",
        "                criterion = nn.NLLLoss()\n",
        "              else:\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "              #updated only classifier layer in pre-trained models , or all layers in normal networks\n",
        "              parameters_update = Network.parameters_to_update(model,network_type)\n",
        "              optimizer = optim.Adam(parameters_update, lr=lr)\n",
        "              \n",
        "                #if(dataset == 'MINST'):\n",
        "                #  model = Network(784, 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True,network_type=network_type)\n",
        "                #else:\n",
        "                #  model = Network((32*32*3), 10, hidden_layer ,classes,transform,dataset,drop_p=drop_ratio,lr =lr,train_on_gpu=True,network_type=network_type)\n",
        "\n",
        "              #Upload checkpoint to local drive\n",
        "              #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, False,checkpointPath,PreviousCheckPointId,PreviousValidationLoss,epochs=100)\n",
        "\n",
        "              \n",
        "              train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, True,checkpointPath,'',PreviousValidationLoss,start_time,exp_id,epochs=epochs)\n",
        "              if( bool(checkpointt) and checkpointt['ValidationLoss'] < PreviousValidationLoss ):\n",
        "                PreviousValidationLoss = checkpointt['ValidationLoss']\n",
        "              \n",
        "              print('Finished Global Counter: '+str(global_counter)+' %Network Type: {'+pre_trained_model+'}% EXP-ID : '+exp_id+'  DurationSinceStart :',datetime.timedelta(seconds = time.time() - start_time),' with %hidden_layers: {',hidden_layers,'}% %hidden_layer_width: {',hidden_layer ,'}% %Learning_Rate: {',lr, '}% %drop_ratio: {',drop_ratio,'}% %ReplaceFullClassifier: {',current_replace_full_classifier,'}%')\n",
        "              global_counter+= 1\n",
        "\n",
        "              #Plot current experiement training vs validation losses\n",
        "              plotLossTrend(train_lossess,valid_lossess, mode='Single')\n",
        "\n",
        "              #Plot global training vs validation losses\n",
        "              key = dataset + '_' + exp_id + '_' + (str(checkpointt['LastEpoch']) if bool(checkpointt) else str(epochs))            \n",
        "              \n",
        "              # get minimal loss here , as may be during certain experiment its loss is not less than global loss\n",
        "              min_loss = np.Inf\n",
        "              for curr_loss in train_lossess:\n",
        "                if(curr_loss < min_loss):\n",
        "                  min_loss = curr_loss\n",
        "              ele = {key: min_loss}\n",
        "              global_train_loss.append(ele)\n",
        "              \n",
        "\n",
        "              ele = {}\n",
        "              min_loss = np.Inf\n",
        "              for curr_loss in valid_lossess:\n",
        "                if(curr_loss < min_loss):\n",
        "                  min_loss = curr_loss\n",
        "              ele = {key: min_loss}\n",
        "              global_valid_loss.append(ele)\n",
        "\n",
        "              global_train_loss , global_valid_loss, min_train_loss , min_valid_loss = plotLossTrendAll(resume_checkpointPath,False,global_train_loss,global_valid_loss)\n",
        "            \n",
        "            #pdb.set_trace()\n",
        "            resumeExp=False\n",
        "\n",
        "#######################\n",
        "# PLOT LOSS TREND OF TRAINING & VALIDATON OF ALL EXP\n",
        "##############################3\n",
        "def plotLossTrendAll(OutputFolder,init,train_loss,valid_loss):\n",
        "\n",
        "    #OutputFolder = './results/'\n",
        "    file_epoch = 0\n",
        "    result_list=[]\n",
        "    print('Starting Plotting Loss Trend Across All Experiements ....')\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "    ele = dict()\n",
        "    min_train = np.Inf\n",
        "    min_valid = np.Inf\n",
        "\n",
        "    \"\"\"\n",
        "        for folder in os.listdir(OutputFolder):\n",
        "          for filename in os.listdir(OutputFolder+folder):\n",
        "            data = filename.split('_')\n",
        "            #pdb.set_trace()\n",
        "            print(data)\n",
        "            file_epoch=int(data[1][:-3])\n",
        "\n",
        "            model , checkpoint , filepath = load_checkpoint(OutputFolder+folder,OutputFilePrefix,False,file_epoch)\n",
        "    \"\"\"\n",
        "    if(init):\n",
        "      for root, dirs, files in os.walk(OutputFolder):\n",
        "        for filename in files:\n",
        "          fname, fext = os.path.splitext(filename)\n",
        "          if( fext != '.pt' ):\n",
        "            continue\n",
        "\n",
        "          model , checkpoint , filepath = load_checkpoint(root,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')],load_model=False)\n",
        "\n",
        "          key = checkpoint['Dataset'] + '_' + checkpoint['OutputFolder'] + '_' + str(checkpoint['LastEpoch'])\n",
        "          ele = {key: checkpoint['TrainingLoss']}\n",
        "          training_loss.append(ele)\n",
        "          \n",
        "          ele = {}\n",
        "          ele ={key: checkpoint['ValidationLoss']}\n",
        "          validation_loss.append(ele)\n",
        "\n",
        "          if(checkpoint['ValidationLoss'] < min_valid ):\n",
        "            min_valid = checkpoint['ValidationLoss']\n",
        "          if(checkpoint['TrainingLoss'] < min_train ):\n",
        "            min_train = checkpoint['TrainingLoss']\n",
        "            \n",
        "    else:\n",
        "      training_loss = train_loss\n",
        "      validation_loss = valid_loss\n",
        "        \n",
        "    #print('Result List',result_list)\n",
        "    plotLossTrend (training_loss,validation_loss,mode='Multiple')\n",
        "\n",
        "    return training_loss,validation_loss, min_train, min_valid \n",
        "      \n",
        "\n",
        "#############################\n",
        "# PLOT TRAINING LOSS VS VALIDATION LOSS \n",
        "############################\n",
        "def plotLossTrend(train_losses,validation_losses,test_losses=[],mode='Single'):\n",
        "  #TRAINING LOSS DATA\n",
        "  values = []\n",
        "  labels = []\n",
        "  \n",
        "  if(mode !='Single'):\n",
        "    for item in train_losses:    \n",
        "      for key, value in item.items():\n",
        "        values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "        labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "  else:\n",
        "    for epoch in range(len(train_losses)):    \n",
        "      values.append(\"{0:.5f}\".format(train_losses[epoch])) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(epoch) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "    #values = train_losses\n",
        "    #labels = train_losses\n",
        "\n",
        "  plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Training Loss',linestyle='dashed')\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "  \n",
        "  plt.xticks(rotation=90)\n",
        "  #plt.show()\n",
        "\n",
        "  #VALIDATON LOSS\n",
        "  values = []\n",
        "  labels = []\n",
        "  if(mode !='Single'):\n",
        "    for item in validation_losses:   \n",
        "      #pdb.set_trace() \n",
        "      for key, value in item.items():      \n",
        "        values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "        labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "  else:\n",
        "    for epoch in range(len(validation_losses)):    \n",
        "      values.append(\"{0:.5f}\".format(validation_losses[epoch])) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(epoch) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "\n",
        "  #plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Validation Loss', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4)\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "  \n",
        "  plt.xticks(rotation=90)\n",
        "  #plt.show()\n",
        "\n",
        "  #TEST LOSS\n",
        "  values = []\n",
        "  labels = []\n",
        "  for item in test_losses:    \n",
        "    for key, value in item.items():\n",
        "      #pdb.set_trace()\n",
        "      values.append(\"{0:.5f}\".format(value)) #= train_losses[:1] #[7, 57, 121, 192, 123, 240, 546]\n",
        "      labels.append(key) #= train_losses[:0] #['1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
        "\n",
        "  if(bool(test_losses)):\n",
        "    plt.title(\"Training vs Validation vs Testing\")\n",
        "  else:\n",
        "    plt.title(\"Training vs Validation\")\n",
        "  if( mode == 'Single' ):\n",
        "    plt.xlabel(\"Epochs\")\n",
        "  else:\n",
        "    plt.xlabel(\"Expriements\")\n",
        "\n",
        "  #plt.figure(figsize = (12,12))   \n",
        "  plt.plot(labels,values,label='Test Loss')\n",
        "  for i,j in zip(labels,values):\n",
        "      plt.annotate(str(j),xy=(i,j))\n",
        "\n",
        "  plt.ylabel(\"Loss\")  \n",
        "  #plt.ylim((0,1.))\n",
        "\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  #for i, v in enumerate(values):\n",
        "  #    ax.text(i, v+25, \"%d\" %v, ha=\"center\")\n",
        "  #plt.ylim(-10, 595)\n",
        "\n",
        "#############################\n",
        "# LOAD CHECKPOINT\n",
        "############################\n",
        "def load_checkpoint(OutputFolder,OutputFilePrefix,max_epoch,exact_epoch,load_model=True):\n",
        "    \n",
        "    file_epoch = 0\n",
        "    if(max_epoch):\n",
        "      for filename in os.listdir(OutputFolder):\n",
        "        data = filename.split('_')\n",
        "        tmp=int(data[1][:-3])\n",
        "        #print('data[1]',data[1],' tmp[:-3] ',tmp[:-3])\n",
        "        if( file_epoch <= tmp ):\n",
        "          file_epoch = tmp\n",
        "    else:\n",
        "      file_epoch=exact_epoch\n",
        "\n",
        "    filepath = OutputFolder+'/'+OutputFilePrefix + str(file_epoch)+'.pt'\n",
        "    print('Loading Checkpoint from '+filepath+'...')\n",
        "    indent=1\n",
        "    \n",
        "    cpu_or_gpu = torch.cuda.is_available()\n",
        "    checkpoint = None\n",
        "\n",
        "    if not cpu_or_gpu :\n",
        "      checkpoint = torch.load(filepath,map_location='cpu')\n",
        "    else:\n",
        "      checkpoint = torch.load(filepath)\n",
        "\n",
        "    for key, value in checkpoint.items():\n",
        "        if(key == 'StateDictionay'):\n",
        "          continue\n",
        "        print('\\t' * indent + str(key),'\\t' * (indent+1) + str(value))\n",
        "        #print('\\t' * (indent+1) + str(value))\n",
        "    \n",
        "    testmodel = None\n",
        "\n",
        "    if(load_model ):\n",
        "      testmodel = Network(    checkpoint['InputSize'],\n",
        "                              checkpoint['OutputSize'],\n",
        "                              checkpoint['HiddenLayers'],\n",
        "                              checkpoint['OutputClasses'],\n",
        "                              checkpoint['Transforms'],\n",
        "                              checkpoint['Dataset'],\n",
        "                              checkpoint['DropRatio'],\n",
        "                              checkpoint['LearningRate'],\n",
        "                              train_on_gpu=checkpoint['GPUState'],\n",
        "                              network_type=checkpoint['NetworkType'],\n",
        "                              replace_full_classifier = checkpoint.get('ReplaceFullClassifier',False)\n",
        "                      )\n",
        "      if(testmodel.network_type == 'normal'):\n",
        "        testmodel.load_state_dict(checkpoint['StateDictionay'])\n",
        "      else:\n",
        "        testmodel.pre_trained_model.load_state_dict(checkpoint['StateDictionay'])\n",
        "    \"\"\"elif(load_model and checkpoint['NetworkType'] !='normal' ):\n",
        "      testmodel = PreTrainenModels(    checkpoint['InputSize'],\n",
        "                              checkpoint['OutputSize'],\n",
        "                              checkpoint['HiddenLayers'],\n",
        "                              checkpoint['OutputClasses'],\n",
        "                              checkpoint['Transforms'],\n",
        "                              checkpoint['Dataset'],\n",
        "                              checkpoint['DropRatio'],\n",
        "                              checkpoint['LearningRate'],\n",
        "                              train_on_gpu=checkpoint['GPUState'],\n",
        "                              network_type=checkpoint['NetworkType']\n",
        "                      )\n",
        "    \n",
        "    print(testmodel.state_dict().keys())\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    return testmodel , checkpoint , filepath\n",
        "\n",
        "\n",
        "def test_all_epochs(OutputFolder,test_loader,criterion,batch_size,OutputFilePrefix='checkpoint_'):\n",
        "\n",
        "    #OutputFolder = './results/'\n",
        "    file_epoch = 0\n",
        "    result_list=[]\n",
        "    print('Starting Test All Saved Epochs ....')\n",
        "    trainig_loss=[]\n",
        "    validation_loss=[]\n",
        "    test_loss=[]\n",
        "    ele = dict()\n",
        "\n",
        "    \"\"\"\n",
        "        for folder in os.listdir(OutputFolder):\n",
        "          for filename in os.listdir(OutputFolder+folder):\n",
        "            data = filename.split('_')\n",
        "            #pdb.set_trace()\n",
        "            print(data)\n",
        "            file_epoch=int(data[1][:-3])\n",
        "\n",
        "            model , checkpoint , filepath = load_checkpoint(OutputFolder+folder,OutputFilePrefix,False,file_epoch)\n",
        "    \"\"\"\n",
        "    #for filename in os.listdir(checkpointPath):\n",
        "    for root, dirs, files in os.walk(OutputFolder):\n",
        "      for filename in files:\n",
        "        model , checkpoint , filepath = load_checkpoint(root,filename[:filename.rfind('_')+1],False,filename[filename.rfind('_')+1:filename.rfind('.')],load_model=True)\n",
        "\n",
        "        checkpoint , checkpoint_test = test(model,test_loader,criterion,checkpoint,filepath,batch_size,False)\n",
        "\n",
        "        print('Test Accuracy ',checkpoint_test['Test Accuracy (Overall): '])\n",
        "        result_list.append(checkpoint_test)\n",
        "\n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint['TrainingLoss'])\n",
        "        key = checkpoint['Dataset'] + '_' + checkpoint['OutputFolder'] + '_' + str(checkpoint['LastEpoch'])\n",
        "        ele = {key: checkpoint['TrainingLoss']}\n",
        "        trainig_loss.append(ele)\n",
        "        \n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint['ValidationLoss'])\n",
        "        ele = {}\n",
        "        ele ={key: checkpoint['ValidationLoss']}\n",
        "        validation_loss.append(ele)\n",
        "\n",
        "        #ele = [list() for f in range(1)] # We have Three Empty Rows\n",
        "        #ele[0].append(checkpoint['Dataset']+'_'+checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch']))\n",
        "        #ele[0].append(checkpoint_test['TestLoss'])\n",
        "        ele = {}\n",
        "        ele ={key: checkpoint_test['TestLoss']}\n",
        "        test_loss.append(ele)\n",
        "    \n",
        "    #print('Result List',result_list)\n",
        "    plotLossTrend (trainig_loss,validation_loss,test_loss)\n",
        "    return result_list\n",
        "      \n",
        "\n",
        "#############################\n",
        "# VISUALIZE ALL IMAGES IN BATCH\n",
        "############################\n",
        "def visualize_images_in_batch(loader,batch_size) :\n",
        "    # obtain one batch of training images\n",
        "\t\tdataiter = iter(loader)\n",
        "\t\timages, labels = dataiter.next()\n",
        "\t\timages = images.numpy()\n",
        "\n",
        "\t\t# plot the images in the batch, along with the corresponding labels\n",
        "\t\tfig = plt.figure(figsize=(25, 4))\n",
        "\t\tfor idx in np.arange(batch_size):\n",
        "\t\t\tax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
        "\t\t\tax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "\t\t\t# print out the correct label for each image\n",
        "\t\t\t# .item() gets the value contained in a Tensor\n",
        "\t\t\tax.set_title(str(labels[idx].item()))\n",
        "\t\treturn images\n",
        "\n",
        "#############################\n",
        "# VISUALIZE ALL RGB IMAGES IN BATCH\n",
        "############################\n",
        "def visualize_rgb_images_in_batch(train_loader):\n",
        "  # obtain one batch of training images\n",
        "  dataiter = iter(train_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images = images.numpy() # convert images to numpy for display\n",
        "  # plot the images in the batch, along with the corresponding labels\n",
        "  fig = plt.figure(figsize=(25, 4))\n",
        "  # display 20 images\n",
        "  for idx in np.arange(20):\n",
        "      ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "      #imshow(images[idx])\n",
        "      img = images[idx]\n",
        "      img = img / 2 + 0.5  # unnormalize\n",
        "      plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "      ax.set_title(classes[labels[idx]])\n",
        "\n",
        "\n",
        "\n",
        "#############################\n",
        "# VISUALIZE PIXEL OF AN IMAGE RETURN FROM PREV FUNCTION\n",
        "############################\n",
        "def visualize_image_pixels_value(image):\n",
        "\n",
        "  img = np.squeeze(image)\n",
        "  fig = plt.figure(figsize = (12,12)) \n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img, cmap='gray')\n",
        "  width, height = img.shape\n",
        "  thresh = img.max()/2.5\n",
        "  for x in range(width):\n",
        "      for y in range(height):\n",
        "          val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "          ax.annotate(str(val), xy=(y,x),\n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center',\n",
        "                      color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "def visualize_rgb_image_pixels_value(image):\n",
        "  rgb_img = np.squeeze(image)\n",
        "  channels = ['red channel', 'green channel', 'blue channel']\n",
        "\n",
        "  fig = plt.figure(figsize = (36, 36)) \n",
        "  for idx in np.arange(rgb_img.shape[0]):\n",
        "      ax = fig.add_subplot(1, 3, idx + 1)\n",
        "      img = rgb_img[idx]\n",
        "      ax.imshow(img, cmap='gray')\n",
        "      ax.set_title(channels[idx])\n",
        "      width, height = img.shape\n",
        "      thresh = img.max()/2.5\n",
        "      for x in range(width):\n",
        "          for y in range(height):\n",
        "              val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "              ax.annotate(str(val), xy=(y,x),\n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center', size=8,\n",
        "                      color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "def visualize_test_results(model,test_loader,batch_size,RGB=False):\n",
        "  # obtain one batch of test images\n",
        "  dataiter = iter(test_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images.numpy()\n",
        "\n",
        "  # move model inputs to cuda, if GPU available\n",
        "  if model.train_on_gpu:\n",
        "      images = images.cuda()\n",
        "\n",
        "  # Flatten images into a 784 long vector\n",
        "  images.resize_(images.size()[0], model.input_size)\n",
        "\n",
        "  # get sample outputs\n",
        "  output = model(images)\n",
        "  # convert output probabilities to predicted class\n",
        "  _, preds_tensor = torch.max(output, 1)\n",
        "  preds = np.squeeze(preds_tensor.numpy()) if not model.train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "  # plot the images in the batch, along with predicted and true labels\n",
        "  fig = plt.figure(figsize=(25, 4))\n",
        "  for idx in np.arange(batch_size):\n",
        "      ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
        "\n",
        "      image_cpu = images.cpu()[idx]\n",
        "      image_cpu = image_cpu / 2 + 0.5  # unnormalize\n",
        "      if(RGB):\n",
        "        plt.imshow(np.transpose(image_cpu, (1, 2, 0)))  # convert from Tensor image\n",
        "      else:\n",
        "        ax.imshow(np.squeeze(image_cpu), cmap='gray')\n",
        "\n",
        "      ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                  color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.4.0\n",
            "Torchvision Version:  0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wXvRQ0zv5hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### TEST ALL EPOCHS ##############################\n",
        "def test_test_all_epochs():\n",
        "    \n",
        "\n",
        "  #model , checkpointtt , filepathh = load_checkpoint(checkpointttt['OutputFolder'],checkpointttt['OutputFilePrefix'],False,10)\n",
        "\n",
        "  #result_list = test_all_epochs(test_loader,criterion,batch_size)\n",
        "\n",
        "  dataset = 'MINST'\n",
        "\n",
        "\n",
        "  #How many samples loaded per batch\n",
        "  batch_size = 20\n",
        "  # percentage of training set to use as validation\n",
        "  valid_size = 0.2\n",
        "\n",
        "  #train_loader =None\n",
        "  #valid_loader =None\n",
        "  #Load Data\n",
        "  dataset = 'MINST'\n",
        "  train_loader , valid_loader ,test_loader , classes , transform = LoadData(dataset,batch_size,valid_size)\n",
        "\n",
        "\n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "  gfolder = '/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/'\n",
        "\n",
        "  localfolder = './results/'+dataset+'/'\n",
        "\n",
        "  result_list = test_all_epochs(gfolder,test_loader,nn.NLLLoss(),batch_size,OutputFilePrefix='checkpoint_')\n",
        "\n",
        "  #checkpoint = torch.load('/content/drive/My Drive/Colab Notebooks/models/minst/29_Feb_2020_20_06_50_74.pt')\n",
        "\n",
        "  #print(checkpoint)\n",
        "  #load_checkpoint('/gdrive/My Drive/Colab Notebooks/models/'+dataset,'29_Feb_2020_20_06_50',False,74)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu907NvWVlBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## TEST VISUALIZATION###################\n",
        "def test_visualize_images_in_batch():\n",
        "  images = visualize_images_in_batch(train_loader,batch_size)\n",
        "  visualize_image_pixels_value(images[2])\n",
        "\n",
        "  model , checkpointtt , filepathh = load_checkpoint(checkpointt['OutputFolder'],checkpointt['OutputFilePrefix'],True,0)\n",
        "\n",
        "  checkpointttt = test(model,test_loader,criterion,checkpointtt,filepathh,batch_size,True)\n",
        "\n",
        "  # obtain one batch of test images\n",
        "  dataiter = iter(test_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images.numpy()\n",
        "\n",
        "  #visualize_rgb_image_pixels_value(images[2])\n",
        "  #visualize_test_results(model,test_loader,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbNJdUIMSTBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "#import helper.py\n",
        "import imp \n",
        "\n",
        "\n",
        "################################\n",
        "# INIT GITHUB\n",
        "#######################################\n",
        "def init_github():\n",
        "  \"\"\"\n",
        "  !git init\n",
        "  !git config  global user.email ice.man011@gmail.com\n",
        "  !git config  global user.name iceman011\n",
        "  !git add -A\n",
        "  !git commit -m first commit\n",
        "  !git remote add origin https://<username>:<password>github@github.com/iceman011/mydeeplearning.git\n",
        "  !git push -u origin master\n",
        "  \"\"\"\n",
        "  #!git clone -l -s git://github.com/iceman011/mydeeplearning.git #mydeeplearning-repo\n",
        "  #!git clone -l -s https://github.com/iceman011@github.com/mydeeplearning.git\n",
        "\n",
        "  #%cd mydeeplearning-repo\n",
        "  #!ls\n",
        "\n",
        "  # path to your project on Google Drive\n",
        "  #MY_GOOGLE_DRIVE_PATH = 'My Drive/MyDrive/Udacity/deep-learning-v2-pytorch' \n",
        "  # replace with your Github username \n",
        "  GIT_USERNAME = \"iceman011\" \n",
        "  # definitely replace with your\n",
        "  GIT_TOKEN = \"1aeb0c6f424e3c604988a3a636f74c6e5180cd89\"  \n",
        "  # Replace with your github repository in this case we want \n",
        "  # to clone deep-learning-v2-pytorch repository\n",
        "  GIT_REPOSITORY = \"mydeeplearning\" \n",
        "\n",
        "  # REMOVE IT BEFORE INIT\n",
        "  if( os.path.isdir('./'+GIT_REPOSITORY) ):\n",
        "    shutil.rmtree('./'+GIT_REPOSITORY)\n",
        "\n",
        "  #PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "  # It's good to print out the value if you are not sure \n",
        "  #print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "  # In case we haven't created the folder already; we will create a folder in the project path \n",
        "  #!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "  #GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "\n",
        "  GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "  print(\"GIT_PATH: \", GIT_PATH)\n",
        "\n",
        "  !git clone \"{GIT_PATH}\" # clone the github repository\n",
        "\n",
        "############################3\n",
        "# CONVERT FROM COLAB INTO PYTHON\n",
        "#############################3\n",
        "def from_colab_to_python():\n",
        "\n",
        "  !pip install ipython\n",
        "  !pip install nbconvert\n",
        "  !ipython nbconvert --to python ./mydeeplearning/ez_deep.ipynb\n",
        "\n",
        "  #helper = imp.new_module('ez-mlp')\n",
        "  #exec(open('./'+GIT_REPOSITORY+\"/ez-mlp.py\").read(), helper.__dict__)\n",
        "\n",
        "\n",
        "#############################\n",
        "#\n",
        "#################################\n",
        "def download_dataset_from_url():\n",
        "  !wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "  os.listdir()\n",
        "  !unzip hymenoptera_data.zip -d ./data/hymenoptera_data\n",
        "\n",
        "\n",
        "######################################\n",
        "# PUSH CHANGES TO GITHUB\n",
        "##################################\n",
        "def push_github():\n",
        "  !git add -u\n",
        "  !git commit -m \"new commit\"\n",
        "  !git push mydeeplearning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voDNqAjioodn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################# TEST TUNE NETWORK ####################################\n",
        "import sys\n",
        "\n",
        "\"\"\"\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\"\"\"\n",
        "def test_tune_train_network(dataset):    \n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "  #tune_train_network(resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "  #tune_train_network('MINST',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "\n",
        "  #load_last_exp_param('/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/3-6-2020.txt','/content/gdrive/My Drive/Colab Notebooks/models/MINST/06_Mar_2020_07_57_24/')\n",
        "\n",
        "  #sys.path.append('./mydeeplearning/')\n",
        "  \n",
        "  #MINST\n",
        "  #cmd_str = \"from mydeeplearning.ez_mlp import*; tune_train_network(\"+dataset+\",10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/') 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt'\" \n",
        "  func_str = \"\\\"from mydeeplearning.ez_deep import*; tune_train_network(\\'\"+dataset+\"\\',1,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/\"+dataset+\"_logs/resume.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/')\\\"\" \n",
        "  log_path = \"'/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/\"+dataset+\"_logs/test-25-3-2020.txt'\"\n",
        "\n",
        "\n",
        "  #CIFAR\n",
        "  #func_str = \"\\\"from mydeeplearning.ez_mlp import*; tune_train_network(\\'\"+dataset+\"\\',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/3-8-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/')\\\"\" \n",
        "  #log_path = \"'/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/3-8-2020.txt'\"\n",
        "\n",
        "  print(func_str)\n",
        "  print(log_path)\n",
        "\n",
        "  #!python -c \"from mydeeplearning.ez_mlp import*; tune_train_network('CIFAR',10,resumeExp=False,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/logs/3-8-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/06_Mar_2020_07_57_24/')\" 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/logs/3-8-2020.txt'\n",
        "  !python -c $func_str 2>&1 | tee -a $log_path\n",
        "\n",
        "\n",
        "  #!python -c $cmd_str\n",
        "\n",
        "  #!python -c \"from mydeeplearning.ez_mlp import*; tune_train_network(\"+dataset+\",10,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/logs/resume-3-6-2020.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/\"+dataset+\"/06_Mar_2020_07_57_24/')\" -u /mydeeplearning/ez_mlp.py 2>&1 | tee -a '/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs/resume-3-6-2020.txt' #2>&1\n",
        "  \n",
        "  \n",
        "\n",
        "  #load_last_exp_param('/content/gdrive/My Drive/Colab Notebooks/models/MINST/logs','/content/gdrive/My Drive/Colab Notebooks/models/MINST/04_Mar_2020_20_13_34')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7of0_y_zsQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "######################    \n",
        "# MAIN #\n",
        "######################\n",
        "def main():\n",
        "\n",
        "  # Create the network, define the criterion and optimizer\n",
        "  drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "  dataset = 'CIFAR'\n",
        "\n",
        "  #init_github()\n",
        "  #from_colab_to_python()\n",
        "  test_tune_train_network(dataset)\n",
        "\n",
        "  #CONTINUE FROM PREVIOUS MODEL\n",
        "  #model , checkpoint , filepath = load_checkpoint('/content/drive/My Drive/Colab Notebooks/models/MINST/01_Mar_2020_18_42_35','checkpoint_',True,0)\n",
        "  #PreviousCheckPointId = checkpoint['OutputFolder']+'_'+str(checkpoint['LastEpoch'])\n",
        "  #PreviousValidationLoss= checkpoint['ValidationLoss'] #np.Inf\n",
        "\n",
        "  #model = Network(784, 10, [512, 256, 128 , 64 ],classes,transform,dataset, lr=0.001,train_on_gpu=True)\n",
        "\n",
        "  #criterion = nn.NLLLoss()\n",
        "  #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  #checkpointPath = f'/content/gdrive/My Drive/Colab Notebooks/models/'+dataset+'/'\n",
        "  #checkpointPath = f'./results/'+dataset+'/'\n",
        "\n",
        "\n",
        "\n",
        "  #Upload checkpoint to local drive\n",
        "  #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, False,checkpointPath,PreviousCheckPointId,PreviousValidationLoss,epochs=100)\n",
        "\n",
        "  #Upload to gDrive\n",
        "  #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, True,checkpointPath,'',np.Inf,epochs=10)\n",
        "\n",
        "  #plotLossTrend (train_lossess , valid_lossess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mp5Be63OjI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if __name__ == '__main__':\n",
        "#main()\n",
        "\n",
        "#tune_train_network('CIFAR',1,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/logs/test.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/test/',network_type='resnet18')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ5bRRFqG7QE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08452113-44d9-47f9-c699-17a310f8007e"
      },
      "source": [
        " tune_train_network('CIFAR',2,resumeExp=True,resume_logPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/CIFAR_logs/test.txt',resume_checkpointPath='/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/transferL',network_type='resenet')\n"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Plotting Loss Trend Across All Experiements ....\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/CIFAR/transferL/24_Mar_2020_18_00_11/vgg16/checkpoint_24_Mar_2020_18_28_37_0.pt...\n",
            "\tInputSize \t\t4096\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\tVGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t1\n",
            "\tTrainingLoss \t\t0.09621553091406822\n",
            "\tValidationLoss \t\t2.184646368980408\n",
            "\tValidationAccuracy \t\ttensor(42.2600)\n",
            "\tElapsedTime \t\t0:28:25.850911\n",
            "\tDataset \t\tCIFAR\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t24_Mar_2020_18_00_11/vgg16\n",
            "\tCheckPointTimestamp \t\t24_Mar_2020_18_28_37\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "\tNetworkType \t\tvgg16\n",
            "\tTransforms \t\tNone\n",
            "\tTrainingLosses \t\t[0.09621553091406822]\n",
            "\tValidationLosses \t\t[2.184646368980408]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdMAAAcPCAYAAADKC2hBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAw4n8AbPzqd8dBPIwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 745,
              "height": 903
            }
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Starting Tunning With MinTrainLoss: 0.09621553091406822  MinValidLoss: 2.184646368980408\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "25_Mar_2020_20_30_39 : Resuming Experiment With New ID  25_Mar_2020_20_30_35\n",
            "Loading Checkpoint from /content/gdrive/My Drive/Colab Notebooks/models/CIFAR/transferL/24_Mar_2020_18_00_11/vgg16/checkpoint_24_Mar_2020_18_28_37_0.pt...\n",
            "\tInputSize \t\t4096\n",
            "\tOutputSize \t\t10\n",
            "\tHiddenLayers \t\tVGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\tLearningRate \t\t0.0001\n",
            "\tDropRatio \t\t1\n",
            "\tTrainingLoss \t\t0.09621553091406822\n",
            "\tValidationLoss \t\t2.184646368980408\n",
            "\tValidationAccuracy \t\ttensor(42.2600)\n",
            "\tElapsedTime \t\t0:28:25.850911\n",
            "\tDataset \t\tCIFAR\n",
            "\tLastEpoch \t\t0\n",
            "\tPreviousCheckPoint \t\t\n",
            "\tGPUState \t\tTrue\n",
            "\tOutputFolder \t\t24_Mar_2020_18_00_11/vgg16\n",
            "\tCheckPointTimestamp \t\t24_Mar_2020_18_28_37\n",
            "\tOutputFilePrefix \t\tcheckpoint_\n",
            "\tOutputClasses \t\t['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "\tNetworkType \t\tvgg16\n",
            "\tTransforms \t\tNone\n",
            "\tTrainingLosses \t\t[0.09621553091406822]\n",
            "\tValidationLosses \t\t[2.184646368980408]\n",
            "CUDA is available!  Using GPU ...\n",
            "init Network with Type  vgg16\n",
            " Not Found Matching Checkpoint with Last Experiement Parameters hidden_layers:1  hidden_layer_width:[1] Learning_rate:0.0001 drop_ratio:0.1 network_type:vgg11 replace_full_classifier:False \n",
            "> <ipython-input-172-6118650ebbb9>(994)tune_train_network()\n",
            "-> resume_hidden_layer_width_list = tuple(list(map(int, resume_hidden_layer_width.split(','))))\n",
            "(Pdb) resume_hidden_layer_width\n",
            "[]\n",
            "--KeyboardInterrupt--\n",
            "(Pdb) exit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-83367f25969a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtune_train_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CIFAR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresumeExp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresume_logPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/CIFAR_logs/test.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresume_checkpointPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/models/CIFAR/transferL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-172-6118650ebbb9>\u001b[0m in \u001b[0;36mtune_train_network\u001b[0;34m(dataset, epochs, resumeExp, resume_logPath, resume_checkpointPath, network_type)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m#resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mresume_hidden_layer_width_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_hidden_layer_width\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0miter_hidden_layer_nodes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_hidden_layer_nodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_hidden_layer_nodes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_hidden_layer_width_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-172-6118650ebbb9>\u001b[0m in \u001b[0;36mtune_train_network\u001b[0;34m(dataset, epochs, resumeExp, resume_logPath, resume_checkpointPath, network_type)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m#resume_hidden_layer_width = resume_hidden_layer_width[1:len(resume_hidden_layer_width)-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mresume_hidden_layer_width_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_hidden_layer_width\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0miter_hidden_layer_nodes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_hidden_layer_nodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_hidden_layer_nodes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_hidden_layer_width_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3pXag-J41mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "\n",
        "\"\"\",'vgg11'-> model.classifier[0].in_features\n",
        "'vgg11_bn'-> model.classifier[0].in_features\n",
        "'vgg13' -> model.classifier[0].in_features\n",
        "'vgg13_bn'-> model.classifier[0].in_features\n",
        "\n",
        "'vgg16','vgg16_bn','vgg19','vgg19_bn',\n",
        "                             'resnet18' ->model.fc.in_features\n",
        "                             \n",
        "                             ,'resnet34','resnet50','resnet101','resnet152',\n",
        "                             'squeezenet1_0','squeezenet1_1', -> 512\n",
        "\n",
        "                             'densenet121','densenet169','densenet161','densenet201', -> model.classifier.in_features\n",
        "                             'inception_v3'\n",
        "                            ]\n",
        "\n",
        "\n",
        "model  = pretrained_models.squeezenet1_0(pretrained=True)\n",
        "print(model)\n",
        "#print(model.classifier.in_features)\n",
        "\"\"\"\n",
        "\n",
        "def test_pre_trained_mode():\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_loader , valid_loader ,test_loader , classes , transform = LoadData('CIFAR',20,0.2,'resnet18')\n",
        "\n",
        "  model = pretrained_models.vgg11(pretrained=True)\n",
        "\n",
        "  print(model)\n",
        "  # Freeze parameters so we don't backprop through them\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "      \n",
        "  model.classifier[6] = nn.Linear(4096,10)\n",
        "                     #nn.Sequential(nn.Linear(512, 1024),\n",
        "                     #             nn.ReLU(),\n",
        "                     #             nn.Dropout(0.2),\n",
        "                     #             nn.Linear(1024, 10),\n",
        "                     #             nn.LogSoftmax(dim=1))\n",
        "\n",
        "  for param in model.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "  criterion = CrossEntropyLoss()\n",
        "  #criterion = nn.NLLLoss()\n",
        "\n",
        "  # Only train the classifier parameters, feature parameters are frozen\n",
        "  optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "  \n",
        "  #checkpointPath = f'./results/CIFAR/'\n",
        "\n",
        "  #Upload checkpoint to local drive\n",
        "  #train_lossess , valid_lossess , checkpointt = train(model, train_loader, valid_loader, criterion, optimizer, False,checkpointPath,'',np.Inf,'start_time','exp_id',epochs=100)\n",
        "                                                  \n",
        "  \n",
        "  model.to(device);\n",
        "\n",
        "  epochs = 10\n",
        "  steps = 0\n",
        "  running_loss = 0\n",
        "  print_every = 2\n",
        "  for epoch in range(epochs):\n",
        "      for inputs, labels in train_loader:\n",
        "          steps += 1\n",
        "          # Move input and label tensors to the default device\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          logps = model.forward(inputs)\n",
        "          loss = criterion(logps, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          \n",
        "          if steps % print_every == 0:\n",
        "              test_loss = 0\n",
        "              accuracy = 0\n",
        "              model.eval()\n",
        "              with torch.no_grad():\n",
        "                  for inputs, labels in test_loader:\n",
        "                      inputs, labels = inputs.to(device), labels.to(device)\n",
        "                      logps = model.forward(inputs)\n",
        "                      batch_loss = criterion(logps, labels)\n",
        "                      \n",
        "                      test_loss += batch_loss.item()\n",
        "                      \n",
        "                      # Calculate accuracy\n",
        "                      ps = torch.exp(logps)\n",
        "                      top_p, top_class = ps.topk(1, dim=1)\n",
        "                      equals = top_class == labels.view(*top_class.shape)\n",
        "                      accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                      \n",
        "              print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                    f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                    f\"Test loss: {test_loss/len(test_loader):.3f}.. \"\n",
        "                    f\"Test accuracy: {accuracy/len(test_loader):.3f}\")\n",
        "              running_loss = 0\n",
        "              model.train()\n",
        "\n",
        "\n",
        "#test_pre_trained_mode()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}